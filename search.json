{"entries":[{"title":"Yegor Bugayenko About Programming","url":"/index.html","tags":[],"date":null,"categories":[],"body":" page of "},{"title":"Unsubscribe","url":"/unsubscribe.html","tags":[],"date":null,"categories":[],"body":"I'm sorry to see you leaving :( Your email Unsubscribe You can always subscribe again. "},{"title":null,"url":"/tag/oop.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/anti-pattern.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/dynamodb.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/maven.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/aws.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/java.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/logging.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/slf4j.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/github.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/jcabi.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/mysql.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/s3.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/stateful.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/xembly.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/xml.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/xsl.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/xsd.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/hamcrest.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/xpath.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/testing.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/http.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/xdsd.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/mgmt.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/phandom.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/phantomjs.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/w3c.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/pdd.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/s3auth.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/mocking.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/requs.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/requirements.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/movies.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/liquibase.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/rultor.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/devops.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/docker.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/qulice.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/static-analysis.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/jdbc.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/rubygems.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/ruby.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/book-review.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/aop.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/heroku.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/restful.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/xslt.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/ssh.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/jekyll.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/pygments.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/casperjs.html","tags":[],"date":null,"categories":[],"body":""},{"title":null,"url":"/tag/sass.html","tags":[],"date":null,"categories":[],"body":""},{"title":"Puzzle Driven Development","url":"/2009/03/04/pdd.html","tags":["pdd"],"date":"2009-03-04 16:52:26 +0000","categories":[],"body":"PDD, or Puzzle Driven Development, is a method used to break down programming tasks into smaller ones and enable their implementation in parallel. The PDD method is used widely in XDSD methodology. The method is pending a USPTO patent (application no. 12/840,306 ). Let's review the method with an example. Say, for instance, you are a programmer and have been tasked to design and implement a Java class. This is the formal task description: \"class DBWriter has to extend java.io.Writer abstract class and save all incoming data into the database\". You have one hour to implement this task. It is obvious to you that one hour is not enough because the problem is much bigger and requires more work than the slotted time allows. Additionally, there are a numerous unknowns: What information do we need to save, and in what format? What is the DB schema? Is it an SQL or NoSQL database? How to connect to the DB? JDBC? JPA? DAO? How to handle exceptions? Let's keep all these unknowns in mind as we try to solve the problem on the highest level of abstraction. Of course, we start with a test: import org.junit.* ; import static org . mockito . Mockito .*; public class DBWriterTest { @Test void testSavesDataIntoDatabase () throws Exception { DataBridge mapper = mock ( DataBridge . class ); Writer writer = new DBWriter ( mapper ); try { writer . write ( \"hello, world!\" ); } finally { writer . close (); } verify ( mapper ). insert ( \"hello, world!\" ); } } In the above test, we define the expected behavior of the class. The test fails to compile because there are two missing classes: DataBridge and DBWriter . Let's implement the bridge first: import java.io.IOException ; public interface DataBridge { void insert ( String text ) throws IOException ; } Next, the writer itself: import java.io.IOException ; import java.io.Writer ; import java.utils.Arrays ; public class DBWriter implements Writer { private DataBridge bridge ; public DBWriter ( DataBridge brdg ) { this . bridge = brdg ; } @Override void flush () throws IOException { } @Override void close () throws IOException { } @Override void write ( char [] cbuf , int off , int len ) throws IOException { String data = new String ( Arrays . copyOfRange ( cbuf , off , off + len )); this . bridge . insert ( data ); } } Using the above code, we solve the problem. In the example, we successfully designed, implemented and tested the required DBWriter class. Subsequently, the class can now immediately can be used \"as is\" by other classes. Of course, the implementation is not finished, since we are not writing anything to the database. Furthermore, we still aren't answering the majority of questions asked in the sample scneario. For instance, we still don't know exactly how the database needs to be connected, its type (SQL or NoSQL,) the correct data format and so on. However, we've already made a number of important architectural assumptions, which allowed us to implement the class and make it usable by other classes. Now it's time to identify the unknowns in our code and mark them with puzzles. Every puzzle is a request for refinement. We want to ask someone else to help us refine and correct our assumptions. Here is the first puzzle we need to add: public interface DataBridge { /** * @todo #123 I assumed that a simple insert() method will be * enough to insert data into the database. Maybe it's * not true, and some sort of transaction support may be * required. We should implement this interface and create * an integration test with a database. */ void insert ( String text ) throws IOException { } } The puzzle has three elements: @todo tag, #123 locator and a comment. Locator displays the following: \"The puzzle was created while working with ticket #123\". Let’s add one more puzzle: void write ( char [] cbuf , int off , int len ) throws IOException { // @todo #123 I assumed that the data should be sent to the database // as its received by the writer. Maybe this assumption // is wrong and we should aggregate data into blocks/chunks // and then send them to the data bridge. String data = new String ( Arrays . copyOfRange ( cbuf , off , off + len )); this . bridge . insert ( data ); } This puzzle indicates one of our concerns because we are not sure that the architectural decision is right. Actually, the design is very primitive at the moment and very likely to be incorrect. To refine it and refactor, we require more information from the task specifier. The task is finished. Now, you can reintegrate your branch into master and return the ticket to whoever assigned it to you. His task now is to find other people who will be able to resolve the puzzles we just created. Every puzzle created now will produce other puzzles, which will be resolved by other people. Consequtly, our simple one-hour task can potentially generate hundreds of other tasks, which may take days or even years to complete. Nevertheless, your goal of working with your specific task is to finish it as soon as possible and reintegrate your branch into master . Best Practices There are a few simple rules that help you to place puzzles correctly. First, you should put your @todo annotations at the point where your code hits a stub. For example, in a unit test. You're implementing a test and it fails because the class has not yet been implemented. You skip the test with the @Ignore annotation and add a @todo puzzle to its Javadoc. Second, your puzzle should remain as near as possible to the code element that is hitting the stub. Say thay you have a unit test that has three test methods. All of them fail now because the class has not been implemented. The best approach would be to ignore every one of them and create three (!) puzzles. Each one of the puzzles should explain what you expect from the class and how it should be implemented. Third, be as descriptive as possible. Your puzzle will soon be a task definition for someone else. So, explain clearly what you expect the next person to implement, how to do it, which documentation to use and so on and so forth. There should be enough information present that the next person assigned to the puzzles is ables implement your required classes without additional input from you! BTW, puzzle collection process can be automated by means of our PDD Ruby gem . "},{"title":"First Post","url":"/2014/04/06/introduction.html","tags":[],"date":"2014-04-06 00:00:00 +0000","categories":[],"body":"This is the first post on my new blog. Therefore, it's not about anything in particular - just an introduction and my way of saying hello. This blog will be primarily about software development ideas. As my About Me page says, I'm passionate about software quality, and will write solely about my ideas and views on it. Anyway, welcome to my new blog. Together, let's see how this works out! :) ps. BTW, I purchased the Cambria font just for this new blog. It cost, €98. Nevertheless, I think its a good investment for this new venture. "},{"title":"Movies for Thanasis","url":"/2014/04/06/movies-for-thanasis.html","tags":["movies"],"date":"2014-04-06 00:00:00 +0000","categories":[],"body":"Sometime ago, I recommended a list of movies to a friend of mine after he told me was losing all interest in \"Hollywood.\" Level C titles are supposed to be impossible to understand unless you've seen (and understood) their prequels -- listed in sections A and B. So, start browsing the lists in sections A and post your comments if you have any. :) Level A True Romance (1993) Pulp Fiction (1994) Kill Bill (2003) Doberman (1997) La fille sur le pont (1999) Irreversible (2002) Fear and Loathing in Las Vegas (1998) Perdita Durango (1997) Golden Balls (1993) The Million Dollar Hotel (2000) Y Tu Mamá También (2001) Reservoir Dogs (1992) Trainspotting (1996) Fight Club (1999) Arizona Dream (1992) Black Cat, White Cat (1998) Buffalo '66 (1998) Jamon Jamon (1992) Natural Born Killers (1994) Thursday (1998) Bullet (1996) Level B Delicatessen (1991) Bernie (1996) Hardmen (1996) Revolver (2005) Science of Sleep (2006) Cashback (2006) El Crimen Perfecto (2004) El día de la bestia (1995) La comunidad (2000) The Happiness of the Katakuris (2001) 99 francs (2007) Combien tu m'aimes? (2005) Ying xiong (2002) Brutti, sporchi e cattivi (1976) Level C What Just Happened (2008) Happiness (1998) Before the Devil Knows You Are Dead (2007) No Country for Old Men (2007) A Serious Man (2009) "},{"title":"Phantomjs as an HTML Validator","url":"/2014/04/06/phandom.html","tags":["phandom","phantomjs","testing"],"date":"2014-04-06 00:00:00 +0000","categories":[],"body":" I created phandom.org a few months ago, but yesterday finally found the time to make some needed changes to it. So, now is a good time to explain how I'm using Phandom in some of my unit tests. Before I get started, though, I should say a few words about phantomjs , which is a JavaScript interface for WebKit. WebKit, on the other hand, is a web browser without a user interface. WebKit is a C++ library that enables manipulation of HTML content, through DOM calls. For example, this is a simple JavaScript located code in example.js : 1 2 3 4 5 6 7 8 var page = require ( 'webpage' ). create (); page . open ( 'http://google.com' , function () { console . log ( 'loaded!' ); phantom . exit ( 0 ); } ); We run phantomjs from the command line with the following code: $ phantomjs example.js Phantomjs creates a page object (provided by webpage module inside phantomjs), and then asks it to open() a Web page. The object communicates with WebKit and converts this call into DOM instructions. After which, the page loads. The phantomjs engine then terminates on line 6. WebKit renders a web page with all neccessary components such as CSS, JavaScript, ActionScript, etc, just as any standard Web browser would. So far so good, and this is the traditional way of using phantomjs. Now, on to giving you an idea of how Phandom (which stands for \"PhantomJS DOM\") works inside Java unit tests: To test this, let's give phantomjs an HTML page and ask him to render it. When the page is ready, we'll ask phantomjs to show us how this HTML looks in WebKit. If we see the elements we need and desire, — we're good to go. Let's use the following example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import com.rexsl.test.XhtmlMatchers ; import org.hamcrest.MatcherAssert ; import org.phandom.Phandom ; public class DocumentTest { @Test public void rendersValidHtml () { Document doc = new Document (); // This is the method we're testing. It is supposed // to return a valid HTML without broken JavaScript // and with all required HTML elements. String html = doc . html (); MatcherAssert . assertThat ( XhtmlMatchers . xhtml ( new Phandom ( html ). dom ()), XhtmlMatchers . hasXPath ( \"//p[.='Hello, world!']\" ) ); } } When we use the above code, here is what happens. First, we get HTML html as a String from doc object, and then pass it to Phandom as an argument. Then, on line 13, we call the Phandom.dom() method to get an instance of the class org.w3c.dom.Document . If our HTML contains any broken JavaScript code, method dom() produces a runtime exception and the unit test faila. If HTML is clean and WebKit is able to render it without problems, the test passes. I'm using this mechanism in a few different projects,and it works quite well. Therefore, I highly recommend it. Of course, you shouldn't forget that you must have phantomjs installed on your build machine. In order to avoid unit test failures when phantomjs is not available or present, I've created the following supplementary method: public class DocumentTest { @Test public void rendersValidHtml () { Assume . assumeTrue ( Phandom . installed ()); // the rest of the unit test method body... } } Enjoy and feel free to report any bugs or problems you encounter to: Github issues :) "},{"title":"Xembly, an Assembly for XML","url":"/2014/04/09/xembly-intro.html","tags":["xembly","xml","xsl","xsd"],"date":"2014-04-09 00:00:00 +0000","categories":[],"body":" I use XML in almost every one of my projects. And, despite all the fuss about JSON/YAML, I honestly believe that XML is one of the greatest languages ever invented. Also, I believe that the beauty of XML reveals itself when used in combination with related technologies. For example, you can expose your data in XML and render it for the end-user using XSL stylesheet . Another example would be when you validate the same data, before rendering, to ensure that the structure is correct. You can do this with the XSD schema. Alternatively, you can pick specific data elements from the entire document by using XPath queries. Essentially, these three technologies, XSL, XSD schema and XPath, are what makes XML so powerful. However, there can be times when XML falls short. For instance, imagine you have an existing document that needs to be modified just slightly. For example, let's use the following: <accounts> [...] <acc id= '34' > <name> Jeffrey </name> <balance> 305 </balance> </acc> <acc id= '35' > <name> Walter </name> <balance> 50090 </balance> </acc> [...] </accounts> The above code represents a list of accounts. Each account has its own id and several child elements. In our example, we need to find the account belonging to Jeffrey and increase its balance by 500 . How would we do this? Well, there are a few possible solutions: SAX-parse the document, change the balance and save the stream; DOM-parse it, find the element with XPath, change the value and then print it; apply a parametrized XSL stylesheet; apply XQuery small script to make changes All of these methods have their own drawbacks. However, all of them have one particular problem in common — they are very verbose. With each of the above methods, you need at least a page of code to perform this rather simple operation. Furthermore, if the logic of the operation becomes more complex, the amount of needed code grows much faster than you may expect. Simply put, XML lacks a tool for primitive data manipulations within a document. Perhaps, it is this shortcoming that makes XML unpopular with some. Anyway, here is a tool I created a few month ago: Xembly . It is an imperative language with a few simple directives and resembles Assembly in style. Thus, the name - Xembly. With Xembly, there are no loops, conditions or variables - just a sequence of directives with arguments. Let's create a simple example. Say, for instance, we want to add a new account number 36 to our list document. The code would look like: 1 2 3 4 5 6 7 8 XPATH '/ accounts '; ADD ' account '; ATTR ' id ' , ' 36 '; ADD ' name '; SET ' Donny '; UP ; ADD ' balance '; SET ' 3400 '; The above should be intuitively clear, but I'll explain just in case. First, the XPATH directive points us to the element found by the \"/accounts\" XPath query. This will be our root element. We assume here that it exists in the document. Therefore, if it is absent, our Xembly script will fail with a runtime exception. Next, the ADD directive on line 2 creates a new XML element without any children or attributes. Then, the ATTR directive sets an attribute for this element. The code then adds the new child element name and sets its text value to \"Donny\" using the SET directive. Finally, we move our pointer back to account element using UP , add the balance child element and set its value to \"3400\" . Our balance changing task can be expressed in Xembly with the following code: XPATH '/ accounts / account [ name =\" Jeffrey \"]/ balance '; XSET ' . + 500 '; The XSET directive sets the element text value, similar to SET , but calculates it beforehand using the provided XPath expression . + 500 . Xembly performs all manipulations through DOM. Consequently, Xembly can be implemented inside any language that has a built-in DOM implementation. In the meantime, there is only one implementation of Xembly language — in Java. Here is how it works: 1 2 3 4 5 6 7 Iterable < Directive > directives = new Directives () . xpath ( \"/accounts\" ) . add ( \"account\" ) . attr ( \"id\" , \"36\" ) . add ( \"name\" ). set ( \"Donny\" ). up () . add ( \"balance\" ). set ( \"3400\" ); new Xembler ( directives ). apply ( document ); In this snippet, I'm using a supplementary script builder, Directives , which enables generation of directives in a fluent way. Then, I use Xembler class, which is similar to \"assembler\", to apply all specified directives to the document object of class org.w3c.dom.Document . Additionally, Xembly can be used to build XML documents from scratch and as a replacement for traditional DOM building. A quick example: System . out . println ( new Xembler ( new Directives (). add ( \"html\" ) . add ( \"head\" ) . add ( \"title\" ) . set ( \"Hello, world!\" ) ). xml () ); The above snippet produces the following output: <html> <head> <title> Hello, world! </title> </head> </html> For me, this appears to be more simple and compact. As usual, your bug reports and suggestions are always welcomed. Please send to Github issues :) "},{"title":"How much do you pay per line of code?","url":"/2014/04/11/cost-of-loc.html","tags":["xdsd","mgmt"],"date":"2014-04-11 00:00:00 +0000","categories":["best"],"body":"Yes, I know, \"line of code\" (LoC) is a very wrong metric . There are tons of articles written about it, as well as famous books. However, I want to compare two projects in which I have participated recently and discuss some very interesting numbers. Project #1: Traditionally Co-located The first project I was apart of was performed by a traditionally co-located group of programmers. There were about 20 of them (I'm not counting managers, analysts, product owners, SCRUM masters, etc.) The project was a web auctioning site with pretty high traffic numbers (over two million page views per day). The code base size was about 200k lines, of which 150k was PHP, 35k JavaScript and the remainder CSS, XML, Ruby, and something else. I'm counting only non-empty and non-comment lines of code, using cloc.pl . It was a commercial project, so I can't disclose its name. Brazil (1985) by Terry Gilliam The team was co-located in one office in Europe where everybody was working \"from nine 'til five\". We had meetings, lunches, desk-to-desk chats and lots of other informal communications. All tasks were tracked in JIRA. Project #2: Extremely Distributed The second project was an open source Java product, developed by an extremely distributed team of about 15 developers. We didn't have any chats or any other informal communications. We discussed everything in Github issues. The code base was significantly smaller with only about 30k lines, of which about 90% was Java and the rest in XML. Shaolin Temple (1982) by Chang Hsin Yen Maturity of Development Both projects hosted their code bases on Github. Both teams were developing in feature branches - even for small fixes. Both teams used build automation, continuous integration, pre-flight builds, static analysis and code reviews. This indicates the maturity of the project teams. Both projects satisfied the requirements of their users. I'm mentioning this to emphasize that both projects produced valuable and useful lines of code. There was no garbage and almost no code duplication . Show Me the Money In both projects, my role was called that of lead architect, and I know their economics and financials. Besides that, I had access to both Git repositories, so I can measure how many new lines (or changed lines) were introduced by both teams in, say, a three-month period. Now, let's see the numbers. The first project (the one that was co-located) was paying approximately €50,000 annually to a good developer, which was about $5,600 per month or $35 per hour. The second one (the extremely distributed project) was paying $20-35 per hour, for completed tasks only according to one of the principles of XDSD . The first one, in three months, produced 59k new lines and removed 29k in changes in the master branch, which in totals 88k lines of code. The project resulted in about 10,000 man hours to produce these lines (20 programmers, three months, 170 working hours per month) — which equates to about $350k. Therefore, the project cost a whopping $3.98 per line The second project, in the same three month period, produced 45k new lines and removed 9k, which comes to 54k in all. To complete this work, we spent only $7k (approximately 350 working hours in 650 tasks). Thus, the project costs merely: ¢13 per line This also means that programmers were writing approximately 270 lines per hour or over 2,000 per day. The Mythical Man-Month talks about 10 lines per day, which is 200 times less than we saw in our project. $350k vs $7k, $3.98 vs ¢13? What do you think? How to Validate the Numbers? If you're curios, I'm using this script to get the numbers from Git: 1 2 git log \"--since=3 months\" --pretty = tformat: --numstat \\ | gawk '{ add += $1; subs += $2; } END { printf \"added: %s removed: %s\\n\",add,subs,loc }' - You can validate the numbers for the second project here on Github: jcabi/jcabi-github . Conclusion What I'm trying to express with these numbers is that distributed programming is much more effective, money-wise, than a co-located team. Again, I can hear you saying that \"line of code\" is not a proper metric. But, come on, $0.13 vs. $3.98? Thirty times more expensive? The Big Lebowski (1998) by Joel Coen It's not about metrics any more. It's about preventing wasteful man hours and the huge waste of money that comes with them? Can We Do the Same? Of course, the same results can't be achieved by just telling your programmers to work from home and never come to the office. XDSD is not about that. XDSD is about strict quality principles, which should be followed by the entire team. And when these principles are in place — you pay thirty times less. By the way, this is what people say about their projects: $12–103: crazyontap.com $15–40: betterembsw.blogspot.nl over $5: joelonsoftware.com What are your numbers? Please post your comments below. "},{"title":"Fluent Java HTTP Client","url":"/2014/04/11/jcabi-http-intro.html","tags":["jcabi","http","java"],"date":"2014-04-11 00:00:00 +0000","categories":["best"],"body":" In the world of Java, there are plenty of HTTP clients from which to choose. Nevertheless, I decided to create a new one because none of the other clients satisfied fully all of my requirements. Maybe, I'm too demanding. Still, this is how my jcabi-http client interacts when you make an HTTP request and expect a successful HTML page in return: 1 2 3 4 5 6 7 8 String html = new JdkRequest ( \"https://www.google.com\" ) . uri (). path ( \"/users\" ). queryParam ( \"id\" , 333 ). back () . method ( Request . GET ) . header ( \"Accept\" , \"text/html\" ) . fetch () . as ( RestResponse . class ) . assertStatus ( HttpURLConnection . HTTP_OK ) . body (); I designed this new client with the following requirements in mind: Simplicity For me, this was the most important requirement. The client must be simple and easy to use. In most cases, I need only to make an HTTP request and parse the JSON response to return a value. For example, this is how I use the new client to return a current EUR rate: 1 2 3 4 5 6 String rate = new JdkRequest ( \"http://www.getexchangerates.com/api/latest.json\" ) . header ( \"Accept\" , \"application/json\" ) . fetch () . as ( JsonResponse . class ) . json (). readArray (). getJsonObject ( 0 ) . getString ( \"EUR\" ); I assume that the above is easy to understand and maintain. Fluent Interface The new client has to be fluent, which means that the entire server interaction fits into one Java statement. Why is this important? I think that fluent interface is the most compact and expressive way to perform multiple imperative calls. To my knowledge, none of the existing libraries enable this type of fluency. Testable and Extendable I'm a big fan of interfaces, mostly because they make your designs both cleaner and highly extendable at the same time. In jcabi-http , there are five interfaces extended by 20 classes. Request is an interface, as well as Response , RequestURI , and RequestBody exposed by it. Use of interfaces makes the library highly extendable. For example, we have JdkRequest and ApacheRequest , which make actual HTTP calls to the server using two completely different technologies: (JDK HttpURLConnection and Apache Http Client, respectively). In the future, it will be possible to introduce new implementations without breaking existing code. Say, for instance, I want to fetch a page and then do something with it. These two calls perform the task differently, but the end results are the same: String uri = \"http://www.google.com\" ; Response page ; page = new JdkRequest ( uri ). fetch (); page = new ApacheRequest ( uri ). fetch (); XML and JSON Out-of-the-Box There are two common standards that I wanted the library to support right out of the box. In most cases, the response retrieved from a server is in either XML or JSON format. It has always been a hassle, and extra work, for me to parse the output to take care of formatting issues. jcabi-http client supports them both out of the box, and it's possible to add more formats in the future as needed. For example, you can fetch XML and retrieve a string value from its element: String name = new JdkRequest ( \"http://my-api.example.com\" ) . header ( \"Accept\" , \"text/xml\" ) . fetch () . as ( XmlResponse . class ) . xml (). xpath ( \"/root/name/text()\" ). get ( 0 ); Basically, the response produced by fetch() is decorated by XmlResponse . This then exposes the xml() method that returns an instance of the XML interface. The same can be done with JSON through the Java JSON API ( JSR-353 ). None of the libraries that I'm aware of or worked with offer this feature. Immutable The last requirement, but certainly not the least important, is that I need all interfaces of the library to be annotated with @Immutable . This is important because I need to be able to encapsulate an instance of Request in other immutable classes. "},{"title":"PDD by Roles","url":"/2014/04/12/puzzle-driven-development-by-roles.html","tags":["xdsd","pdd","mgmt"],"date":"2014-04-12 00:00:00 +0000","categories":[],"body":"In this post, I'll try to walk you through a project managed with the spirit of Puzzle Driven Development (PDD). As I do this, I will attempt to convey typical points of view of various project members. Basically, there are six key roles in any software team: Project Manager — assigns tasks and pays on completion System Analyst — documents the product owner's ideas Architect — defines how system components interact Designer — implements most complex components Programmer — implements all components Tester — finds and reports bugs Everybody, except the project manager, affects the project in two ways: they fix it and they break it at the same time. Let me explain this with a simple example. \"Fix and Break\" Let's assume, for the sake of simplicity, that a project is a simple software tool written by me for a close friend. I created the first draft version 0.0.1 and delivered it to him. For me, the project is done. I've completed the work, and hopefully will never have to return to it again. However, the reality of the project is very different. In just a few hours, I receive a call from my friend saying that a he's found a few bugs in the tool. He is asking me to fix them. Now, I can see that the project is not done. In fact, it's broken. It has a few bugs in it, which means a few tasks to complete. I'm going to fix the project, by removing the bugs. I implement a new version of the software, name it 0.0.2 and ship it to my friend. Again, I believe my project is finished. It is fixed and should be closed. This scenario repeats itself again and again until my friend stops calling me. In other words, until he stops breaking my project. It is obvious that the more my friend breaks my project, the higher the quality of the software delivered ultimately at the end. Version 0.0.1 was just a very preliminary version, although I considered it final at the time I released it. In a few months, after I learn of and fix hundreds of bugs, version 3.5.17 will be much more mature and stable. This is the result of this \"fix and break\" approach. The diagram shows the relation between time and mess in the project. The bugs my friend is reporting to me are breaking the project, increasing its instability (or simply its messiness). New versions I release resolve the bugs and are fixing the project. Your Github commit dynamics should resemble this graph, for example: When the project starts, its messiness is rather low, and then it starts to grow. The messiness then reaches its peak and starts to go down. Project Manager The job of a project manager is to do as much as possible to fix the project. He has to use the sponsor's time and money in order to remove all bugs and inconsistencies and return the project back to a \"fixed\" state. Pulp Fiction (1994) by Quentin Tarantino When I say \"bugs,\" I mean more than just software errors but also: unclear or ambiguous requirements features not yet implemented functional and non-functional bugs lack of test coverage unresolved @todo markers lack of risk analysis etc. The project manager gives me tasks that he wants done in order to fix and stabilize the project to return it back to a bug-free state. My job, as a member of a software team, is to help him perform the needed fixes and, at the same time, do my best to break the project! In the example with my friend, he was breaking the project constantly by reporting bugs to me. This is how he helped both of us increase the final quality of the product. I should do the same and always try to report new bugs when I'm working on some feature. I should fix and break at the same time. Now let's take a closer look at project roles. System Analyst A product owner submits an informal feature request, which usually starts with \"it would be nice to have...\" I'm a system analyst and my job is to translate owner's English into formal specifications in the SRS, understandable both by programmers and myself. It's not my responsibility to implement the feature. Arizona Dream (1992) by Emir Kusturica My task is complete when a new version of the SRS is signed by the Change Control Board. I'm an interpreter for the product owners, translating from their language to formal language needed in the SRS document. My only customer is the product owner. As soon as she closes the feature request, I'll be paid. Besides feature requests from product owners, I often receive complaints about the quality of the SRS. The document may not be clear enough for some team members. Therefore, it's my job to resolve clarity problems and fix the SRS. These team members are also my customers. When they close their bug reports, I'll be paid. In both cases (a feature request or a bug,) I can make changes to the SRS immediately - if I have enough time. However, it's not always possible. I can submit a bug and wait for its resolution; but, I don't want to keep my customers waiting. This is where puzzle driven development helps me. Instead of submitting bug reports, I add \" TBD \" puzzles in the SRS document. The puzzles are informal replacements of normally very strict formal requirements. They satisfy my customer, since they are in plain English, and are understandable by technical people. Thus, when I don't have time, I don't wait. I change the SRS using TBDs at points where I can't create a proper and formal description of the requirements or simply don't know what to write exactly. Architect Now, I'm the architect, and my task is to implement a requirement, which has been formally specified in the SRS. PM is expecting a working feature from me, which I can deliver only when the architecture is clear and classes have been designed and implemented. The Science of Sleep (2006) by Michel Gondry Being an architect, I'm responsible for assembling all of the components together and making sure they fit. In most cases, I'm not creating them myself, but I'm telling everybody how they should be created. My work flow of artifacts is the following: directed graph digraph G { SRS -> UML; UML -> \"Source code\"; } G SRS SRS UML UML SRS->UML Source code Source code UML->Source code I receive requirements from the SRS, produce UML diagrams and explain to designers how to create source code according to my diagrams. I don't really care how source code is implemented. I'm more concerned with the interaction of components and how well the entire architecture satisfies functional and non-functional (!) requirements. My task will be closed and paid when the system analyst changes its state to \"implemented\" in the SRS. The system analyst is my only customer. I have to sell my solution to him. Project manager will close my task and pay me when system analyst changes the status of the functional requirement from \"specified\" to \"implemented\". The task sounds big, and I have only half an hour. Obviously, puzzle driven development should help me. I will create many tickets and puzzles. For example: SRS doesn't explain requirements properly Non-functional requirements are not clear UML diagrams are not clear enough Components are not implemented Build is not automated Continuous integration is not configured Quality of code is not under control Performance testing is not automated When all of my puzzles are resolved, I can get back to my main task and finish feature implementation. Obviously, this may take a long time - days or even weeks. But, the time cost of the main task is less than an hour. What is the point of all this hard work? Well, it's simple; I'll earn my hours from all the bugs reported. From this small half-an-hour task, I will generate many tickets, and every one of them will give me extra cash. Designer and Programmer The only real differences between designer and programmer are the complexity of their respective tasks and the hourly rates they receive. Designers usually do more complex and higher level implementations, while programmers implement all low-level details. Pulp Fiction (1994) by Quentin Tarantino I'm a programmer and my task is to implement a class or method or to fix some functional bug. In most cases, I have only half an hour available. And, most tasks are bigger and require more time than that. Puzzle driven development helps me break my task into smaller sub-tasks. I always start with a unit test. In the unit test, I'm trying to reproduce a bug or model the feature. When my test fails, I commit it and determine the amount of time I have left. If I still have time to make it pass — I do it, commit the changes and report to the project manager. If I don't have time to implement the fix, I mark pieces of code that don't already have @todo markers, commit them and report to the project manager that I've finished. As you see, I'm fixing the code and breaking it at the same time. I'm fixing it with my new unit test, but breaking it with @todo puzzles. This is how I help to increase the overall quality of the project - by fixing and breaking at the same time. Tester I'm a tester and my primary motivation is to find bugs. This may be contradictory to what you've heard before; but in XDSD , we plan to find a certain amount of bugs at every stage of the project. Fear and Loathing in Las Vegas (1998) by Terry Gilliam As as a tester, I receive tasks from my project manager. These tasks usually resemble \"review feature X and find 10 bugs in it\". The project manager needs a certain number of bugs to be found in order to fix the project. From his point of view, the project is fixed when, say, 200 bugs have been found. That's why he asks me to find more. Thus, to respond to the request, i find bugs to do my part in regard to the \"fixing\" part of the bigger picture. At the same time, though, I can find defects on my own and report them. This is the \"breaking\" part of my mission. "},{"title":"Bugs Are Welcome","url":"/2014/04/13/bugs-are-welcome.html","tags":["testing","xdsd","mgmt"],"date":"2014-04-13 00:00:00 +0000","categories":[],"body":"The traditional understanding of a software defect (aka \"bug\") is that it is something negative and want to avoid in our projects. We want our projects to be \"bug-free.\" Our customers are asking us to develop software that doesn't have bugs. And, we, as users, expect software to work without bugs. Charlie and the Chocolate Factory (2005) by Tim Burton But, let's take a look at bugs from a different angle. In XDSD , we say that \"bugs are welcome.\" This means we encourage all interested parties to find bugs and report them. We want our team to see bugs as something that we need in our projects. Why? Because we understand that there are two categories of bugs: visible and hidden. The more bugs that become visible, the more of them we can fix. More fixed bugs means fewer to annoy our users. By discovering bugs we make them visible. This is the primary job of a software tester — to make bugs visible. Obviously, their visibility affects the quality of the product in a positive way. This is because we can fix them before our users start complaining. In order to motivate all team members to make more bugs visible, we pay for their discovery. In XDSD projects, we are pay 15 minutes for every bug found (no matter who finds them and where.) We Plan Bugs We go even further. At XDSD , we plan for a number of hidden bugs in every project. We do this by using our experience with previous projects and expert judgment. Let's say we're starting to develop a web system, which is similar to the one we worked on last year. We know that in the previous project our users and team together reported 500 bugs. It's logical to assume that the new project will have a similar number of bugs. Thus, our task is to make those 500 bugs visible before they hit the production platform and our users call us to complain about them. Therefore, we're making it one of the project goals: \"discover 500 bugs.\" Of course, our estimate may be wrong. Nevertheless, we have historical records for a few dozen projects, and in all of them the number is close to 500. So, finding 500 bugs in a project is usually a reality — we can use it as a target. What Is a Bug? Let us try to define a bug (or software defect) in a non-ambiguous manner. Something can be reported as a bug and subsequently paid for iff: it is reproducible it refers to functionality already implemented is can be fixed in a reasonable amount of time it doesn't duplicate a bug already reported Reproducibility of a bug is very important. Consequently, it is the responsibility of a bug reporter to make sure the bug is reproducible. Until it is proven that the bug can be reproduced — it's not a bug for which payment can be made. A bug is not a task; it has to refer to an existing functionality. Additionally, an explanation must exist for how and when the existing functionality doesn't work as expected. "},{"title":"No Obligations","url":"/2014/04/13/no-obligations-principle.html","tags":["xdsd","mgmt"],"date":"2014-04-13 00:00:00 +0000","categories":[],"body":"It is a very common problem in project management — how to make team members more responsible and avoid micro management ? We start with creating plans, drawing Gantt charts, announcing milestones, motivating everybody and promising big bonuses on success. Excuses Then everybody begins working and we start hearing excuses: \"The task is not yet ready. I was doing something else\" \"May I take a day off? Tomorrow is my birthday?\" \"May I skip the unit test because I don't know how to fix it?\" \"I don't know how to do it, can someone help me?\" \"I tried, but this doesn't work; what can I do?\" \"This installation requires all of my time. I can't finish the task\" With excuses, team members transfer responsibility back to the project manager. There was a very famous article \"Management Time: Who's Got the Monkey?\" published in the Harvard Business Review about this very subject. I recommend that you read it. Its authors present problems as monkeys sitting on our shoulders. When the project manager assigns a task to a programmer — he moves the monkey from his shoulders to the programmer's shoulders. The programmer usually presents the excuse \"I don't know what to do\". Now the monkey is back on the shoulders of the managers. The goal of the manager is to send the monkey back to make it the programmer's problem again. One of traditional way of transferring responsibility back to team members is to become an aggressive manager. For instance the manager may say, \"You have a birthday tomorrow? I don't care, you still have to meet your deadline\" or \"You don't know how to fix the unit test? Not my problem, it should be fixed by tomorrow,\" etc. We've all seen multiple examples of that type of aggressive management. Personally, I find this management style extremely annoying and destructive for the project. The project environment becomes very unhealthy and good people usually end up leaving. Another traditional management method is micro-management. This results when the project manager checks task statuses every few hours and tells people what to do and how to handle problems. Needless to say, this management style ruins the team and causes good people to leave even faster. However, in order to keep the project on track and meet all milestones, responsibility must be on the shoulders of the team members. They should be responsible for their own tasks and report back to the project manager when they are finished with their jobs. The Big Lebowski (1998) by Joel Coen Implementation problems should be solved by team members on their own. So, how do we accomplish this in XDSD ? I Owe You Nothing In XDSD , there is the first fundamental principle that says everybody should be paid for deliverables. Based on this idea, we can go even further and declare a \"No Obligations\" principle. In essence, for every team member, it says: if you don’t like the task assigned to you, don’t have time or you’re simply not in the mood — don't do it. You have no obligation to do anything. You're free to reject every second task that a project manager gives to you or even all of them. On the other hand, though, the project manager is not obliged to keep a task assigned to you for longer than 10 days (we think that this time frame is logical). If you get a task, and don't deliver within ten days, the project manager can take it away and pay you nothing — no matter how much time you invested in the task already or the reasons for your failure to complete it. Where Are The Monkeys Now? This principle helps us to separate responsibilities between project manager and team members. The manager is responsible for finding the right people and assigning them appropriate tasks. There is a problem with the project manager's management style if he receives too many rejections from the team. On the other hand, his team members are responsible for their tasks and should not provide excuses for non-completion. Well, team members can make excuses, but they won't change anything. No matter what their excuses are, the deliverables will be purchased only from members who manage to complete their tasks on time. How Does This Affect Me? When you're working with XDSD -inspired project, you should always keep the \"No Obligations\" principle in mind. You should start a task only if you're sure that you can finish it in a few days. You should pursue your tasks and control deadlines yourself. The project manager will not ask you for status updates, as usually happens with traditional projects. He will just take the task away from you after ten days if you don’t finish it. To avoid that, you should control your tasks and their deadlines. With every task, try to be as lazy as possible and cut every corner you can. The smaller the amount of work you perform on a task, the easier it will be to deliver it and pass all quality controls. Always remember that your efforts are not appreciated — only the deliverables matter. "},{"title":"Object-Oriented DynamoDB API","url":"/2014/04/14/jcabi-dynamo-java-api-of-aws-dynamodb.html","tags":["dynamodb","aws","java","jcabi"],"date":"2014-04-14 00:00:00 +0000","categories":[],"body":" I'm a big fan of cloud computing in general and of Amazon Web Services in particular. I honestly believe that in a few years big providers will host all, or almost all, computing and storage resources. When this is the case, we won't have to worry too much anymore about downtime, backups and system administrators. DynamoDB is one of the steps towards this future. This looks cool - jcabi-dynamo - a #Java Object layer atop the #DynamoDB SDK - http://t.co/khRFR2joKX #aws — Jeff Barr (@jeffbarr) September 19, 2013 DynamoDB is a NoSQL database accessible through RESTful JSON API. Its design is relatively simple. There are tables, which basically are collections of data structs, or in AWS terminology, \"items.\" Every item has a mandatory \"hash,\" an optional \"range\" and a number of other optional attributes. For instance, take the example table depts : +------+--------+---------------------------+ | dept | worker | Attributes | +------+--------+---------------------------+ | 205 | Jeff | job=\"manager\", sex=\"male\" | | 205 | Bob | age=43, city=\"Chicago\" | | 398 | Alice | age=27, job=\"architect\" | +------+--------+---------------------------+ For Java, Amazon provides an SDK , which mirrors all RESTful calls to Java methods. The SDK works fine, but is designed in a pure procedural style. Let's say we want to add a new item to the table above. RESTful call putItem looks like (in essence): putItem: tableName: depts item: dept: 435 worker: \"William\" job: \"programmer\" This is what the Amazon server needs to know in order to create a new item in the table. This is how you're supposed to make this call through the AWS Java SDK: 1 2 3 4 5 6 7 8 9 10 11 12 13 PutItemRequest request = new PutItemRequest (); request . setTableName ( \"depts\" ); Map < String , AttributeValue > attributes = new HashMap <>(); attributes . put ( \"dept\" , new AttributeValue ( 435 )); attributes . put ( \"worker\" , new AttributeValue ( \"William\" )); attributes . put ( \"job\" , new AttributeValue ( \" programmer )); request . setItem ( attributes ); AmazonDynamoDB aws = // instantiate it with credentials try { aws . putItem ( request ); } finally { aws . shutdown (); } The above script works fine, but there is one major drawback — it is not object oriented. It is a perfect example of an imperative procedural programming . To allow you to compare, let me show what I've done with jcabi-dynamo . Here is my code, which does exactly the same thing, but in an object-oriented way: 1 2 3 4 5 6 7 8 Region region = // instantiate it with credentials Table table = region . table ( \"depts\" ); Item item = table . put ( new Attributes () . with ( \"dept\" , 435 ) . with ( \"worker\" , \"William\" ) . with ( \"job\" , \"programmer\" ) ); My code is not only shorter, but it also employs encapsulation and separates responsibilities of classes. Table class (actually it is an interface internally implemented by a class) encapsulates information about the table, while Item encapsulates item details. We can pass an item as an argument to another method and all DynamoDB related implementation details will be hidden from it. For example, somewhere later in the code: void sayHello ( Item item ) { System . out . println ( \"Hello, \" + item . get ( \"worker\" )); } In this script, we don't know anything about DynamoDB or how to deal with its RESTful API. We interact solely with an instance of Item class. By the way, all public entities in jcabi-dynamo are Java interfaces. Thanks to that, you can test and mock the library completely. Let's consider a more complex example, which would take a page of code if we were to use a bare AWS SDK. Let's say that we want to remove all workers from our table who work as architects: Region region = // instantiate it with credentials Iterator < Item > workers = region . table ( \"depts\" ). frame () . where ( \"job\" , Condition . equalTo ( \"architect\" )); while ( workers . hasNext ()) { workers . remove (); } jcabi-dynamo has saved a lot of code lines in a few of my projects. You can see it in action at rultor-users . The library ships as a JAR dependency in Maven Central (get its latest versions from Maven Central ): <dependency> <groupId> com.jcabi </groupId> <artifactId> jcabi-dynamo </artifactId> </dependency> "},{"title":"Definition Of Done","url":"/2014/04/15/definition-of-done.html","tags":["mgmt","xdsd"],"date":"2014-04-15 00:00:00 +0000","categories":[],"body":"Definition of Done (DoD) is a key definition used in Scrum and the one we also use in XDSD . DoD is an exit criteria of a simple atomic task and answers the question:\"am I done with this task?\" Moreover, DoD answers the question: \"will I be paid for the task?\" In XDSD , the definition of \"done\" is very simple — the task is done iff its author accepts the deliverables. At XDSD , our first and most important principle states that someone is paid only when he provides deliverables. Combining the definition of done and the principle of paying only for deliverables provides us a very important conclusion: we do not pay for un-finished tasks. Every task has its own time budget. Regardless of the number of people who worked on a task previously, only the last one — the one who managed to provide a working deliverable — receives payment. To better understand this principle, you should read: No Obligations Principle . Your goal as a developer working on a task should be to close it and receive payment as soon as possible. To that end, here are few things that can help you complete tasks and receive payments without too much frustration: Don't even start a task unless you're sure you can finish it; Ask any and all questions of the task author in advance (before beginning work); Don't assume anything — ask if you're not sure; Stay after the author to close tasks — be aggressive; Don't expect any help from anyone — you're on your own; Ask about payment if you don’t receive it automatically after an author closes your task(s) It is important to remember that, as a developer, it is your responsibility to ensure that tasks are closed and you receive payment. "},{"title":"Github Guidelines","url":"/2014/04/15/github-guidelines.html","tags":["github","xdsd"],"date":"2014-04-15 00:00:00 +0000","categories":[],"body":"This manual explains the workflow used when working with a XDSD project hosted on Github.com . You start when a Github issue is assigned to you. Next, you will receive a message from a project manager containing the issue number, title, description and its budget in hours (usually 30 minutes). If you don't agree with the budget allotment, don't hesitate to ask for an increase. As soon as you are comfortable with the budget and understand the scope of the work, say so in a reply to the ticket and start working. Be aware that you won't be paid for time spent above and beyond the allotted time budget. 1. Fork Even though you're part of the development team, you don't have write access to the repository in Github. Consequently, to contribute changes, you should fork the repository to your own Github account (create a private copy of it), make needed changes and then submit them for review using \"a pull request.\" After you submit a pull request review, the repository owner approves your changes by merging them into the main repository. This is how we protect the main development stream against accidental damage. This article explains how to fork a repository: fork-a-repo This one explains how to download and install Github on your computer: set-up-git Finally, don't forget to add your private SSH key to Github: generating-ssh-keys 2. Branch Once you have a forked our repository to your account, clone it to your computer, and then check out the master branch. For example: 1 2 git clone git@github.com:yegor256/jcabi.git git checkout master Now, it's time to branch ( 123 is the number of the Github issue you're going to work with, and the name of the branch): 1 git checkout -b 123 By convention, we use the same names for the branch and issue you're working with. 3. Changes All task-related questions should be discussed in the Github issue. For Github issues, we don't use emails, Skype, phone calls or meetings. All questions should be asked directly in the Github issues. Don't hesitate to submit new issues if something is not clear or you need help. It's a very common to receive a task that you may not be able to implement. Don't panic. This usually happens when you first just join a project and don't yet have enough information. If this happens, don't try to figure out a problem or issue by yourself. The rule of thumb for this type of situation is: \"if something is not clear, it is our fault, not yours.\" Therefore, if you don’t understand the project design, it is the fault of the project designer. Submit a bug report requesting an explanation of a design concept. You will be paid for this report, and the information you receive in the reply will be shared between all other developers. Read this article: Bugs Are Welcome . Don't expect anyone to help you. Your only source of help is the source code itself. If the code doesn't explain everything you need to know — it is a bug, which must be reported. 4. Commit and Push Make any needed changes using a text editor or IDE. It's a good practice to commit changes as soon as you make them. Don't accumulate large numbers of changes too long before committing them. 1 2 git commit -am '#123: the description of the changes' git push origin 123 If you have questions about the scope of work, post them in the Github issue and wait for an answer. If you think that the existing code needs improvements, don't hesitate to submit a new issue to Github. Don't try to fix all problems in one branch; let other programmers take care of them. 5. Pull Request Create a pull request in Github using the process in the following article: using-pull-requests Post its number in the original issue and wait for feedback. 6. Code Review After a while, your pull request will be reviewed by someone from the project team. In many cases, you may receive a few negative comments, and you will have to fix any and all issues associated with them. Your pull request won't be merged into master branch , until your changes satisfy the reviewer. Be patient with the reviewer, and listen to him carefully. However, don't think that your reviewer is always right. If you think that your changes are valid, insist that someone else review them. 7. Merge When everything looks good to the reviewer, he will inform our automated merge bot. The automated merge bot will then select your pull request and try to merge it into master branch. For various reasons, this operation fails often. If the merge fails, regardless of the reason, it is your responsibility to make sure that your branch is merged successfully. If you can't merge a branch because of failures in tests not associated with your task, don't try to fix them yourself. Instead, report a problem as a new bug and wait for its resolution. Remember, until your branch is merged, you are not paid. 8. Payment Once your changes are merged, return to the Github issue and ask the author to close it. Once the issue is closed by a project manager, you will receive your payment within a few hours, through oDesk or PayPal. "},{"title":"How XDSD Is Different","url":"/2014/04/17/how-xdsd-is-different.html","tags":["xdsd","mgmt"],"date":"2014-04-17 00:00:00 +0000","categories":["best"],"body":"eXtremely Distributed Software Development, or XDSD for short, is a methodology that differs significantly from working in traditional software development teams. Most XDSD methods are so different (yet critical) that many newcomers get confused. This article should help you bootstrap once you join a project managed with by XDSD principles — either as a developer or a project sponsor. We Pay Only For Closed Tasks Unlike with many other projects, in XDSD , we pay only for closed tasks and the agreed upon time budget. Let me explain by example. Let's say, you are a Ruby programmer and you a get a new task that requires you to fix a broken unit test. The task has a time budget of 30 minutes, as is the case most of the time. Sometimes, though, tasks may have time budgets of fifteen minutes or one hour. In our example, we agree upon a contract rate of $50 per hour. With the broken test, you will receive $25 for completing the task — 30 minute tasked billed at $50 per hour. It does not matter how long it actually takes you to fix the test. Your actual time spent on the project may be five minutes or five hours. Nevertheless, you will receive compensation for 30 minutes of work only. If you fix the broken test in 5 minutes, you receive $25. If the task takes you an hour, or even a month, to complete, you still receive only $25. Furthermore, if you fail to fix the unit test and close the task altogether, you will receive no pay at all for the assignment. You can view more details about this principle in the following articles: No Obligations Principle or Definition of Done . Revolver (2005) by Guy Ritchie As mentioned above, this is one of the most important differences between XDSD and other methods. Many people get confused when they see this principle in action, and some leave our projects because of it. They simply are used to being paid by the end of the month — no matter how much work they actually deliver. In XDSD, we consider this type of approach very unfair. We feel that people who deliver more results should receive more cash. Conversely, those who don't deliver should get less. We Deliver Unfinished Components Since most of our tasks are half an hour in size, we encourage developers to deliver unfinished components. Read more about this concept in the article below: Puzzle Driven Development . No Informal Communications Unlike many other projects or teams you may have worked with, XDSD uses no informal communication channels. To clarify, we never use emails, we never chat on Skype and we don't do any meetings or phone calls. Additionally, XDSD maintains no type mailing list. Our only method of communication is a ticket tracking system (which in most projects consists of Github Issues .) Moreover, we discourage horizontal communications between developers regarding the scope of individual tasks. When assigned a task, your single and only point of contact (and your only customer) is the task author. You communicate with the author in the ticket to clarify task requirements. When the requirements of a task are clear — and you understand them fully — deliver the result to the author and wait for him to close the task. After the author closes the task, the project manager pays you. Goodfellas (1990) by Martin Scorsese We're very strict about this principle — no informal communications. However, it doesn't mean that we are not interested in your opinions and constructive criticism. Rather, we encourage everyone to submit their suggestions and bugs. By the way, we pay for bugs (see the next section for further details about bug reporting and payments.) Since we have no formal communications, members of project teams are not required to work at specific times. Instead, team members work at times convenient for them in their time zones. This includes weekdays and weekends. We Pay For Bugs Unlike many other software teams, XDSD welcomes bug reports in all our projects. Therefore, we ask for bugs openly and expect team members to report them. Review the following article for complete details on XDSD bug reporting: Bugs are welcome We expect everyone involved with a project to report every bug found. Additionally, we encourage team members to make suggestions. In XDSD, we pay team members for every properly reported bug. XDSD makes payments for reported bugs because we believe that the more of them we can find, the higher the quality of the end product. Some new developers are surprised when they receive tasks such as \"you must find 10 bugs in class A.\" Often, the natural reaction is to ask \"what if there are no bugs?\" However, we believe that any software product may have an unlimited amount of bugs; it is just a matter of expending the time and effort needed to discover them. Only Pull Request We never grant team member access to the master branch — no matter how long you work on a project. Consequently, you must always submit your changes through pull requests (most of our projects are done in Github .) We enforce this policy not because we don't trust our developers, but simply because we don't trust anyone :) Read this article: Master Branch Must Be Read-Only . No Compromises About Code Quality Before merge any changes to the master branch, we check the entire code base with unit tests and static analyzers. Unit testing is a very common component in modern software development, and one by which you should not be surprised. However, the strictness of static analysis is something that often frustrates XDSD newcomers, and we understand that. We pay much more attention to the quality and uniformity of our source code than most of our competing software development teams. Even more important is that we never make compromises. If your pull request violates even one rule of the static analyzer, it won't be accepted. And, it doesn't matter how small or innocent that violation may look. This merging process is fully automated and can't be bypassed. "},{"title":"Mocking of HTTP Server in Java","url":"/2014/04/18/jcabi-http-server-mocking.html","tags":["jcabi","http","mocking"],"date":"2014-04-18 00:00:00 +0000","categories":[],"body":" Recently, I explained a fluent Java HTTP client created (mostly) to make HTTP interactions more object-oriented than with other available clients,including: Apache Client , Jersey Client and plain old HttpURLConnection . This client ships in the jcabi-http Maven artifact. However, the client part is not the only benefit of using jcabi-http . Jcabi also includes a server component that can help you in unit and integration testing of your HTTP clients. Let me show you an example first. In the example, I'm using hamcrest for assertions. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 MkContainer container = new MkGrizzlyContainer () . next ( new MkAnswer . Simple ( \"hello, world!\" )) . start (); try { new JdkRequest ( container . home ()) . header ( \"User-agent\" , \"Myself\" ) . fetch () . assertBody ( Matchers . containsString ( \"hello\" )); } finally { container . stop (); } MkQuery query = container . take (); MatcherAssert . assertThat ( query . headers (). get ( \"User-agent\" ), Matchers . hasItem ( \"Myself\" ) ); Now, let's discover what happens here. In the first few lines, I create an instance of MkContainer , which literally has four methods: next(MkAnswer) , start() , stop() , and home() . It works as an HTTP server with a \"first-in-first-out\" queue for HTTP answers. We add answers, and the server returns them in response to HTTP requests. The server starts on start() call and stops on stop() . Its method home() returns a URL of its \"home page\". The server then binds itself to a randomly allocated TCP port. The container finds the first available and unoccupied port. In the example above, I added just one answer. This means that the container will reply only to the first HTTP request with that answer and that all consecutive requests will cause HTTP responses with status \"internal server error 500 .\" In lines 5 through 8, I make an HTTP request to the already started server. Also, I make an assertion that the body of the HTTP response contains the text \"hello\" . Obviously, this assertion will pass because the server will return \"hello, world!\" to my first request: new JdkRequest ( container . home ()) . header ( \"User-agent\" , \"Myself\" ) . fetch () . assertBody ( Matchers . containsString ( \"hello\" )); As you can see, I use container.home() in order to get the URL of the server. It is recommended that you allow the container to find the first unoccupied TCP port and bind itself to it. Nevertheless, if you need to specify your own port, you can do it with a one-argument method start(int) in MkContainer . I use try/finally to stop the container safely. In unit tests, this is not critical, as you can simplify your code and never stop the container. Besides, the container will be killed together with the JVM. However, for the sake of clarity, I would recommend you stop the container in the finally block. On line 12, I ask the stopped container to give me the first request it received. This mechanism is similar conceptually to the \"verify\" technology of mocking frameworks. For example, Mockito . MkQuery query = container . take (); MatcherAssert . assertThat ( query . headers (). get ( \"User-agent\" ), Matchers . hasItem ( \"Myself\" ) ); An instance of MkQuery exposes information about the query made. In this example, I get all headers of the HTTP request and making an assertion that the \"User-Agent\" header was there and had at least one value equal to \"Myself\" . This mocking technology is used actively in unit and integration tests of jcabi-github , which is a Java client to Github API. In its development, the technology is very important in checking which requests are being sent to the server and validating whether they comply with our requirements. Here, we are using jcabi-http mocking. As with the client, you need the jcabi-http.jar dependency (get its latest versions in Maven Central ): <dependency> <groupId> com.jcabi </groupId> <artifactId> jcabi-http </artifactId> </dependency> Besides the above, you need to add one more dependency, which is a Grizzly HTTP server. MkGrizzlyContainer is based on it. <dependency> <groupId> com.sun.grizzly </groupId> <artifactId> grizzly-servlet-webserver </artifactId> <scope> test </scope> </dependency> If you have any questions or suggestions, please submit them through Github issues . As always, bugs are welcome :) "},{"title":"How Hourly Rate Is Calculated","url":"/2014/04/20/how-hourly-rate-is-calculated.html","tags":["xdsd"],"date":"2014-04-20 00:00:00 +0000","categories":[],"body":"In XDSD , everyone — including project managers, analysts, programmers, and product owners — receives payments based on deliverables with agreed upon budgets. In the fhe first section of the article, How XDSD Is Different I explain exactly how this concept works. I don't explain in the article, though, how we decide which hourly rate is acceptable for each project participant. When new people come to us, usually they have some numbers in mind. They know how much they expect to make per week, per month or per day. We rarely negotiate the payment rates, but rather just accept reasonable offers. Nonetheless, every few months, we review payments rates and change them accordingly (increasing or decreasing them as appropriate). Further along in the article, is a list of factors that influence our decision making process regarding payment rates. However, before we get to the factors that influence our rate-setting decisions, it is important to mention that — unlike most other companies or software teams — we don't pay attention to the following: Your geographic location; Skills and experience listed in your CV; Amount of time already spent on our projects; Age, sex, nationality, religious beliefs, etc. The factors listed below, though, are indeed very important to us. They affect your \"overall score\" significantly and play a major part in decisions to decrease or increase a payment rate. After changing a payment rate, we don't negotiate it with the project member. Keep in mind that besides decreasing your hourly rate, a low overall score may affect the number of tasks you receive from us. The best developers receive most of the new tasks. So, continue reading, follow our principles and learn how to earn and enjoy higher rates :) Fast Delivery The faster you deliver on a task, the better. We track all your completed tasks and can calculate easily how many days it takes you, on average, to close tasks. To increase this metric, you should try to close all tasks as soon as possible to reduce your overall completion-time average. If you see that a specific task is not suitable for you, don't hold on to it. Instead, inform your project manager as soon as possible that you do not want to work on the task. After you inform the project manager, he will try find you something else more suitable. By the way, the best developers usually close their tasks in five calendar days (or less) on average. Past Due Tasks Though we encourage everyone to reject tasks they don't like, we are strongly against overdue tasks. Once you have started to work on a task, we expect you to finish it on time. Our No Obligation Principle gives our project managers freedom to take any task away from you if don’t complete it in a reasonable amount of time (ten days). Removal of tasks by project managers affects your overall score negatively. Nevertheless, even the best developers sometimes have overdue tasks, and we understand that it happens from time to time. However, our best developers they keep their number of overdue tasks to a minimum. A good rule of thumb for acceptable numbers in this area is about one overdue task per twenty completed successfully and on time. Complexity Every XDSD task has a project role assigned to it. The article, Puzzle Driven Development by Roles , lists the key roles we use in XDSD projects. Generally speaking, the higher the role, the higher the complexity of tasks assigned to it. Therefore, closing a task in an \"architect\" role is much more important than closing one as an \"implementer\" (or \"developer.\") The more tasks you close in your current role, the faster you will receive promotions and receive pay-rate increases. Very often, our developers work in a few roles at the same time. Lengthy Discussions We discourage long conversations on one task. The longer the discussions about a task, the longer it takes to complete — which lowers your quality as a developer. Ideally, developers should receive a task, deliver the result and inform the task author after it's done. Afterwards, the task author closes the task and payment is made. We track the number of messages you post and receive in your tasks automatically. Consequently, too many messages may affect your overall score in a negative way. To avoid long conversations in tasks, submit new tickets with questions or bug reports. Again, the Puzzle Driven Development by Roles article explains the whole idea of helping us \"to break the project\" by submitting new bugs. Follow this concept and you'll be fine. Contribution via Bugs In XDSD Bugs Are Welcome . You are supposed to report bugs along the normal development activities. Besides receiving extra money for reporting bugs, you can also increase your overall rating. The best developers submit one bug for every 2 to 3 tasks they complete. "},{"title":"Basic HTTP Auth for S3 Buckets","url":"/2014/04/21/s3-http-basic-auth.html","tags":["aws","s3","http","s3auth"],"date":"2014-04-21 00:00:00 +0000","categories":[],"body":" Amazon S3 is a simple and very useful storage of binary objects (aka \"files\"). To use it, you create a \"bucket\" there with a unique name and upload your objects. Afterwards, AWS guarantees your object will be available for download through their RESTful API . A few years ago, AWS introduced a S3 feature S3 called static website hosting . With static website hosting, you simply turn on the feature and all objects in your bucket become available through public HTTP. This is an awesome feature for hosting static content, such as images, JavaScript files, video and audio content. When using the hosting, you need to change the CNAME record in your DNS so that it points to www.example.com.aws.amazon.com . After changing the DNS entry, your static website is available at www.example.com just as it would be normally. When using Amazon S3, though, it is not possible to protect your website because the content is purely static. This means you can't have a login page on the front end. With the service, you can either make your objects either absolutely public — so that anyone can see them online — or assign access rights to them — but only for users connected through RESTful API. My use case with the service was a bit more complex, though. I wanted to host my static content as S3 objects. However, I wanted to do this while ensuring only a few people had access to the content using their Web browsers. HTTP Basic Authentication The HTTP protocol offers a nice \"basic access authentication\" feature that doesn't require any extra site pages. When an HTTP request arrives at the server, it doesn't deliver the content but replies with a 401 status response. This response means literally \"I don't know who you are, please authenticate yourself.\" The browser shows its native login screen and prompts for a user name and password. After entering the login credentials, they are concatenated, Base64 encoded, and added to the next request in Authorization HTTP header. Now, the browser tries to make another attempt to fetch the same webpage. But, this time, the HTTP request contains a header: Authorization: Basic am9lOnNlY3JldA== The above is just an example. In the example, the Base64 encoded part means joe:secret , where joe is the user name and secret the password entered by the user. This time the server has authentication information and can make a decision whether this user is authenticated (his password matches the server's records) and authorized (he has permission to access the request webpage). s3auth.com Since Amazon doesn't provide this feature, I decided to create a simple web service, s3auth.com , which stays in front of my Amazon S3 buckets and implements the HTTP-native authentication and authorization mechanism. Instead of making my objects public, though, I make them private and point my CNAME record to relay.s3auth.com . HTTP requests from Web browsers then arrive at my server, connect to Amazon S3, retrieve my objects and deliver them back in HTTP responses. The server implements authentication and authorization using a special file .htpasswd in the root of my bucket. The format of the \".htpasswd\" file is identical to the one used by Apache HTTP Server — one user per line. Every line has the name of a user and a hash version of his password. Implementation I made this software open source mostly to guarantee to my users that the server doesn't store their private data anywhere, but rather acts only as a pass-through service. As a result, the software is on Github . For the sake of privacy and convenience, I use only OAuth2 for user accounts. This means that I don't know who my users are. I don't possess their names or emails, but only their account numbers in Facebook, Google Plus or Github. Of course, I can find their names using these numbers, but this information is public anyway. The server is implemented in Java6. For its hosting, I'm using a single Amazon EC2 m1.small Ubuntu server. These days, the server seems to work properly and is stable. Extra Features Besides authentication and authorization, the s3auth.com server can render lists of pages — just like Apache HTTP Server. If you have a collection of objects in your bucket — but the index.html file is missing — Amazon S3 delivers a \"page not found\" result. Conversely, my server displays a list of objects in the bucket, when no \"index.html\" is present, and makes it possible to navigate up or down one folder. When your bucket has the versioning feature turned on, you are able to list all versions of any object in the browser. To do this, just add ?all-versions to the end of the URL to display the list. Next, click a version to have s3auth.com retrieve and render it. Traction I created this service mostly for myself, but apparently I'm not the only with the problems described above. At the moment, s3auth.com hosts over 300 domains and sends through more than 10Mb of data each hour. "},{"title":"Java XML Parsing Made Easy","url":"/2014/04/24/java-xml-parsing-and-traversing.html","tags":["xml","java","jcabi"],"date":"2014-04-24 00:00:00 +0000","categories":[],"body":"Unlike with many other modern languages, parsing XML in Java requires more than one line of code. XML traversing using XPath takes even more code, and I find this is unfair and annoying. I'm a big fan of XML and use it it in almost every Java application. Some time ago, I decided to put all of that XML-to-DOM parsing code into a small library — jcabi-xml . Put simply, the library is a convenient wrapper for JDK-native DOM manipulations. That's why it is small and dependency-free. With the following example, you can see just how simple XML parsing can be: import com.jcabi.xml.XML ; import com.jcabi.xml.XMLDocument ; XML xml = new XMLDocument ( \"<root><a>hello</a><b>world!</b></root>\" ); Now, we have an object of interface XML that can traverse the XML tree and convert it back to text. For example: // outputs \"hello\" System . out . println ( xml . xpath ( \"/root/a/text()\" ). get ( 0 )); // outputs the entire XML document System . out . println ( xml . toString ()); Method xpath() allows you to find a collection of text nodes or attributes in the document, and then convert them to a collection of strings, using XPath query : // outputs \"hello\" and \"world\" for ( String text : xml . xpath ( \"/root/*/text()\" )) { System . out . println ( text ); } Method nodes() enables the same XPath search operation, but instead returns a collection of instances of XML interface: // outputs \"<a>hello</a>\" and \"<b>world</b>\" for ( XML node : xml . xpath ( \"/root/*\" )) System . out . println ( node ); } Besides XML parsing, printing and XPath traversing, jcabi-xml also provides XSD validation and XSL transformations. I'll write about those features in the next post :) "},{"title":"Incremental Requirements With Requs","url":"/2014/04/26/incremental-requirements-with-requs.html","tags":["requs","xdsd","requirements"],"date":"2014-04-26 00:00:00 +0000","categories":[],"body":"Requirements engineering is one of the most important disciplines in software development. Perhaps, even more important than architecture, design or coding itself. Joy Beatty and Karl Wiegers in Software Requirements argue that the cost of mistakes made in a requirements specification is significantly higher than a bug in source code. I totally agree. In XDSD projects we specify requirements using Requs , a controlled natural language that sounds like English, while at the same time is parseable by computers. A simple requirements document in Requs may look similar to: 1 2 3 Department has employee-s. Employee has name and salary. UC1 where Employee gets raise: \"TBD\". This Software Requirements Specification (SRS) defines two types ( Department and Employee ) and one method UC (aka \"use case\"). Requs syntax is explained here . The main and only goal of requirements engineering in any XDSD project is to create a complete and non-ambiguous SRS document. The person who performs this task is called the \"system analyst\". This article explains his or her main tasks and discusses possible pitfalls. Tasks We modify SRS incrementally, and our increments are very small. For instance, say we have the sample document I mentioned above, and I'm a system analyst on the project. All my tasks will be similar to \"there is a bug in SRS, let's fix it\". Even if it is a suggestion, it will still start with a complaint about the incompleteness of the SRS. For example: UC1 doesn't explain how exactly an employee receives a raise. Does the salary of an employee have limits? Can it be negative? How many employees can a department have? Can it be zero? Can an employee receive a decrease in salary? All of these bugs are addressed to me. I need to fix them by improving the SRS. My workflow is the same in every task: Understand what is required Change the SRS Close the task Let's try this step by step. Requirements Providers As a system analyst, my job is to understand what product owners (aka \"requirements providers\") want and document their wishes. In most cases, their wants and wishes are very vague and chaotic. My job is to make them complete and unambiguous. That's why the first step is to understand what is required. First of all, I must determine who the product owner is before I can begin. The product owner signs the SRS, so I should pay complete attention to his opinions. However, my job is not only to listen, but also to suggest. A good system analyst can provoke creative thinking in a product owner by asking the right questions. OK, now I that know the identity of the product owner, I need to talk to him. In XDSD, we don't do any meetings, phone calls, or any other type of informal communications. Therefore, my only mechanism for receiving the information I need is with is — tickets. I will submit new tickets, addressing them to the product owner. As there can be many product owners in a project, I must submit tickets that clearly state in the first sentence that the ticket pertains to questions for a particular owners. The person receiving the ticket will then determine the best person to answer it. Thus, while working with a single task, I will submit many questions and receive many interesting answers. I'll do all this in order to improve my understanding of the product the owners are developing. When I understand how the SRS should be fixed, it is time to make changes in the Requs files. Requs Files The SRS document is generated automatically on every continuous integration build cycle. It is compiled from pieces called .req files, which are usually located in the src/main/requs directory in a project repository. My job, as a system analyst, is to make changes to some of these files and submit a pull request for review. Github Guidelines explains [how to work with Github. However, in short, I need to: Clone the repository; Check out its copy to my computer; Make changes; Commit my changes; Push them to my remote fork; Submit a pull request It doesn't really matter which files I edit because Requs automatically composes together all files with the req extension. I can even add new files to the directory — they will be picked up. Likewise, I can also add sub- directories with files. Local Build Before submitting a pull request, I will try to validate that my changes are syntactically and grammatically valid. I will compile Requs files into the SRS document using the same method our continuous integration server uses to compile them. Before I can compile, though, I need to install JDK7 and Maven . Afterwards, I make the following command line call in the project directory: 1 mvn clean requs:compile After entering the commands, I expect to see the BUILD SUCCESS message. If not, there are some errors and I should fix them. My pull request won't be merged and I won't be able to close the task if Requs can't compile the files. Once compiled, I can open the SRS in Firefox. It is in target/requs/index.xml . Even though it is an XML file, Firefox can open it as a webpage. Other browsers won't work. Well, Google Chrome will work, but only with this small trick . Pull Request Review Once all changes are finished, I will submit a pull request. A project manager will the assign someone to review my pull request and I will receive feedback. In most cases, there will be at least a few corrections requested by the reviewer. Generally speaking, my requests are reviewed by other system analysts. Therefore, I must address all comments and make sure my changes satisfy the reviewer. I will make extra changes to the same branch locally, and push them to Github. The pull request will be updated automatically, so I don't need to create a new one. Once the pull request is clean enough for the reviewer, he will merge it into the master branch. Close and Get Paid Finally, my pull request is merged and I get back to the task owner. I tell him that the SRS was fixed and request that he review it. His original problem should be fixed by now — the SRS should provide the information required. He then closes the task and the project manager pays me within a few hours. "},{"title":"Typical Mistakes in Java Code","url":"/2014/04/27/typical-mistakes-in-java-code.html","tags":["anti-pattern","java","oop"],"date":"2014-04-27 00:00:00 +0000","categories":[],"body":"This page contains most typical mistakes I see in the Java code of people working with me. Static analysis (we're using qulice can't catch all of the mistakes for obvious reasons, and that's why I decided to list them all here. Let me know if you want to see something else added here, and I'll be happy to oblige. All of the listed mistakes are related to object-oriented programming in general and to Java in particular. Class Names Read this short \"What is an Object?\" article. Your class should be an abstraction of a real life entity with no \"validators\", \"controllers\", \"managers\", etc. If your class name ends with an \"-er\" — it's a bad design . And, of course, utility classes are anti-patterns, like StringUtils , FileUtils , and IOUtils from Apache. The above are perfect examples of terrible designs. Read this follow up post: OOP Alternative to Utility Classes Of course, never add suffixes or prefixes to distinguish between interfaces and classes . For example, all of these names are terribly wrong: IRecord , IfaceEmployee , or RecordInterface . Usually, interface name is the name of a real-life entity, while class name should explain its implementation details. If there is nothing specific to say about an implementation, name it Default, Simple , or something similar. For example: class SimpleUser implements User {}; class DefaultRecord implements Record {}; class Suffixed implements Name {}; class Validated implements Content {}; Method Names Methods can either return something or return void . If a method returns something, then its name should explain what it returns , for example (don't use the get prefix ever ): boolean isValid ( String name ); String content (); int ageOf ( File file ); If it returns void, then its name should explain what it does . For example: void save ( File file ); void process ( Work work ); void append ( File file , String line ); There is only one exception to the rule just mentioned — test methods for JUnit. They are explained below. Test Method Names Method names in JUnit tests should be created as English sentences without spaces. It's easier to explain by example: /** * HttpRequest can return its content in Unicode. * @throws Exception If test fails */ public void returnsItsContentInUnicode () throws Exception { } It's important to start the first sentence of your JavaDoc with the name of the class you're testing followed by can . So, your first sentence should always be similar to \"somebody can do something\". The method name will state exactly the same, but without the subject. If I add a subject at the beginning of the method name, I should get a complete English sentence, as in above example: \"HttpRequest returns its content in unicode\". Pay attention that the test method doesn't start with can .Only JavaDoc comments start with 'can.' Additionally, method names shouldn’t start with a verb. It's a good practice to always declare test methods as throwing Exception . Variable Names Avoid composite names of variables, like timeOfDay , firstItem , or httpRequest . I mean with both — class variables and in-method ones. A variable name should be long enough to avoid ambiguity in its scope of visibility, but not too long if possible. A name should be a noun in singular or plural form, or an appropriate abbreviation. For example: List < String > names ; void sendThroughProxy ( File file , Protocol proto ); private File content ; public HttpRequest request ; Sometimes, you may have collisions between constructor parameters and in-class properties if the constructor saves incoming data in an instantiated object. In this case, I recommend to create abbreviations by removing vowels (see how USPS abbreviates street names ). Another example: public class Message { private String recipient ; public Message ( String rcpt ) { this . recipient = rcpt ; } } In many cases, the best hint for a name of a variable can ascertained by reading its class name. Just write it with a small letter, and you should be good: File file ; User user ; Branch branch ; However, never do the same for primitive types, like Integer number or String string . You can also use an adjective, when there are multiple variables with different characteristics. For instance: String contact(String left, String right); Constructors Without exceptions, there should be only one constructor that stores data in object variables. All other constructors should call this one with different arguments. For example: public class Server { private String address ; public Server ( String uri ) { this . address = uri ; } public Server ( URI uri ) { this ( uri . toString ()); } } One-time Variables Avoid one-time variables at all costs. By \"one-time\" I mean variables that are used only once. Like in this example: String name = \"data.txt\" ; return new File ( name ); This above variable is used only once and the code should be refactored to: return new File ( \"data.txt\" ); Sometimes, in very rare cases — mostly because of better formatting — one-time variables may be used. Nevertheless, try to avoid such situations at all costs. Exceptions Needless to say, you should never swallow exceptions, but rather let them bubble up as high as possible. Private methods should always let checked exceptions go out. Never use exceptions for flow control. For example this code is wrong: int size ; try { size = this . fileSize (); } catch ( IOException ex ) { size = 0 ; } Seriously, what if that IOException says \"disk is full\"? Will you still assume that the size of the file is zero and move on? Indentation For indentation, the main rule is that a bracket should either end a line or be closed on the same line (reverse rule applies to a closing bracket). For example, the following is not correct because the first bracket is not closed on the same line and there are symbols after it. The second bracket is also in trouble because there are symbols in front of it and it is not opened on the same line: final File file = new File(directory, \"file.txt\"); Correct indentation should look like: StringUtils.join( Arrays.asList( \"first line\", \"second line\", StringUtils.join( Arrays.asList(\"a\", \"b\") ) ), \"separator\" ); The second important rule of indentation says that you should put as much as possible on one line - within the limit of 80 characters. The example above is not valid since it can be compacted: StringUtils.join( Arrays.asList( \"first line\", \"second line\", StringUtils.join(Arrays.asList(\"a\", \"b\")) ), \"separator\" ); Redundant Constants Class constants should be used when you want to share information between class methods, and this information is a characteristic (!) of your class. Don't use constants as a replacement of string or numeric literals — very bad practice that leads to code pollution. Constants (as with any object in OOP) should have a meaning in a real world. What meaning do these constants have in the real world: class Document { private static final String D_LETTER = \"D\" ; // bad practice private static final String EXTENSION = \".doc\" ; // good practice } Another typical mistake is to use constants in unit tests to avoid duplicate string/numeric literals in test methods. Don't do this! Every test method should work with its own set of input values. Use new texts and numbers in every new test method. They are independent. So, why do they have to share the same input constants? Test Data Coupling This is an example of data coupling in a test method: User user = new User ( \"Jeff\" ); // maybe some other code here MatcherAssert . assertThat ( user . name (), Matchers . equalTo ( \"Jeff\" )); On the last line, we couple \"Jeff\" with the same string literal from the first line. If, a few months later, someone wants to change the value on the third line, he/she has to spend extra time finding where else \"Jeff\" is used in the same method. To avoid this data coupling, you should introduce a variable. "},{"title":"XML/XPath Matchers for Hamcrest","url":"/2014/04/28/xml-xpath-hamcrest-matchers.html","tags":["xml","hamcrest","xpath","testing"],"date":"2014-04-28 00:00:00 +0000","categories":[],"body":" Hamcrest is my favorite instrument in unit testing. It replaces the JUnit procedural assertions of org.junit.Assert with an object-oriented mechanism. However, I will discuss that subject in more detail sometime later. Now, though, I want to demonstrate a new library published today on Github and Maven Central: jcabi-matchers . jcabi-matchers is a collection of Hamcrest matchers to make XPath assertions in XML and XHTML documents. Let's say, for instance, a class that is undergoing testing produces an XML that needs to contain a single <message> element with the content \"hello, world!\" This is how that code would look in a unit test: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import com.jcabi.matchers.XhtmlMatchers ; import org.hamcrest.MatcherAssert ; import org.junit.Test ; public class FooTest { @Test public void hasWelcomeMessage () { MatcherAssert . assertThat ( new Foo (). createXml (), XhtmlMatchers . hasXPaths ( \"/document[count(message)=1]\" , \"/document/message[.='hello, world!']\" ) ); } } There are two alternatives to the above that I'm aware of, which are do almost the same thing: xml-matchers by David Ehringer and hasXPath() method in Hamcrest itself. I have tried them both, but faced a number of problems. First, Hamcrest hasXPath() works only with an instance of Node . With this method, converting a String into Node becomes a repetitive and routine task in every unit test. The above is a very strange limitation of Hamcrest in contrast to jcabi-matchers , which works with almost anything, from a String to a Reader and even an InputStream . Second, `XmlMatchers from xml-matchers provides a very inconvenient way for working with namespaces. Before you can use an XPath query with a non-default namespace, you should create an instance of NamespaceContext. The library provides a simple implementation of this interface, but, still, it is requires extra code in every unit test. jcabi-matchers simplifies namespace handling problems even further, as it pre-defines most popular namespaces, including xtml , xs , xsl , etc. The following example works right out-of-the-box — without any extra configuration: 1 2 3 4 MatcherAssert . assertThat ( new URL ( \"http://www.google.com\" ). getContent (), XhtmlMatchers . hasXPath ( \"//xhtml:body\" ) ); To summarize, my primary objective with the library was its simplicity of usage. "},{"title":"W3C Java Validators","url":"/2014/04/29/w3c-java-validators.html","tags":["w3c","java","jcabi"],"date":"2014-04-29 00:00:00 +0000","categories":[],"body":" A few years ago, I created two Java wrappers for W3C validators: ( HTML and CSS ). Both wrappers seemed to be working fine and were even listed by W3C on their website in the API section. Until recently, these wrappers have always been part of ReXSL library. A few days ago, though, I took the wrappers out of ReXSL and published them as a standalone library — jcabi-w3c . Consequently, now seems to be a good time to write a few words about them. Below is an example that demonstrates how you can validate an HTML document against W3C compliancy rules: 1 2 3 4 import com.jcabi.w3c.ValidatorBuilder ; assert ValidatorBuilder . html () . validate ( \"<html>hello, world!</html>\" ) . valid (); The valid() method is a black or white indicator that returns false when the document is not valid. Additionally, you can obtain more information through a list of \"defects\" returned by the W3C server: 1 2 3 Collection < Defect > defects = ValidatorBuilder . html () . validate ( \"<html>hello, world!</html>\" ) . errors (); The same can be done with CSS: 1 2 3 Collection < Defect > defects = ValidatorBuilder . css () . validate ( \"body { font-family: Arial; }\" ) . errors (); Personally, I think it is a good practice to validate all of HTML pages produced by your application against W3C during integration testing. It's not a matter of seeking perfection, but rather of preventing bigger problems later. These dependencies are mandatory when using jcabi-w3c (get their latest versions in Maven Central ): <dependency> <groupId> com.jcabi </groupId> <artifactId> jcabi-w3c </artifactId> </dependency> <dependency> <groupId> org.glassfish </groupId> <artifactId> javax.json </artifactId> </dependency> <dependency> <groupId> com.sun.jersey </groupId> <artifactId> jersey-client </artifactId> </dependency> <dependency> <groupId> org.hamcrest </groupId> <artifactId> hamcrest-core </artifactId> </dependency> "},{"title":"DynamoDB Local Maven Plugin","url":"/2014/05/01/dynamodb-local-maven-plugin.html","tags":["dynamodb","maven","aws","java"],"date":"2014-05-01 00:00:00 +0000","categories":[],"body":" DynamoDB Local is a locally running copy of Amazon DynamoDB server. Amazon developed the tool and based it on SQLite. It acts as a real DynamoDB service through the RESTful API. I guess, DynamoDB Local is meant to be used in integration testing and this is how we're going to use it below. I use Maven to run all of my Java integration testing using maven-failsafe-plugin . The philosophy of integration testing with Maven is that you start all your supplementary test stubs during the pre-integration-test phase, run your tests in the integration-test phase and then shutdown all stubs during the post-integration-test . It would be great if it were possible to use DynamoDB Local that way. I didn't find any Maven plugins for that purpose, so I decided to create my own — jcabi-dynamodb-maven-plugin . Full usage details for the plugin are explained on its website . However, here is a simple example (get its latest versions in Maven Central ): <plugin> <groupId> com.jcabi </groupId> <artifactId> jcabi-dynamodb-maven-plugin </artifactId> <executions> <execution> <goals> <goal> start </goal> <goal> stop </goal> </goals> <configuration> <port> 10500 </port> <dist> ${project.build.directory}/dynamodb-dist </dist> </configuration> </execution> </executions> </plugin> The above configuration will start DynamoDB Local right before running integration tests, and then stop it immediately afterwards. The server will listen at TCP port 10500. While the number is used in the example, you're supposed to use a randomly allocated port instead. When the DynamoDB Local server is up and running, we can create an integration test for it: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import com.amazonaws.auth.BasicAWSCredentials ; import com.amazonaws.services.dynamodbv2.AmazonDynamoDB ; import com.amazonaws.services.dynamodbv2.AmazonDynamoDBClient ; import com.amazonaws.services.dynamodbv2.model.ListTablesResult ; public class FooITCase { @Test public void worksWithAwsDynamoDb () { AmazonDynamoDB aws = new AmazonDynamoDBClient ( new BasicAWSCredentials ( \"\" , \"\" ) ); aws . setEndpoint ( \"http://localhost:10500\" ); ListTablesResult list = aws . listTables (); for ( String name : list . getTableNames ()) { System . out . println ( \"table found: \" + name ); } } } Of course, there won't be any output because the server starts without any tables. Since the server is empty, you should create tables before every integration test, using createTable() from DynamoDB SDK . To avoid this type of extra hassle, in the latest version 0.6 of jcabi-dynamodb-maven-plugin we introduced a new goal create-tables : <plugin> <groupId> com.jcabi </groupId> <artifactId> jcabi-dynamodb-maven-plugin </artifactId> <executions> <execution> <goals> <goal> create-tables </goal> </goals> <configuration> <tables> <table> ${basedir}/src/test/dynamodb/foo.json </table> </tables> </configuration> </execution> </executions> </plugin> The foo.json file used above should contain a JSON request that is sent to DynamoDB Local right after it is up and running. The request should comply with the specification of CreateTable request. For example: { \"AttributeDefinitions\" : [ { \"AttributeName\" : \"id\" , \"AttributeType\" : \"N\" } ], \"KeySchema\" : [ { \"AttributeName\" : \"id\" , \"KeyType\" : \"HASH\" } ], \"ProvisionedThroughput\" : { \"ReadCapacityUnits\" : \"1\" , \"WriteCapacityUnits\" : \"1\" }, \"TableName\" : \"foo\" } The table will be created during the pre-integration-test phase and dropped at the post-integration-test phase. Now, we can make our integration test much more meaningful with the help of jcabi-dynamo : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import com.jcabi.dynamo.Attributes ; import com.jcabi.dynamo.Conditions ; import com.jcabi.dynamo.Credentials ; import com.jcabi.dynamo.Region ; import com.jcabi.dynamo.Table ; import org.hamcrest.MatcherAssert ; import org.hamcrest.Matchers ; public class FooITCase { @Test public void worksWithAwsDynamoDb () { Region region = new Region . Simple ( new Credentials . Simple ( \"\" , \"\" )); Table table = region . table ( \"foo\" ); table . put ( new Attributes () . with ( \"id\" , 123 ) . with ( \"name\" , \"Robert DeNiro\" ) ); MatcherAssert . assertThat ( table . frame (). where ( \"id\" , Conditions . equalTo ( 123 )), Matchers . notEmpty () ); } } The above test will put a new item into the table and then assert that the item is there. The plugin was tested with three operating systems, and proved to work without problems: Mac OS X 10.8.5, Windows 7 SP1 and Ubuntu Linux 12.04 Desktop. "},{"title":"OOP Alternative to Utility Classes","url":"/2014/05/05/oop-alternative-to-utility-classes.html","tags":["oop","anti-pattern"],"date":"2014-05-05 00:00:00 +0000","categories":["best"],"body":"A utility class (aka helper class) is a \"structure\" that has only static methods and encapsulates no state. StringUtils , IOUtils , FileUtils from Apache Commons ; Iterables and Iterators from Guava , and Files from JDK7 are perfect examples of utility classes. This design idea is very popular in the Java world (as well as C#, Ruby, etc.) because utility classes provide common functionality used everywhere. Here, we want to follow the DRY principle and avoid duplication. Therefore, we place common code blocks into utility classes and reuse them when necessary: // This is a terrible design, don't reuse public class NumberUtils { public static int max ( int a , int b ) { return a > b ? a : b ; } } Indeed, this a very convenient technique!? Utility Classes Are Evil However, in an object-oriented world, utility classes are considered a very bad (some even may say \"terrible\") practice. There have been many discussions of this subject; to name a few: Are Helper Classes Evil? by Nick Malik, Why helper, singletons and utility classes are mostly bad by Simon Hart, Avoiding Utility Classes by Marshal Ward, Kill That Util Class! by Dhaval Dalal, Helper Classes Are A Code Smell by Rob Bagby. Additionally, there are a few questions on StackExchange about utility classes: If a “Utilities” class is evil, where do I put my generic code? , Utility Classes are Evil . A dry summary of all their arguments is that utility classes are not proper objects; therefore, they don't fit into object-oriented world. They were inherited from procedural programming, mostly because most were used to a functional decomposition paradigm back then. Assuming you agree with the arguments and want to stop using utility classes, I'll show by example how these creatures can be replaced with proper objects. Procedural Example Say, for instance, you want to read a text file, split it into lines, trim every line and then save the results in another file. This is can be done with FileUtils from Apache Commons: 1 2 3 4 5 6 7 8 void transform ( File in , File out ) { Collection < String > src = FileUtils . readLines ( in , \"UTF-8\" ); Collection < String > dest = new ArrayList <>( src . size ()); for ( String line : src ) { dest . add ( line . trim ()); } FileUtils . writeLines ( out , dest , \"UTF-8\" ); } The above code may look clean; however, this is procedural programming, not object-oriented. We are manipulating data (bytes and bits) and explicitly instructing the computer from where to retrieve them and then where to put them on every single line of code. We're defining a procedure of execution . Object-Oriented Alternative In an object-oriented paradigm, we should instantiate and compose objects, thus letting them manage data when and how they desire. Instead of calling supplementary static functions, we should create objects that are capable of exposing the behaviour we are seeking: public class Max implements Number { private final int a ; private final int b ; public Max ( int x , int y ) { this . a = x ; this . b = y ; } @Override public int intValue () { return this . a > this . b ? this . a : this . b ; } } This procedural call: int max = NumberUtils . max ( 10 , 5 ); Will become object-oriented: int max = new Max ( 10 , 5 ). intValue (); Potato, potato? Not really; just read on... Objects Instead of Data Structures This is how I would design the same file-transforming functionality as above but in an object-oriented manner: 1 2 3 4 5 6 7 8 9 void transform ( File in , File out ) { Collection < String > src = new Trimmed ( new FileLines ( new UnicodeFile ( in )) ); Collection < String > dest = new FileLines ( new UnicodeFile ( out ) ); dest . addAll ( src ); } FileLines implements Collection<String> and encapsulates all file reading and writing operations. An instance of FileLines behaves exactly as a collection of strings and hides all I/O operations. When we iterate it — a file is being read. When we addAll() to it — a file is being written. Trimmed also implements Collection<String> and encapsulates a collection of strings ( Decorator pattern ). Every time the next line is retrieved, it gets trimmed. All classes taking participation in the snippet are rather small: Trimmed , FileLines , and UnicodeFile . Each of them is responsible for its own single feature, thus following perfectly the single responsibility principle . On our side, as users of the library, this may be not so important, but for their developers it is an imperative. It is much easier to develop, maintain and unit-test class FileLines rather than using a readLines() method in a 80+ methods and 3000 lines utility class FileUtils . Seriously, look at its source code . An object-oriented approach enables lazy execution. The in file is not read until its data is required. If we fail to open out due to some I/O error, the first file won't even be touched. The whole show starts only after we call addAll() . All lines in the second snippet, except the last one, instantiate and compose smaller objects into bigger ones. This object composition is rather cheap for the CPU since it doesn't cause any data transformations. Besides that, it is obvious that the second script runs in O(1) space, while the first one executes in O(n). This is the consequence of our procedural approach to data in the first script. In an object-oriented world, there is no data; there are only objects and their behavior! "},{"title":"Why NULL is Bad?","url":"/2014/05/13/why-null-is-bad.html","tags":["oop","anti-pattern"],"date":"2014-05-13 00:00:00 +0000","categories":["best"],"body":"A simple example of NULL usage in Java: 1 2 3 4 5 6 7 public Employee getByName ( String name ) { int id = database . find ( name ); if ( id == 0 ) { return null ; } return new Employee ( id ); } What is wrong with this method? It may return NULL instead of an object — that's what is wrong. NULL is a terrible practice in an object-oriented paradigm and should be avoided at all costs. There have been a number of opinions about this published already, including Null References, The Billion Dollar Mistake presentation by Tony Hoare and the entire Object Thinking book by David West. Here, I'll try to summarize all the arguments and show examples of how NULL usage can be avoided and replaced with proper object-oriented constructs. Basically, there are two possible alternatives to NULL . The first one is Null Object design pattern (the best way is to make it a constant): public Employee getByName ( String name ) { int id = database . find ( name ); if ( id == 0 ) { return Employee . NOBODY ; } return Employee ( id ); } The second possible alternative is to fail fast by throwing an Exception when you can't return an object: public Employee getByName ( String name ) { int id = database . find ( name ); if ( id == 0 ) { throw new EmployeeNotFoundException ( name ); } return Employee ( id ); } Now, let's see the arguments against NULL . Besides Tony Hoare's presentation and David West's book mentioned above, I read these publications before writing this post: Clean Code by Robert Martin, Code Complete by Steve McConnell, Say \"No\" to \"Null\" by John Sonmez, Is returning null bad design? discussion at StackOverflow. Ad-hoc Error Handling Every time you get an object as an input you must check whether it is NULL or a valid object reference. If you forget to check, a NullPointerException (NPE) may break execution in runtime. Thus, your logic becomes polluted with multiple checks and if/then/else forks: // this is a terrible design, don't reuse Employee employee = dept . getByName ( \"Jeffrey\" ); if ( employee == null ) { System . out . println ( \"can't find an employee\" ); System . exit (- 1 ); } else { employee . transferTo ( dept2 ); } This is how exceptional situations are supposed to be handled in C and other imperative procedural languages. OOP introduced exception handling primarily to get rid of these ad-hoc error handling blocks. In OOP, we let exceptions bubble up until they reach an application-wide error handler and our code becomes much cleaner and shorter: dept . getByName ( \"Jeffrey\" ). transferTo ( dept2 ); Consider NULL references an inheritance of procedural programming, and use 1) Null Objects or 2) Exceptions instead. Ambiguous Semantic In order to explicitly convey its meaning, the function getByName() has to be named getByNameOrNullIfNotFound() . The same should happen with every function that returns an object or NULL . Otherwise, ambiguity is inevitable for a code reader. Thus, to keep semantic unambiguous, you should give longer names to functions. To get rid of this ambiguity, always return a real object, a null object or throw an exception. Some may argue that we sometimes have to return NULL , for the sake of performance. For example, method get() of interface Map in Java returns NULL when there is no such item in the map: Employee employee = employees . get ( \"Jeffrey\" ); if ( employee == null ) { throw new EmployeeNotFoundException (); } return employee ; This code searches the map only once due to the usage of NULL in Map . If we would refactor Map so that its method get() will throw an exception if nothing is found, our code will look like this: if (! employees . containsKey ( \"Jeffrey\" )) { // first search throw new EmployeeNotFoundException (); } return employees . get ( \"Jeffrey\" ); // second search Obviously, this is method is twice as slow as the first one. What to do? The Map interface (no offense to its authors) has a design flaw. Its method get() should have been returning an Iterator so that our code would look like: Iterator found = Map . search ( \"Jeffrey\" ); if (! found . hasNext ()) { throw new EmployeeNotFoundException (); } return found . next (); BTW, that is exactly how C++ STL map::find() method is designed. Computer Thinking vs. Object Thinking Statement if (employee == null) is understood by someone who knows that an object in Java is a pointer to a data structure and that NULL is a pointer to nothing ( 0x00000000 , in Intel x86 processors). However, if you start thinking as an object, this statement makes much less sense. This is how our code looks from an object point of view: - Hello, is it a software department? - Yes. - Let me talk to your employee \"Jeffrey\" please. - Hold the line please... - Hello. - Are you NULL? The last question in this conversation sounds weird, doesn’t it? Instead, if they hang up the phone after our request to speak to Jeffrey, that causes a problem for us (Exception). At that point, we try to call again or inform our supervisor that we can't reach Jeffrey and complete a bigger transaction. Alternatively, they may let us speak to another person, who is not Jeffrey, but who can help with most of our questions or refuse to help if we need something \"Jeffrey specific\" (Null Object). Slow Failing Instead of failing fast , the code above attempts to die slowly, killing others on its way. Instead of letting everyone know that something went wrong and that an exception handling should start immediately, it is hiding this failure from its client. This argument is close to the \"ad-hoc error handling\" discussed above. It is a good practice to make your code as fragile as possible, letting it break when necessary. Make your methods extremely demanding as to the data they manipulate. Let them complain by throwing exceptions, if the provided data provided is not sufficient or simply doesn’t fit with the main usage scenario of the method. Otherwise, return a Null Object, that exposes some common behavior and throws exceptions on all other calls: public Employee getByName ( String name ) { int id = database . find ( name ); Employee employee ; if ( id == 0 ) { employee = new Employee () { @Override public String name () { return \"anonymous\" ; } @Override public void transferTo ( Department dept ) { throw new AnonymousEmployeeException ( \"I can't be transferred, I'm anonymous\" ); } }; } else { employee = Employee ( id ); } return employee ; } Mutable and Incomplete Objects In general, it is highly recommended to design objects with immutability in mind. This means that an object gets all necessary knowledge during its instantiating and never changes its state during the entire lifecycle. Very often, NULL values are used in lazy loading , to make objects incomplete and mutable. For example: public class Department { private Employee found = null ; public synchronized Employee manager () { if ( this . found == null ) { this . found = new Employee ( \"Jeffrey\" ); } return this . found ; } } This technology, although widely used, is an anti-pattern in OOP. Mostly because it makes an object responsible for performance problems of the computational platform, which is something an Employee object should not be aware of. Instead of managing a state and exposing its business-relevant behavior, an object has to take care of the caching of its own results — this is what lazy loading is about. Caching is not something an employee does in the office, does he? The solution? Don't use lazy loading in such a primitive way, as in the example above. Instead, move this caching problem to another layer of your application. For example, in Java, you can use aspect-oriented programming aspects. For example, jcabi-aspects has @Cacheable annotation that caches the value returned by a method: import com.jcabi.aspects.Cacheable ; public class Department { @Cacheable ( forever = true ) public Employee manager () { return new Employee ( \"Jacky Brown\" ); } } I hope this analysis was convincing enough that you will stop NULL -ing your code :) "},{"title":"Object-Oriented Github API","url":"/2014/05/14/object-oriented-github-java-sdk.html","tags":["github","jcabi"],"date":"2014-05-14 00:00:00 +0000","categories":[],"body":" Github is an awesome platform for maintaining Git sources and tracking project issues. I moved all my projects (both private and public) to Github about three years ago and have no regrets. Moreover, Github gives access to almost all of its features through RESTful JSON API. There are a few Java SDKs that wrap and expose the API. I tried to use them, but faced a number of issues: They are not really object-oriented (even though one of them has a description that says it is) They are not based on JSR-353 (JSON Java API) They provide no mocking instruments They don't cover the entire API and can't be extended Keeping in mind all those drawbacks, I created my own library — jcabi-github . Let's look at its most important advantages. Object Oriented for Real Github server is an object. A collection of issues is an object, an individual issue is an object, its author is an author, etc. For example, to retrieve the name of the author we use: Github github = new RtGithub ( /* credentials */ ); Repos repos = github . repos (); Repo repo = repos . get ( new Coordinates . Simple ( \"jcabi/jcabi-github\" )); Issues issues = github . issues (); Issue issue = issues . get ( 123 ); User author = new Issue . Smart ( issue ). author (); System . out . println ( author . name ()); Needless to say, Github , Repos , Repo , Issues , Issue , and User are interfaces. Classes that implement them are not visible in the library. Mock Engine MkGithub class is a mock version of a Github server. It behaves almost exactly the same as a real server and is the perfect instrument for unit testing. For example, say that you're testing a method that is supposed to post a new issue to Github and add a message into it. Here is how the unit test would look: public class FooTest { @Test public void createsIssueAndPostsMessage () { Github github = new MkGithub ( \"jeff\" ); github . repos (). create ( Json . createObjectBuilder (). add ( \"name\" , owner ). build () ); new Foo (). doTheThing ( github ); MatcherAssert . assertThat ( github . issues (). get ( 1 ). comments (). iterate (), Matchers . not ( Matchers . emptyIterable ()) ); } } This is much more convenient and compact than traditional mocking via Mockito or a similar framework. Extendable It is based on JSR-353 and uses jcabi-http for HTTP request processing. This combination makes it highly customizable and extendable, when some Github feature is not covered by the library (and there are many of them). For example, you want to get the value of hireable attribute of a User . Class User.Smart doesn't have a method for it. So, here is how you would get it: User user = // get it somewhere // name() method exists in User.Smart, let's use it System . out . println ( new User . Smart ( user ). name ()); // there is no hireable() method there System . out . println ( user . json (). getString ( \"hireable\" )); We're using method json() that returns an instance of JsonObject from JSR-353 (part of Java7). No other library allows such direct access to JSON objects returned by the Github server. Let's see another example. Say, you want to use some feature from Github that is not covered by the API. You get a Request object from Github interface and directly access the HTTP entry point of the server: Github github = new RtGithub ( oauthKey ); int found = github . entry () . uri (). path ( \"/search/repositories\" ). back () . method ( Request . GET ) . as ( JsonResponse . class ) . getJsonObject () . getNumber ( \"total_count\" ) . intValue (); jcabi-http HTTP client is used by jcabi-github . Immutable All classes are truly immutable and annotated with @Immutable . This may sound like a minor benefit, but it was very important for me. I'm using this annotation in all my projects to ensure my classes are truly immutable. Version 0.8 A few days ago we released the latest version 0.8 . It is a major release, that included over 1200 commits. It covers the entire Github API and is supposed to be very stable. The library ships as a JAR dependency in Maven Central (get its latest versions in Maven Central ): <dependency> <groupId> com.jcabi </groupId> <artifactId> jcabi-github </artifactId> </dependency> "},{"title":"Atomic Counters at Stateful.co","url":"/2014/05/18/cloud-autoincrement-counters.html","tags":["stateful","aws","dynamodb"],"date":"2014-05-18 00:00:00 +0000","categories":[],"body":" Amazon DynamoDB is a great NoSQL cloud database. It is cheap, highly reliable and rather powerful. I'm using it in many web systems. There is one feature that it lacks, though — auto-increment attributes. Say that you have a table with a list of messages: +------+----------------------------+ | id | Attributes | +------+----------------------------+ | 205 | author=\"jeff\", text=\"...\" | | 206 | author=\"bob\", text=\"...\" | | 207 | author=\"alice\", text=\"...\" | +------+----------------------------+ Every time you add a new item to the table, a new value of id has to be set. And this has to be done with concurrency in mind. SQL databases like PostgreSQL, Oracle, MySQL and others support auto-increment features. When you add a new record to the table, the value of the primary key is omitted and the server retrieves the next one automatically. If a number of INSERT requests arrive at the same time the server guarantees that the numbers won't be duplicated. However, DynamoDB doesn't have this feature. Instead, DynamoDB has Atomic Counters and Conditional Updates , which are very similar features. Still, they're not exactly the same. In case of an atomic counter, you should create a supplementary table and keep the latest value of id in it. In case of conditional updates, you should retry a few times in case of collisions. To make life easier in a few of my applications, I created a simple web service — stateful.co . It provides a simple atomic counter feature through its RESTful API. First, you create a counter with a unique name. Then, you set its initial value (it is zero by default). And, that's it. Every time you need to obtain a new value for id column in DynamoDB table, you make an HTTP request to stateful.co asking to increment your counter by one and return its next value. stateful.co guarantees that values returned will never duplicate each other — no matter how many clients are using a counter or how fast they request increments simultaneously. Moreover, I designed a small Java SDK for stateful.co . All you need to do is add this java-sdk.jar Maven dependency to your project: <dependency> <groupId> co.stateful </groupId> <artifactId> java-sdk </artifactId> <version> 0.6 </version> </dependency> And, you can use stateful.co counters from Java code: Sttc sttc = new RtSttc ( new URN ( \"urn:github:526301\" ), \"9FF3-41E0-73FB-F900\" ); Counters counters = sttc . counters (); Counter counter = counters . get ( \"foo\" ); long value = counter . incrementAndGet ( 1L ); System . out . println ( \"new value: \" + value ); You can review authentication parameters for RtSttc constructor at stateful.co . The service is absolutely free of charge. "},{"title":"MySQL Maven Plugin","url":"/2014/05/21/mysql-maven-plugin.html","tags":["mysql","maven","java"],"date":"2014-05-21 00:00:00 +0000","categories":[],"body":"I was using MySQL in a few Java web projects and found out there was no Maven plugin that would help me to test my DAO classes against a real MySQL server. There are plenty of mechanisms to mock a database persistence layer both in memory and on disc. However, it is always good to make sure that your classes are tested against a database identical to the one you have in production environment. I've created my own Maven plugin, jcabi-mysql-maven-plugin , that does exactly two things: starts a MySQL server on pre-integration-test phase and shuts it down on post-integration-test . This is how you configure it in pom.xml (see also its full usage instructions ): <project> <build> <plugins> <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> build-helper-maven-plugin </artifactId> <executions> <execution> <goals> <goal> reserve-network-port </goal> </goals> <configuration> <portNames> <portName> mysql.port </portName> </portNames> </configuration> </execution> </executions> </plugin> <plugin> <artifactId> maven-dependency-plugin </artifactId> <executions> <execution> <goals> <goal> unpack </goal> </goals> <configuration> <artifactItems> <artifactItem> <groupId> com.jcabi </groupId> <artifactId> mysql-dist </artifactId> <version> 5.6.14 </version> <classifier> ${mysql.classifier} </classifier> <type> zip </type> <overWrite> false </overWrite> <outputDirectory> ${project.build.directory}/mysql-dist </outputDirectory> </artifactItem> </artifactItems> </configuration> </execution> </executions> </plugin> <plugin> <groupId> com.jcabi </groupId> <artifactId> jcabi-mysql-maven-plugin </artifactId> <executions> <execution> <id> mysql-test </id> <goals> <goal> classify </goal> <goal> start </goal> <goal> stop </goal> </goals> <configuration> <port> ${mysql.port} </port> <data> ${project.build.directory}/mysql-data </data> </configuration> </execution> </executions> </plugin> <plugin> <artifactId> maven-failsafe-plugin </artifactId> <configuration> <systemPropertyVariables> <mysql.port> ${mysql.port} </mysql.port> </systemPropertyVariables> </configuration> <executions> <execution> <goals> <goal> integration-test </goal> <goal> verify </goal> </goals> </execution> </executions> </plugin> </plugins> </build> [...] </project> There are two plugins configured above. Let's take a look at what each does. build-helper-maven-plugin is reserving a temporary random TCP port, which will be used by MySQL server. We don't want to start a server on its default 3306 port, because there could be another server already running there. Besides that, if we use a hard-coded TCP port, we won't be able to run multiple builds in parallel. Maybe not a big deal when you're developing locally, but in continuous integration environment this can be a problem. That's why we're reserving a TCP port first. maven-dependency-plugin is downloading a MySQL distribution in a zip archive (rather big file, over 300Mb for Linux), and unpacks it. This archive contains exactly the same files as you would use for a traditional MySQL installation. When the archive is unpacked, it is ready to start serving SQL requests as a normal MySQL server. jcabi-mysql-maven-plugin starts a server, binding it to a TCP port reserved randomly. The main responsibility of my Maven plugin is to make sure that MySQL server starts correctly on every platform (Mac OS, Linux, Windows) and stops when it's not needed any more. All the rest is done by the MySQL distribution itself. maven-failsafe-plugin is running unit tests on integration-test phase. Its main difference from maven-surefire-plugin is that it doesn't fail a build when some tests fail. Instead, it saves all failures into supplementary files in target directory and allows the build continue. Later, when we call its verify goal, it will fail a build if there were any errors during its integration-test goal execution. To be precise, this is the order in which Maven will execute configured goals: jcabi-mysql-maven-plugin:classify maven-dependency-plugin:unpack build-helper-maven-plugin:reserve-network-port jcabi-mysql-maven-plugin:start maven-failsafe-plugin:integration-test jcabi-mysql-maven-plugin:stop maven-failsafe-plugin:verify Run mvn clean install and see how it works. If it doesn't work for some reason, don't hesitate to report an issue to Github . Now it's time to create an integration test, which will connect to the temporary MySQL server, create a table there and insert some data into it. This is just an example to show that MySQL server is running and is capable of serving transactions (I'm using jcabi-jdbc ): public class FooITCase { private static final String PORT = System . getProperty ( \"mysql.port\" ); @Test public void worksWithMysqlServer () { Connection conn = DriverManager . getConnection ( String . format ( \"jdbc:mysql://localhost:%s/root?user=root&password=root\" , FooITCase . PORT ) ); new JdbcSession ( conn ) . sql ( \"CREATE TABLE foo (id INT PRIMARY KEY)\" ) . execute (); } } If you're using Hibernate, just create a db.properties file in src/test/resources directory. In that file you would do something like: hibernate.connection.url = jdbc:mysql://localhost:${mysql.port}/root hibernate.connection.username = root hibernate.connection.password = root Maven will replace that ${mysql.port} with the number of reserved TCP port, during resources copying. This operation is called \"resources filtering\", and you can read about it here . That's pretty much it. I'm using jcabi-mysql-maven-plugin in a few projects, and it helps me to stay confident that my code works with a real MySQL server. I'm also using the Liquibase Maven plugin in order to populate an empty server with tables required for the application. Nevertheless, that is a story for the next post :) "},{"title":"Get Rid of Java Static Loggers","url":"/2014/05/23/avoid-java-static-logger.html","tags":["logging","java","slf4j"],"date":"2014-05-23 00:00:00 +0000","categories":[],"body":"This is a very common practice in Java (using LoggerFactory from slf4j ): import org.slf4j.LoggerFactory ; public class Foo { private static final Logger LOGGER = LoggerFactory . getLogger ( Foo . class ); public void save ( String file ) { // save the file if ( Foo . LOGGER . isInfoEnabled ()) { Foo . LOGGER . info ( \"file {} saved successfuly\" , file ); } } } What's wrong with it? Code duplication. This static LOGGER property has to be declared in every class where logging is required. Just a few lines of code, but this is pure noise, as I see it. To make life easier, I created a library about two years ago, jcabi-log , which has a convenient utility class Logger (yes, I know that utility classes are evil ). import com.jcabi.log.Logger ; public class Foo { public void save ( String file ) { // save the file Logger . info ( this , \"file %s saved successfuly\" , file ); } } This looks much cleaner to me and does exactly the same — sends a single log line to the SLF4J logging facility. Besides, it check automatically whether a given logging level is enabled (for performance optimization) and formats the given string using Formatter (same as String.format() ). For convenience, there are also a number of \"decors\" implemented in the library. The library ships as a JAR dependency in Maven Central (get its latest versions in Maven Central ): <dependency> <groupId> com.jcabi </groupId> <artifactId> jcabi-log </artifactId> </dependency> "},{"title":"Object-Oriented Java Adapter of Amazon S3 SDK","url":"/2014/05/26/amazon-s3-java-oop-adapter.html","tags":["aws","s3","java"],"date":"2014-05-26 00:00:00 +0000","categories":[],"body":" I'm a big fan of Amazon Web Services (AWS). I'm using them in almost all of my projects. One of their most popular services is Simple Storage Service (S3) . It is a storage for binary objects (files) with unique names, accessible through HTTP or RESTful API. Using S3 is very simple. You create a \"bucket\" with a unique name, upload your \"object\" into the bucket through their web interface or through RESTful API, and then download it again (either through HTTP or the API.) Amazon ships the Java SDK that wraps their RESTful API. However, this SDK is not object-oriented at all. It is purely imperative and procedural — it just mirrors the API. For example, in order to download an existing object doc.txt from bucket test-1 , you have to do something like this: AWSCredentials creds = new BasicAWSCredentials ( key , secret ); AmazonS3 aws = new AmazonS3Client ( creds ); S3Object obj = aws . getObject ( new GetObjectRequest ( \"test-1\" , \"doc.txt\" ) ); InputStream input = obj . getObjectContent (); String content = IOUtils . toString ( input , \"UTF-8\" ); input . close (); As always, procedural programming has its inevitable disadvantages. To overcome them all, I designed jcabi-s3 , which is a small object-oriented adapter for Amazon SDK. This is how the same object-reading task can be accomplished with jcabi-s3 : Region region = new Region . Simple ( key , secret ); Bucket bucket = region . bucket ( \"test-1\" ); Ocket ocket = bucket . ocket ( \"doc.txt\" ); String content = new Ocket . Text ( ocket ). read (); Why is this approach better? Well, there are a number of obvious advantages. S3 Object is an Object in Java S3 object get its representative in Java. It is not a collection of procedures to be called in order to get its properties (as with AWS SDK). Rather, it is a Java object with certain behaviors. I called them \"ockets\" (similar to \"buckets\"), in order to avoid clashes with java.lang.Object . Ocket is an interface, that exposes the behavior of a real AWS S3 object: read, write, check existence. There is also a convenient decorator Ocket.Text that simplifies working with binary objects: Ocket . Text ocket = new Ocket . Text ( ocket_from_s3 ); if ( ocket . exists ()) { System . out . print ( ocket . read ()); } else { ocket . write ( \"Hello, world!\" ); } Now, you can pass an object to another class, instead of giving it your AWS credentials, bucket name, and object name. You simply pass a Java object, which encapsulates all AWS interaction details. Extendability Through Decoration Since jcabi-s3 exponses all entities as interfaces, they can easily be extended through encapsulation ( Decorator Pattern ). For example, you want your code to retry S3 object read operations a few times before giving up and throwing an IOException (by the way, this is a very good practice when working with web services). So, you want all your S3 reading operations to be redone a few times if first attempts fail. You define a new decorator class, say, RetryingOcket , which encapsulates an original Ocket : public RetryingOcket implements Ocket { private final Ocket origin ; public RetryingOcket ( Ocket ocket ) { this . origin = ocket ; } @Override public void read ( OutputStream stream ) throws IOException { int attempt = 0 ; while ( true ) { try { this . origin . read ( stream ); } catch ( IOException ex ) { if ( attempt ++ > 3 ) { throw ex ; } } } } // same for other methods } Now, everywhere where Ocket is expected you send an instance of RetryingOcket that wraps your original object: foo . process ( new RetryingOcket ( ocket )); Method foo.process() won't see a difference, since it is the same Ocket interface it is expecting. By the way, this retry functionality is implemented out-of-the-box in jcabi-s3 , in com.jcabi.s3.retry package. Easy Mocking Again, due to the fact that all entities in jcabi-s3 are interfaces, they are very easy to mock. For example, your class expects an S3 object, reads its data and calculates the MD5 hash (I'm using DigestUtils from commons-codec ): import com.jcabi.s3.Ocket ; import org.apache.commons.codec.digest.DigestUtils ; public class S3Md5Hash { private final Ocket ocket ; public S3Md5Hash ( Ocket okt ) { this . ocket = okt ; } public hash () throws IOException { ByteArrayOutputStream baos = new ByteArrayOutputStream (); this . ocket . read ( baos ); return DigestUtils . md5hex ( baos . toByteArray ()); } } Here is how simple a unit test will look (try to create a unit test for a class using AWS SDK and you will see the difference): import com.jcabi.s3.Ocket ; import org.junit.Test ; public class S3Md5HashTest { @Test public void generatesHash () { Ocket ocket = Mockito . mock ( Ocket . class ); Mockito . doAnswer ( new Answer < Void >() { public Void answer ( final InvocationOnMock inv ) throws IOException { OutputStream . class . cast ( inv . getArguments ()[ 0 ]). write ( ' ' ); } } ). when ( ocket ). read ( Mockito . any ( OutputStream . class )); String hash = new S5Md5Hash ( ocket ); Assert . assertEquals ( hash , \"7215ee9c7d9dc229d2921a40e899ec5f\" ); } } I'm using JUnit and Mockito in this test. Immutability All classes in jcabi-s3 are annotated with @Immutable and are truly immutable. The library ships as a JAR dependency in Maven Central (get its latest versions in Maven Central ): <dependency> <groupId> com.jcabi </groupId> <artifactId> jcabi-s3 </artifactId> </dependency> As always, your comments and criticism are welcome as Github issues . "},{"title":"Java Method Logging with AOP and Annotations","url":"/2014/06/01/aop-aspectj-java-method-logging.html","tags":["aop","java","logging","jcabi"],"date":"2014-06-01 00:00:00 +0000","categories":["best"],"body":"Sometimes, I want to log (through slf4j and log4j ) every execution of a method, seeing what arguments it receives, what it returns and how much time every execution takes. This is how I'm doing it, with help of AspectJ , jcabi-aspects and Java 6 annotations: public class Foo { @Loggable public int power ( int x , int p ) { return Math . pow ( x , p ); } } This is what I see in log4j output: [INFO] com.example.Foo #power(2, 10): 1024 in 12μs [INFO] com.example.Foo #power(3, 3): 27 in 4μs Nice, isn't it? Now, let's see how it works. Annotation with Runtime Retention Annotations is a technique introduced in Java 6. It is a meta-programming instrument that doesn't change the way code works, but gives marks to certain elements (methods, classes or variables). In other words, annotations are just markers attached to the code that can be seen and read. Some annotations are designed to be seen at compile time only — they don't exist in .class files after compilation. Others remain visible after compilation and can be accessed in runtime. For example, @Override is of the first type (its retention type is SOURCE ), while @Test from JUnit is of the second type (retention type is RUNTIME ). @Loggable — the one I'm using in the script above — is an annotation of the second type, from jcabi-aspects . It stays with the bytecode in the .class file after compilation. Again, it is important to understand that even though method power() is annotated and compiled, it doesn't send anything to slf4j so far. It just contains a marker saying \"please, log my execution\". Aspect Oriented Programming (AOP) AOP is a useful technique that enables adding executable blocks to the source code without explicitly changing it. In our example, we don't want to log method execution inside the class. Instead, we want some other class to intercept every call to method power() , measure its execution time and send this information to slf4j. We want that interceptor to understand our @Loggable annotation and log every call to that specific method power() . And, of course, the same interceptor should be used for other methods where we'll place the same annotation in the future. This case perfectly fits the original intent of AOP — to avoid re-implementation of some common behavior in multiple classes. Logging is a supplementary feature to our main functionality, and we don't want to pollute our code with multiple logging instructions. Instead, we want logging to happen behind the scenes. In terms of AOP, our solution can be explained as creating an aspect that cross-cuts the code at certain join points and applies an around advice that implements the desired functionality. AspectJ Let's see what these magic words mean. But, first, let's see how jcabi-aspects implements them using AspectJ (it's a simplified example, full code you can find in MethodLogger.java ): @Aspect public class MethodLogger { @Around ( \"execution(* *(..)) && @annotation(Loggable)\" ) public Object around ( ProceedingJoinPoint point ) { long start = System . currentTimeMillis (); Object result = point . proceed (); Logger . info ( \"#%s(%s): %s in %[msec]s\" , MethodSignature . class . cast ( point . getSignature ()). getMethod (). getName (), point . getArgs (), result , System . currentTimeMillis () - start ); return result ; } } This is an aspect with a single around advice around() inside. The aspect is annotated with @Aspect and advice is annotated with @Around . As discussed above, these annotations are just markers in .class files. They don't do anything except provide some meta-information to those w ho are interested in runtime. Annotation @Around has one parameter, which — in this case — says that the advice should be applied to a method if: its visibility modifier is * ( public , protected or private ); its name is name * (any name); its arguments are .. (any arguments); and it is annotated with @Loggable When a call to an annotated method is to be intercepted, method around() executes before executing the actual method. When a call to method power() is to be intercepted, method around() receives an instance of class ProceedingJoinPoint and must return an object, which will be used as a result of method power() . In order to call the original method, power() , the advice has to call proceed() of the join point object. We compile this aspect and make it available in classpath together with our main file Foo.class . So far so good, but we need to take one last step in order to put our aspect into action — we should apply our advice. Binary Aspect Weaving Aspect weaving is the name of the advice applying process. Aspect weaver modifies original code by injecting calls to aspects. AspectJ does exactly that. We give it two binary Java classes Foo.class and MethodLogger.class ; it gives back three — modified Foo.class , Foo$AjcClosure1.class and unmodified MethodLogger.class . In order to understand which advices should be applied to which methods, AspectJ weaver is using annotations from .class files. Also, it uses reflection to browse all classes on classpath. It analyzes which methods satisfy the conditions from the @Around annotation. Of course, it finds our method power() . So, there are two steps. First, we compile our .java files using javac and get two files. Then, AspectJ weaves/modifies them and creates its own extra class. Our Foo class looks something like this after weaving: public class Foo { private final MethodLogger logger ; @Loggable public int power ( int x , int p ) { return this . logger . around ( point ); } private int power_aroundBody ( int x , int p ) { return Math . pow ( x , p ); } } AspectJ weaver moves our original functionality to a new method, power_aroundBody() , and redirects all power() calls to the aspect class MethodLogger . Instead of one method power() in class Foo now we have four classes working together. From now on, this is what happens behind the scenes on every call to power() : Original functionality of method power() is indicated by the small green lifeline on the diagram. As you see, the aspect weaving process connects together classes and aspects, transferring calls between them through join points. Without weaving, both classes and aspects are just compiled Java binaries with attached annotations. jcabi-aspects jcabi-aspects is a JAR library that contains Loggable annotation and MethodLogger aspect (btw, there are many more aspects and annotations). You don't need to write your own aspect for method logging. Just add a few dependencies to your classpath and configure jcabi-maven-plugin for aspect weaving (get their latest versions in Maven Central ): <project> <dependencies> <dependency> <groupId> com.jcabi </groupId> <artifactId> jcabi-aspects </artifactId> </dependency> <dependency> <groupId> org.aspectj </groupId> <artifactId> aspectjrt </artifactId> </dependency> </dependencies> <build> <plugins> <plugin> <groupId> com.jcabi </groupId> <artifactId> jcabi-maven-plugin </artifactId> <executions> <execution> <goals> <goal> ajc </goal> </goals> </execution> </executions> </plugin> </plugins> </build> </project> Since this weaving procedure takes a lot of configuration effort, I created a convenient Maven plugin with an ajc goal, which does the entire aspect weaving job. You can use AspectJ directly, but I recommend that you use jcabi-maven-plugin . That's it. Now you can use @com.jcabi.aspects.Loggable annotation and your methods will be logged through slf4j. If something doesn't work as explained, don't hesitate to submit a Github issue . "},{"title":"Objects Should Be Immutable","url":"/2014/06/09/objects-should-be-immutable.html","tags":["oop","anti-pattern"],"date":"2014-06-09 00:00:00 +0000","categories":["best"],"body":"In object-oriented programming, an object is immutable if its state can't be modified after it is created. In Java, a good example of an immutable object is String . Once created, we can't modify its state. We can request that it creates new strings, but its own state will never change. However, there are not so many immutable classes in JDK. Take, for example, class Date . It is possible to modify its state using setTime() . I don't know why the JDK designers decided to make these two very similar classes differently. However, I believe that the design of a mutable Date has a many flaws, while the immutable String is much more in the spirit of the object-oriented paradigm. Moreover, I think that all classes should be immutable in a perfect object-oriented world . Unfortunately, sometimes, it is technically not possible due to limitations in JVM. Nevertheless, we should always aim for the best. This is an incomplete list of arguments in favor of immutability: immutable objects are simpler to construct, test, and use truly immutable objects are always thread-safe they help to avoid temporal coupling their usage is side-effect free (no defensive copies) identity mutability problem is avoided they always have failure atomicity they are much easier to cache they prevent NULL references, which are bad Let's discuss the most important arguments one by one. Thread Safety The first and the most obvious argument is that immutable objects are thread-safe. This means that multiple threads can access the same object at the same time, without clashing with another thread. If no object methods can modify its state, no matter how many of them and how often are being called parallel — they will work in their own memory space in stack. Goetz et al. explained the advantages of immutable objects in more details in their very famous book Java Concurrency in Practice (highly recommended). Avoiding Temporal Coupling Here is an example of temporal coupling (the code makes two consecutive HTTP POST requests, where the second one contains HTTP body): 1 2 3 4 5 Request request = new Request ( \"http://example.com\" ); request . method ( \"POST\" ); String first = request . fetch (); request . body ( \"text=hello\" ); String second = request . fetch (); This code works. However, you must remember that the first request should be configured before the second one may happen. If we decide to remove the first request from the script, we will remove the second and the third line, and won't get any errors from the compiler: Request request = new Request ( \"http://example.com\" ); // request.method(\"POST\"); // String first = request.fetch(); request . body ( \"text=hello\" ); String second = request . fetch (); Now, the script is broken although it compiled without errors. This is what temporal coupling is about — there is always some hidden information in the code that a programmer has to remember. In this example, we have to remember that the configuration for the first request is also used for the second one. We have to remember that the second request should always stay together and be executed after the first one. If Request class were immutable, the first snippet wouldn't work in the first place, and would have been rewritten like: final Request request = new Request ( \"\" ); String first = request . method ( \"POST\" ). fetch (); String second = request . method ( \"POST\" ). body ( \"text=hello\" ). fetch (); Now, these two requests are not coupled. We can safely remove the first one, and the second one will still work correctly. You may point out that there is a code duplication. Yes, we should get rid of it and re-write the code: final Request request = new Request ( \"\" ); final Request post = request . method ( \"POST\" ); String first = post . fetch (); String second = post . body ( \"text=hello\" ). fetch (); See, refactoring didn't break anything and we still don't have temporal coupling. The first request can be removed safely from the code without affecting the second one. I hope this example demonstrates that the code manipulating immutable objects is more readable and maintainable, b ecause it doesn't have temporal coupling. Avoiding Side Effects Let's try to use our Request class in a new method (now it is mutable): public String post ( Request request ) { request . method ( \"POST\" ); return request . fetch (); } Let's try to make two requests — the first with GET method and the second with POST: Request request = new Request ( \"http://example.com\" ); request . method ( \"GET\" ); String first = this . post ( request ); String second = request . fetch (); Method post() has a \"side effect\" — it makes changes to the mutable object request . These changes are not really expected in this case. We expect it to make a POST request and return its body. We don't want to read its documentation just to find out that behind the scene it also modifies the request we're passing to it as an argument. Needless to say, such side effects lead to bugs and maintainability issues. It would be much better to work with an immutable Request : public String post ( Request request ) { return request . method ( \"POST\" ). fetch (); } In this case, we may not have any side effects. Nobody can modify our request object, no matter where it is used and how deep through the call stack it is passed by method calls: Request request = new Request ( \"http://example.com\" ). method ( \"GET\" ); String first = this . post ( request ); String second = request . fetch (); This code is perfectly safe and side effect free. Avoiding Identity Mutability Very often, we want objects to be identical if their internal states are the same. Date class is a good example: Date first = new Date ( 1L ); Date second = new Date ( 1L ); assert first . equals ( second ); // true There are two different objects; however, they are equal to each other because their encapsulated states are the same. This is made possible through their custom overloaded implementation of equals() and hashCode() methods. The consequence of this convenient approach being used with mutable objects is that every time we modify object's state it changes its identity: Date first = new Date ( 1L ); Date second = new Date ( 1L ); first . setTime ( 2L ); assert first . equals ( second ); // false This may look natural, until you start using your mutable objects as keys in maps: Map < Date , String > map = new HashMap <>(); Date date = new Date (); map . put ( date , \"hello, world!\" ); date . setTime ( 12345L ); assert map . containsKey ( date ); // false When modifying the state of date object, we're not expecting it to change its identity. We're not expecting to lose an entry in the map just because the state of its key is changed. However, this is exactly what is happening in the example above. When we add an object to the map, its hashCode() returns one value. This value is used by HashMap to place the entry into the internal hash table. When we call containsKey() hash code of the object is different (because it is based on its internal state) and HashMap can't find it in the internal hash table. It is a very annoying and difficult to debug side effects of mutable objects. Immutable objects avoid it completely. Failure Atomicity Here is a simple example: public class Stack { private int size ; private String [] items ; public void push ( String item ) { size ++; if ( size > items . length ) { throw new RuntimeException ( \"stack overflow\" ); } items [ size ] = item ; } } It is obvious that an object of class Stack will be left in a broken state if it throws a runtime exception on overflow. Its size property will be incremented, while items won't get a new element. Immutability prevents this problem. An object will never be left in a broken state because its state is modified only in its constructor. The constructor will either fail, rejecting object instantiation, or succeed, making a valid solid object, which never changes its encapsulated state. For more on this subject, read Effective Java, 2nd Edition by Joshua Bloch. Arguments Against Immutability There are a number of arguments against immutability. “Immutability is not for enterprise systems”. Very often, I hear people say that immutability is a fancy feature, while absolutely impractical in real enterprise systems. As a counter-argument, I can only show some examples of real-life applications that contain only immutable Java objects: jcabi-http , jcabi-xml , jcabi-github , jcabi-s3 , jcabi-dynamo , jcabi-simpledb The above are all Java libraries that work solely with immutable classes/objects. netbout.com and stateful.co are web applications that work solely with immutable objects. “It's cheaper to update an existing object than create a new one”. Oracle thinks that “The impact of object creation is often overestimated and can be offset by some of the efficiencies associated with immutable objects. These include decreased overhead due to garbage collection, and the elimination of code needed to protect mutable objects from corruption.” I agree. If you have some other arguments, please post them below and I'll try to comment. "},{"title":"Avoid String Concatenation","url":"/2014/06/19/avoid-string-concatenation.html","tags":["java","oop","anti-pattern"],"date":"2014-06-19 00:00:00 +0000","categories":[],"body":"This is \"string concatentation\", and it is a bad practice: // bad practice, don't reuse! String text = \"Hello, \" + name + \"!\" ; Why? Some may say that it is slow, mostly because parts of the resulting string are copied multiple times. Indeed, on every + operator, String class allocates a new block in memory and copies everything it has into it; plus a suffix being concatenated. This is true, but this is not the point here. Actually, I don't think performance in this case is a big issue. Moreover, there were multiple experiments showing that concatenation is not that slow when compared to other string building methods and sometimes is even faster. Some say that concatenated strings are not localizable because in different languages text blocks in a phrase may be positioned in a different order. The example above can't be translated to, say, Russian, where we would want to put a name in front of \"привет\". We will need to localize the entire block of code, instead of just translating a phrase. However, my point here is different. I strongly recommend avoiding string concatenation because it is less readable than other methods of joining texts together. Let's see these alternative methods. I'd recommend three of them (in order of preference): String.format() , Apache StringUtils and Guava Joiner . There is also a StringBuilder , but I don't find it as attractive as StringUtils . It is a useful builder of strings, but not a proper replacer or string concatenation tool when readability is important. String.format() String.format() is my favorite option. It makes text phrases easy to understand and modify. It is a static utility method that mirrors sprintf() from C. It allows you to build a string using a pattern and substitutors: String text = String . format ( \"Hello, %s!\" , name ); When the text is longer, the advantages of the formatter become much more obvious. Look at this ugly code: String msg = \"Dear \" + customer . name () + \", your order #\" + order . number () + \" has been shipped at \" + shipment . date () + \"!\" ; This one looks much more beautiful doesn’t it: String msg = String . format ( \"Dear %1$s, your order #%2$d has been shipped at %3$tR!\" , customer . name (), order . number (), shipment . date () ); Please note that I'm using argument indexes in order to make the pattern even more localizable. Let's say, I want to translate it to Greek. This is how will it look: Αγαπητέ %1$s, στις %3$tR στείλαμε την παραγγελία σου με αριθμό #%2$d! I'm changing the order of substitutions in the pattern, but not in the actual list of methods arguments. Apache StringUtils.join() When the text is rather long (longer than your screen width), I would recommend that you use the utility class StringUtils from Apache commons-lang3 : import org.apache.commons.lang3.StringUtils ; String xml = StringUtils . join ( \"<?xml version='1.0'?>\" , \"<html><body>\" , \"<p>This is a test XHTML document,\" , \" which would look ugly,\" , \" if we would use a single line,\" \" or string concatenation or String format().</p>\" \"</body></html>\" ); The need to include an additional JAR dependency to your classpath may be considered a downside with this method (get its latest versions in Maven Central ): <dependency> <groupId> org.apache.commons </groupId> <artifactId> commons-lang3 </artifactId> </dependency> Guava Joiner Similar functionality is provided by Joiner from Google Guava : import com.google.common.base.Joiner ; String text = Joiner . on ( '' ). join ( \"WE HAVE BUNNY.\\n\" , \"GATHER ONE MILLION DOLLARS IN UNMARKED \" , \"NON-CONSECUTIVE TWENTIES.\\n\" , \"AWAIT INSTRUCTIONS.\\n\" , \"NO FUNNY STUFF\" ); It is a bit less convenient than StringUtils since you always have to provide a joiner (character or a string placed between text blocks). Again, a dependency is required in this case: <dependency> <groupId> com.google.guava </groupId> <artifactId> guava </artifactId> </dependency> Yes, in most cases, all of these methods work slower than a plain simple concatenation. However, I strongly believe that computers are cheaper than people . What I mean is that the time spent by programmers understanding and modifying ugly code is much more expensive than a cost of an additional server that will make beautifully written code work faster. If you know any other methods of avoiding string concatenation, please comment below. "},{"title":"Limit Java Method Execution Time","url":"/2014/06/20/limit-method-execution-time.html","tags":["java","aop"],"date":"2014-06-20 00:00:00 +0000","categories":[],"body":" Say, you want to allow a Java method to work for a maximum of five seconds and want an exception to be thrown if the timeframe is exceeded. Here is how you can do it with jcabi-aspects and AspectJ : public class Resource { @Timeable ( limit = 5 , unit = TimeUnit . SECONDS ) public String load ( URL url ) { return url . openConnection (). getContent (); } } Keep in mind that you should weave your classes after compilation, as explained here . Let's discuss how this actually works, but first, I recommend you read this post , which explains how AOP aspects work together with Java annotations. Due to @Timeable annotation and class weaving, every call to a method load() is intercepted by an aspect from jcabi-aspects . That aspect starts a new thread that monitors the execution of a method every second, checking whether it is still running. If the method runs for over five seconds, the thread calls interrupt() on the method's thread. Despite a very common expectation that a thread should be terminated immediately on that call, it is not happening at all. This article explains the mechanism in more detail. Let's discuss it briefly: interrupt() sets a marker in a thread; The thread checks interrupted() as often as it can; If the marker is set, the thread stops and throws InterruptedException This method will not react to interrupt() call and will work until JVM is killed (very bad design): public void work () { while ( true ) { // do something } } This is how we should refactor it in order to make sensitive to interruption requests: public void work () { while ( true ) { if ( Thread . interruped ()) { throw new InterruptedException (); } // do something } } In other words, your method can only stop itself. Nothing else can do it. The thread it is running in can't be terminated by another thread. The best thing that the other thread can do is to send your thread a \"message\" (through interrupt() method) that it's time to stop. If your thread ignores the message, nobody can do anything. Most I/O operations in JDK are designed this way. They check the interruption status of their threads while waiting for I/O resources. Thus, use @Timeable annotation, but keep in mind that there could be situations when a thread can't be interrupted. "},{"title":"CasperJS Tests in Maven Build","url":"/2014/06/21/casperjs-with-maven.html","tags":["maven","casperjs","phantomjs","testing"],"date":"2014-06-21 00:00:00 +0000","categories":[],"body":"I'm a big fan of automated testing in general and integration testing in particular. I strongly believe that effort spent on writing tests are direct investments into quality and stability of the product under development. CasperJS is a testing framework on top of PhantomJS , which is a headless browser. Using CasperJS, we can ensure that our application responds correctly to requests sent by a regular web browser. This is a sample CasperJS test, which makes an HTTP request to a home page of a running WAR application and asserts that the response has 200 HTTP status code: casper . test . begin ( 'home page can be rendered' , function ( test ) { casper . start ( casper . cli . get ( 'home' ), // URL of home page function () { test . assertHttpStatus ( 200 ); } ); casper . run ( function () { test . done (); } ); } ); I keep this test in the src/test/casperjs/home-page.js file. Let's see how CasperJS can be executed automatically on every Maven build. Here is the test scenario, implemented with a combination of Maven plugins: Install PhantomJS Install CasperJS Reserve a random TCP port Start Tomcat on that TCP port (with WAR inside) Run CasperJS tests and point them to the running Tomcat Shutdown Tomcat I'm using a combination of plugins. Let's go through the steps one by one. BTW, I'm not showing plugin versions in the examples below, primarily because most of them are in active development. Check their versions at Maven Central (yes, all of them are available there). 1. Install PhantomJS First of all, we have to download the PhantomJS executable. It is a platform-specific binary. Thanks to Kyle Lieber , we have an off-the-shelf Maven plugin: phantomjs-maven-plugin that understands what the current platform is and downloads the appropriate binary automatically, placing it into the target directory. <plugin> <groupId> com.github.klieber </groupId> <artifactId> phantomjs-maven-plugin </artifactId> <executions> <execution> <goals> <goal> install </goal> </goals> </execution> </executions> <configuration> <version> 1.9.2 </version> </configuration> </plugin> The exact name of the downloaded binary is stored in the ${phantomjs.binary} Maven property. 2. Install CasperJS Unfortunately, there is no similar plugin for the CasperJS installation (at least I haven't found any as of yet). That's why I'm using plain old git (you should have it installed on your build machine). <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> exec-maven-plugin </artifactId> <executions> <execution> <id> casperjs-install </id> <phase> pre-integration-test </phase> <goals> <goal> exec </goal> </goals> <configuration> <executable> git </executable> <arguments> <argument> clone </argument> <argument> --depth=1 </argument> <argument> https://github.com/n1k0/casperjs.git </argument> <argument> ${project.build.directory}/casperjs </argument> </arguments> </configuration> </execution> </executions> </plugin> 3. Reserve TCP Port I need to obtain a random TCP port where Tomcat will be started. The port has to be available on the build machine. I want to be able to run multiple Maven builds in parallel, so that's why I get a random port on every build. In other examples, you may see people using fixed port numbers, like 5555 or something similar. This is a very bad practice. Always reserve a new random port when you need it. <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> build-helper-maven-plugin </artifactId> <executions> <execution> <id> tomcat-port </id> <goals> <goal> reserve-network-port </goal> </goals> <configuration> <portNames> <portName> tomcat.port </portName> </portNames> </configuration> </execution> </executions> </plugin> The plugin reserves a port and sets it value to the ${tomcat.port} Maven property. 4. Start Tomcat Now, it's time to start Tomcat with the WAR package inside. I'm using tomcat7-maven-plugin that starts a real Tomcat7 server and configures it to serve on the port reserved above. <plugin> <groupId> org.apache.tomcat.maven </groupId> <artifactId> tomcat7-maven-plugin </artifactId> <configuration> <path> / </path> </configuration> <executions> <execution> <id> start-tomcat </id> <phase> pre-integration-test </phase> <goals> <goal> run-war-only </goal> </goals> <configuration> <port> ${tomcat.port} </port> <fork> true </fork> </configuration> </execution> </executions> </plugin> Due to the option fork being set to true , Tomcat7 continues to run when the plugin execution finishes. That's exactly what I need. 5. Run CasperJS Now, it's time to run CasperJS. Even though there are some plugins exist for this, I'm using plain old exec-maven-plugin , mostly because it is more configurable. <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> exec-maven-plugin </artifactId> <executions> <execution> <id> casperjs-test </id> <phase> integration-test </phase> <goals> <goal> exec </goal> </goals> <configuration> <executable> ${project.build.directory}/casperjs/bin/casperjs </executable> <workingDirectory> ${basedir} </workingDirectory> <arguments> <argument> test </argument> <argument> --verbose </argument> <argument> --no-colors </argument> <argument> --concise </argument> <argument> --home=http://localhost:${tomcat.port} </argument> <argument> ${basedir}/src/test/casperjs </argument> </arguments> <environmentVariables> <PHANTOMJS_EXECUTABLE> ${phantomjs.binary} </PHANTOMJS_EXECUTABLE> </environmentVariables> </configuration> </execution> </executions> </plugin> The environment variable PHANTOMJS_EXECUTABLE is the undocumented feature that makes this whole scenario possible. It configures the location of the PhantomJS executable, which was downloaded a few steps above. 6. Shutdown Tomcat In the last step, I shut down the Tomcat server. <plugin> <groupId> org.apache.tomcat.maven </groupId> <artifactId> tomcat7-maven-plugin </artifactId> <executions> <execution> <id> stop-tomcat </id> <phase> post-integration-test </phase> <goals> <goal> shutdown </goal> </goals> </execution> </executions> </plugin> Real Example If you want to see how this all works in action, take a look at stateful.co . It is a Java Web application hosted at CloudBees . Its source code is open and available in Github . Its pom.xml contains exactly the same configurations explained above, but joined together. If you have any questions, please don't hesitate to ask below. "},{"title":"Deploy Jekyll to Github Pages","url":"/2014/06/24/jekyll-github-deploy.html","tags":["jekyll","github","ruby"],"date":"2014-06-24 00:00:00 +0000","categories":[],"body":"This blog is written in Jekyll and is hosted at Github Pages . It uses half a dozen custom plugins, which are not allowed there . Here is how I deploy it: $ jgd That's it. jgd is my Ruby gem (stands for \"Jekyll Github Deploy\"), which does the trick. Here is what it does : It clones your existing repository from the current directory to a temporary one (guessing the URL of the repo from .git/config file). Runs jekyll build in that temporary directory, which saves the output in another temporary directory. Checks out gh-pages branch or creates one if it doesn't exist. Copies the content of the site built by jekyll build into the branch, thus overwriting existing files, commits and pushes to Github. Cleans up all temporary directories. Using this gem is very easy. Just install it with gem install jgd and then run in the root directory of your Jekyll blog. What is important is that your Jekyll site files be located in the root directory of the repository. Just as they do on this blog; see its sources in Github . You can easily integrate jgd with Travis. See .travis.yml of this blog. Full documentation about the gem is located here . "},{"title":"XML+XSLT in a Browser","url":"/2014/06/25/xml-and-xslt-in-browser.html","tags":["xslt","java","restful"],"date":"2014-06-25 00:00:00 +0000","categories":[],"body":"Separating data and their presentation is a great concept. Take HTML and CSS for example. HTML is supposed to have pure data and CSS is supposed to format that data in order to make it readable by a human. Years ago, that was probably the intention of HTML/CSS, but in reality it doesn't work like that. Mostly because CSS is not powerful enough. We still have to format our data using HTML tags, while CSS can help slightly with positioning and decorating. On the other hand, XML with XSLT implements perfectly the idea of separating data and presentation. XML documents, like HTML, are supposed to contain data only without any information about positioning or formatting. XSL stylesheets position and decorate the data. XSL is a much more powerful language. That's why it's possible to avoid any formatting inside XML. The latest versions of Chrome, Safari, FireFox and IE all support this mechanism. When a browser retrieves an XML document from a server, and the document has an XSL stylesheet associated with it — the browser transforms XML into HTML on-fly. Working Example Let's review a simple Java web application that works this way. It is using ReXSL framework that makes this mechanism possible. In the next post, I'll explain how ReXSL works. For now, though, let's focus on the idea of delivering bare data in XML and formatting it with an XSL stylesheet. Open http://www.stateful.co — it is a collection of stateful web primitives, explained in the Atomic Counters at Stateful.co article. Open it in Chrome or Safari. When you do, you should see a normal web page with a logo, some text, some links, a footer, etc. Now check its sources (I assume you know how to do this). This is approximately what you will see (I assume you understand XML, if not, start learning it immediately): <?xml-stylesheet type='text/xsl' href='/xsl/index.xsl'?> <page date= \"2014-06-15T15:30:49.521Z\" ip= \"10.168.29.135\" > <menu> home </menu> <documentation> .. some text here .. </documentation> <version> <name> 1.4 </name> <revision> 5c7b5af </revision> <date> 2014-05-29 07:58 </date> </version> <links> <link href= \"...\" rel= \"rexsl:google\" type= \"text/xml\" /> <link href= \"...\" rel= \"rexsl:github\" type= \"text/xml\" /> <link href= \"...\" rel= \"rexsl:facebook\" type= \"text/xml\" /> </links> <millis> 70 </millis> </page> As you see, it is a proper XML document with attributes, elements and data. It contains absolutely no information about how its elements have to be presented to an end-user. Actually, this document is more suitable for machine parsing instead of reading by a human. The document contains data, which is important for its requestor. It's up to the requestor on how to render the data or to not render it at all. Its second line associates the document with the XSL stylesheet /xsl/index.xsl that is loaded by the browser separately: <?xml-stylesheet type='text/xsl' href='/xsl/index.xsl'?> Open developer tools in Chrome and you will see that right after the page is loaded, the browser loads the XSL stylesheet and then all other resources including a few CSS stylesheets, jQuery and an SVG logo: index.xsl includes layout.xsl , that's why it is loaded right after. Let's consider an example of index.xsl (in reality it is much more complex, check layout.xsl . For example: <xsl:stylesheet version= \"2.0\" xmlns:xsl= \"http://www.w3.org/1999/XSL/Transform\" xmlns= \"http://www.w3.org/1999/xhtml\" > <xsl:template match= \"page\" > <html> <body> <p> Current version of the application is <xsl:value-of select= \"version/name\" /> </p> </body> </html> </xsl:template> </xsl:stylesheet> I think it's obvious how the HTML page will look like after applying this XSL stylesheet to our XML document. For me, this XSL looks clean and easy to understand. However, I often hear people say that XSLT is a hard-to-understand programming language. I don't find it hard to understand at all. Of course, I'm not using all of its features. But, for simple page rendering, all I need to know are a few simple commands and the principle of XML transformation. Why Not a Templating Engine? Now, why is this approach better than all that widely use Java templating engines, including JSP , JSF , Velocity , FreeMarker , Tiles , etc? Well, I see a number of reasons. But, the most important are: Web UI and API are same pages . There is no need to develop separate pages for RESTful API — Web user interface, being accessed by a computer, is an API. In my experience, this leads to massive avoidance of code duplication. XSL is testable by itself without a server . In order to test how our web site will look with certain data, we just create a new XML document with necessary test data, associate it with an XSL and open it in a browser. We can also modify XML and refresh the page in browser. This makes the work of HTML/CSS designer much easier and independent of programmers. XSL is a powerful functional language . Compared with all other templating engines, which look mostly like workarounds, XSL is a complete and well-designed environment. Writing XSL (after you get used to its syntax and programming concepts) is a pleasure in itself. You're not injecting instructions into a HTML document (like in JSP and all others). Instead, you are programming transformation of data into presentation — a different mindset and much better feeling. XML output is perfectly testable . A controller in MVC that generates an XML document with all data required for the XSL stylesheet can easily be tested in a single unit test using simple XPath expressions. Testing of a controller that injects data into a templating engine is a much more complex operation — even impossible sometimes. I'm also writing in PHP and Ruby. They have exactly the same problems — even though their templating engines are much more powerful due to the interpretation nature of the languages. Is It Fully Supported? Everything would be great if all browsers would support XML+XSL rendering. However, this is far from being true. Only the latest versions of modern browsers support XSL. Check this comparison done by Julian Reschke. Besides that, XSLT 2.0 is not supported at all. There is a workaround, though. We can understand which browser is making a request (via its User-Agent HTTP header) and transform XML into HTML on the server side. Thus, for modern browsers that support XSL, we will deliver XML and for all others — HTML. This is exactly how ReXSL framework works. Open http://www.stateful.co in Internet Explorer and you will see an HTML document, not an XML document as is the case with Chrome. In one of the next posts, I'll explain ReXSL framework . Read this one, it continues the discussion of this subject: RESTful API and a Web Site in the Same URL "},{"title":"SASS in Java Webapp","url":"/2014/06/26/sass-in-java-webapp.html","tags":["java","sass"],"date":"2014-06-26 00:00:00 +0000","categories":[],"body":"SASS is a powerful and very popular language for writing CSS style sheets. This is how I'm using SASS in my Maven projects. First, I change the extensions of .css files to .scss and move them from src/main/webapp/css to src/main/scss . Then, I configure the sass-maven-plugin (get its latest versions in Maven Central ): <plugin> <groupId> org.jasig.maven </groupId> <artifactId> sass-maven-plugin </artifactId> <executions> <execution> <id> generate-css </id> <phase> generate-resources </phase> <goals> <goal> update-stylesheets </goal> </goals> <configuration> <sassSourceDirectory> ${basedir}/src/main/scss </sassSourceDirectory> <destination> ${project.build.directory}/css </destination> </configuration> </execution> </executions> </plugin> The SASS compiler will compile .scss files from src/main/scss and place .css files into target/css . Then, I configure the minify-maven-plugin to compress/minify the style sheets produced by the SASS compiler: <plugin> <groupId> com.samaxes.maven </groupId> <artifactId> minify-maven-plugin </artifactId> <configuration> <charset> UTF-8 </charset> <nosuffix> true </nosuffix> <webappTargetDir> ${project.build.directory}/css-min </webappTargetDir> </configuration> <executions> <execution> <id> minify-css </id> <goals> <goal> minify </goal> </goals> <configuration> <webappSourceDir> ${project.build.directory} </webappSourceDir> <cssSourceDir> css </cssSourceDir> <cssSourceIncludes> <include> *.css </include> </cssSourceIncludes> <skipMerge> true </skipMerge> </configuration> </execution> </executions> </plugin> Minified .css files will be placed into target/css-min . The final step is to configure the maven-war-plugin to pick up .css files and package them into the final WAR archive: <plugin> <artifactId> maven-war-plugin </artifactId> <configuration> [..other configuration options..] <webResources combine.children= \"append\" > <resource> <directory> ${project.build.directory}/css-min </directory> </resource> </webResources> </configuration> </plugin> That's it. "},{"title":"Custom Pygments Lexer in Jekyll","url":"/2014/06/29/custom-lexer-in-jekyll.html","tags":["jekyll","pygments"],"date":"2014-06-29 00:00:00 +0000","categories":[],"body":"I needed to create a custom syntax highlighting for requs.org on which I'm using Jekyll for site rendering. This is how my code blocks look in markdown pages: { % highlight requs %} User is a \"human being\". { % endhighlight %} I created a custom Pygments lexer : from pygments.lexer import RegexLexer from pygments.token import Punctuation , Text , Keyword , Name , String from pygments.util import shebang_matches class RequsLexer ( RegexLexer ): name = 'requs' aliases = [ 'requs' ] tokens = { 'root' : [ ( r'\"[^\"]+\"' , String ), ( r'\"\"\".+\"\"\"' , Text ), ( r'\\b(needs|includes|requires|when|fail|since|must|is|a|the)\\s*\\b' , Keyword ), ( r'([A-Z][a-z]+)+' , Name ), ( r'[,;:]' , Punctuation ), ], } def analyse_text ( text ): return shebang_matches ( text , r'requs' ) Then, I packaged it for easy_install and installed locally: $ easy_install src/requs_pygment Processing requs_pygment Running setup.py -q bdist_egg --dist-dir /Volumes/ssd2/code/requs/src/requs_pygment/egg-dist-tmp-ISj8Nx zip_safe flag not set ; analyzing archive contents... Adding requs-pygment 0.1 to easy-install.pth file Installed /Library/Python/2.7/site-packages/requs_pygment-0.1-py2.7.egg Processing dependencies for requs-pygment == 0.1 Finished processing dependencies for requs-pygment == 0.1 It's done. Now I run jekyll build and my syntax is highlighted according to the custom rules I specified in the lexer. "},{"title":"How to Read MANIFEST.MF Files","url":"/2014/07/03/how-to-read-manifest-mf.html","tags":["java","jcabi"],"date":"2014-07-03 00:00:00 +0000","categories":[],"body":" Every Java package (JAR, WAR, EAR, etc.) has a MANIFEST.MF file in the META-INF directory. The file contains a list of attributes, which describe this particular package. For example: Manifest-Version: 1.0 Created-By: 1.7.0_06 (Oracle Corporation) Main-Class: MyPackage.MyClass When your application has multiple JAR dependencies, you have multiple MANIFEST.MF files in your class path. All of them have the same location: META-INF/MANIFEST.MF . Very often it is necessary to go through all of them in runtime and find the attribute by its name. jcabi-manifests makes it possible with a one-liner: import com.jcabi.manifests.Manifests ; String created = Manifests . read ( \"Created-By\" ); Let's see why you would want to read attributes from manifest files, and how it works on a low level. Package Versioning When you package a library or even a web application, it is a good practice to add an attribute to its MANIFEST.MF with the package version name and build number. In Maven, maven-jar-plugin can help you (almost the same configuration for maven-war-plugin ): <plugin> <artifactId> maven-jar-plugin </artifactId> <configuration> <archive> <manifestEntries> <Foo-Version> ${project.version} </Foo-Version> <Foo-Hash> ${buildNumber} </Foo-Hash> </manifestEntries> </archive> </configuration> </plugin> buildnumber-maven-plugin will help you to get ${buildNumber} from Git, SVN or Mercurial: <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> buildnumber-maven-plugin </artifactId> <executions> <execution> <goals> <goal> create </goal> </goals> </execution> </executions> </plugin> After all these manipulations, MANIFEST.MF , in your JAR will contain these two extra lines (on top of all others added there by Maven by default): Foo-Version: 1.0-SNAPSHOT Foo-Hash: 7ef4ac3 In runtime, you can show these values to the user to help him understand which version of the product he is working with at any given moment. Look at stateful.co , for example. At the bottom of its front page, you see the version number and Git hash. They are retrieved from MANIFEST.MF of the deployed WAR package, on every page click. Credentials Although this may be considered as a bad practice (see Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation by Jez Humble and David Farley), sometimes it is convenient to package production credentials right into the JAR/WAR archive during the continuous integration/delivery cycle. For example, you can encode your PostgreSQL connection details right into MANIFEST.MF : <plugin> <artifactId> maven-war-plugin </artifactId> <configuration> <archive> <manifestEntries> <Pgsql> jdbc:postgresql://${pg.host}:${pg.port}/${pg.db} </Pgsql> </manifestEntries> </archive> </configuration> </plugin> Afterwards, you can retrieve them in runtime using jcabi-manifests : String url = Manifests . read ( \"Pgsql\" ); If you know of any other useful purposes for MANIFEST.MF , let me know :) "},{"title":"Liquibase with Maven","url":"/2014/07/20/liquibase-in-maven.html","tags":["liquibase","maven","java"],"date":"2014-07-20 00:00:00 +0000","categories":[],"body":"Liquibase is a migration management tool for relational databases. It versionalizes schema and data changes in a database; similar to the way Git or SVN works for source code. Thanks to their Maven plugin , Liquibase can be used as a part of a build automation scenario. Maven Plugin Let's assume you're using MySQL (PostgreSQL or any other database configuration will be very similar.) Add liquibase-maven-plugin to your pom.xml (get its latest version in Maven Central ): <project> [...] <build> [...] <plugins> <plugin> <groupId> org.liquibase </groupId> <artifactId> liquibase-maven-plugin </artifactId> <configuration> <changeLogFile> ${basedir}/src/main/liquibase/master.xml </changeLogFile> <driver> com.mysql.jdbc.Driver </driver> <url> jdbc:mysql://${mysql.host}:${mysql.port}/${mysql.db} </url> <username> ${mysql.login} </username> <password> ${mysql.password} </password> </configuration> </plugin> </plugins> </build> </project> To check that it works, run mvn liquibase:help . I would recommend you keep database credentials in settings.xml and in their respective profiles. For example: <settings> <profiles> <profile> <id> production </id> <properties> <mysql.host> db.example.com </mysql.host> <mysql.port> 3306 </mysql.port> <mysql.db> example </mysql.db> </properties> </profile> <profile> <id> test </id> <properties> <mysql.host> test-db.example.com </mysql.host> <mysql.port> 3306 </mysql.port> <mysql.db> example-db </mysql.db> </properties> </profile> </profiles> </settings> When you run Maven, don't forget to turn on one of the profiles. For example: mvn -Pproduction . Initial Schema I assume you already have a database with a schema (tables, triggers, views, etc.) and some data. You should \"reverse engineer\" it and create an initial schema file for Liquibase. In other words, we should inform Liquibase where we are at the moment, so that it starts to apply changes from this point. Maven plugin doesn't support it, so you will have to run Liquibase directly. But, it's not that difficult. First, run mvn liquibase:help in order to download all artifacts. Then, replace placeholders with your actual credentials: $ java -jar ~/.m2/repository/org/liquibase/liquibase-core/3.1.1/liquibase-core-3.1.1.jar \\ --driver = com.mysql.jdbc.Driver \\ --url = jdbc:mysql://db.example.com:3306/example \\ --username = example --password = example \\ generateChangeLog > src/main/liquibase/2014/000-initial-schema.xml Liquibase will analyze your current database schema and copy its own schema into src/main/liquibase/2014/000-initial-schema.xml . Master Changeset Now, create XML master changeset and save it to src/main/liquibase/master.xml : <databaseChangeLog xmlns= \"http://www.liquibase.org/xml/ns/dbchangelog\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-2.0.xsd\" > <includeAll path= \"src/main/liquibase/2014\" /> </databaseChangeLog> It is an entry point for Liquibase. It starts from this file and loads all other changesets available in src/main/liquibase/2014 . They should be either .xml or .sql . I recommend that you use XML mostly because it is easier to maintain and works faster. Incremental Changesets Let's create a simple changeset, which adds a new column to an existing table: <databaseChangeLog xmlns= 'http://www.liquibase.org/xml/ns/dbchangelog' xmlns:xsi= 'http://www.w3.org/2001/XMLSchema-instance' xsi:schemaLocation= 'http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-2.0.xsd' > <changeSet id= \"002\" author= \"Yegor\" > <sql> ALTER TABLE user ADD COLUMN address VARCHAR(1024); </sql> </changeSet> </databaseChangeLog> We save this file we in src/main/liquibase/2014/002-add-user-address.xml . In big projects, you can name your files by the names of the tickets they are produced in. For example, 045-3432.xml , which means changeset number 45 coming from ticket #3432. The important thing is to have this numeric prefix in front of file names, in order to sort them correctly. We want changes to be applied in their correct chronological order. That's it. We're ready to run mvn liquibase:update -Pproduction and our production database will be updated — a new column will be added to the user table. Also, see how MySQL Maven Plugin can help you to automate integration testing of database-connected classes. "},{"title":"Master Branch Must Be Read-Only","url":"/2014/07/21/read-only-master-branch.html","tags":["rultor","devops","mgmt"],"date":"2014-07-21 00:00:00 +0000","categories":["best"],"body":"Continuous integration is easy. Download Jenkins, install, create a job, click the button, and get a nice email saying that your build is broken (I assume your build is automated). Then, fix broken tests (I assume you have tests), and get a much better looking email saying that your build is clean. Then, tweet about it, claiming that your team is using continuous integration. Then, in a few weeks, start filtering out Jenkins alerts, into their own folder, so that they don't bother you anymore. Anyway, your team doesn't have the time or desire to fix all unit tests every time someone breaks them. After all, we all know that unit testing is not for a team working with deadlines, right? Wrong. Continuous integration can and must work. What is Continuous Integration? Nowadays, software development is done in teams. We develop in feature branches and isolate changes while they are in development. Then, we merge branches into master . After every merge, we test the entire product, executing all available unit and integration tests. This is called continuous integration (aka \"CI\"). Sometimes, some tests fail. When this happens, we say that our \"build is broken\". Such a failure is a positive side effect of quality control because it raises a red flag immediately after an error gets into master . It is a well-known practice, when fixing that error becomes a top priority for its author and the entire team. The error should be fixed right after a red flag is raised by the continuous integration server. Continuous Delivery by Jez Humble et. al. explains this approach perfectly in Chapter 7, pages 169–186. There are a few good tools on the market, which automate DevOps procedures. Some of them are open source, you can download and install them on your own servers. For example: Jenkins , Go , and CruiseControl . Some of them are available as a service in cloud, such as: Travis , Drone , Wercker , and many others. Why Continuous Integration Doesn't Work? CI is great, but the bigger the team (and the code base), the more often builds get broken. And, the longer it takes to fix them. I've seen many examples where a hard working team starts to ignore red flags, raised by Jenkins, after a few weeks or trying to keep up. The team simply becomes incapable of fixing all errors in time. Mostly because the business has other priorities. Product owners do not understand the importance of a \"clean build\" and technical leaders can't buy time for fixing unit tests. Moreover, the code that broke them was already in master and, in most cases, has been already deployed to production and delivered to end-users. What's the urgency of fixing some tests if business value was already delivered? In the end, most development teams don't take continuous integration alerts seriously. Jenkins or Travis are just fancy tools for them that play no role in the entire development and delivery pipeline. No matter what continuous integration server says, we still deliver new features to our end-users. We'll fix our build later. And it's only logical. What Is a Solution? Four years ago I published an article in php|Architect called \"Prevent Conflicts in Distributed Agile PHP Projects\". In the article, a solution was proposed (full article in PDF ) for Subversion and PHP. Since that time, I used experimentally that approach in multiple open source projects and a few commercial ones with PHP, Java, Ruby and JavaScript, Git and Subversion. In all cases, my experience was only positive, and that's why rultor.com was born (later about that though). So, the solution is simple — prohibit anyone from merging anything into master and create scripts that anyone can call. The script will merge, test, and commit. The script will not make any exceptions. If any branch is breaking at even one unit test, the entire branch will be rejected. In other words, we should raise that red flag before the code gets into master . We should put the blame for broken tests on the shoulders of its author. Say, I'm developing a feature in my own branch. I finished the development and broke a few tests, accidentally. It happens, we all make mistakes. I can't merge my changes into master . Git simply rejects my push , because I don't have the appropriate permissions. All I can do is call a magic script, asking it to merge my branch. The script will try to merge, but before pushing into master , it will run all tests. And if any of them break, my branch will be rejected. My changes won't be merged. Now it's my responsibility — to fix them and call the script again. In the beginning, this approach slows down the development, because everybody has to start writing cleaner code. At the end, though, this method pays off big time. Pre-flight Builds Some CI servers offer pre-flight builds feature, which means testing branches before they get merged into master . Travis, for example, has this feature and it is very helpful. When you make a new commit to a branch, Travis immediately tries to build it, and reports in Github pull request, if there are problems. Pay attention, pre-flight builds don't merge. They just check whether your individual branch is clean. After merge, it can easily break master . And, of course, this mechanism doesn't guarantee that no collaborators can commit directly to master , breaking it accidentally. Pre-flight builds are a preventive measure, but do not solve the problem entirely. Rultor.com In order to start working as explained above, all you have to do is to revoke write permissions to master branch (or /trunk , in Subversion). Unfortunately, this is not possible in Github. The only solution is to work through forks and pull requests only. Simply remove everybody from the list of \"collaborators\" and they will have to submit changes through pull requests. Then, start using Rultor.com , which will help you to test, merge and push every pull request. Basically, Rultor is the script we were talking about above. It is available as a free cloud service. "},{"title":"Rultor.com, a Merging Bot","url":"/2014/07/24/rultor-automated-merging.html","tags":["rultor","devops"],"date":"2014-07-24 00:00:00 +0000","categories":["best"],"body":" You get a Github pull request. You review it. It looks correct — it's time to merge it into master . You post a comment in it, asking @rultor to test and merge. Rultor starts a new Docker container, merges the pull request into master , runs all tests and, if everything looks clean — merges, pushes, and closes the request. Then, you ask @rultor to deploy the current version to production environment. It checks out your repository, starts a new Docker container, executes your deployment scripts and reports to you right there in the Github issue. Why not Jenkins or Travis? There are many tools on the market, which automate continuous integration and continuous delivery (let's call them DevOps). For example, downloadable open-source Jenkins and hosted Travis both perform these tasks. So, why do we need one more? Well, there are three very important features that we need for our projects, but we can't find all of them in any of the DevOps tools currently available on the market: Merging . We make master branch read-only in our projects, as this article recommends. All changes into master we pass through a script that validates them and merges. Docker . Every build should work in its own Docker container, in order to simplify configuration, isolate resources and make errors easily reproduceable. Tell vs. Trigger . We need to communicate with DevOps tool through commands, right from our issue tracking system (Github issues, in most projects). All existing DevOps systems trigger builds on certain conditions. We need our developers to be able to talk to the tool, through human-like commands in the tickets they are working with. A combination of these three features is what differs Rultor from all other existing systems. How Rultor Merges Once Rultor finds a merge command in one of your Github pull requests, it does exactly this: Reads the .rultor.yml YAML config file from the root directory of your repository. Gets automated build execution command from it, for example bundle test . Checks out your repository into a temporary directory on one of its servers. Merges pull request into master branch. Starts a new Docker container and runs bundle test in it. If everything is fine, pushes modified master branch to Github. Reports back to you, in the Github pull request. You can see it in action, for example, in this pull request: jcabi/jcabi-github#878 . "},{"title":"Every Build in Its Own Docker Container","url":"/2014/07/29/docker-in-rultor.html","tags":["docker","rultor","devops"],"date":"2014-07-29 00:00:00 +0000","categories":[],"body":" Docker is a command line tool that can run a shell command in a virtual Linux, inside an isolated file system. Every time we build our projects, we want them to run in their own Docker containers. Take this Maven project for example: $ sudo docker run -i -t ubuntu mvn clean test This command will start a new Ubuntu system and execute mvn clean test inside it. Rultor.com , our virtual assistant, does exactly that with our builds, when we deploy, package, test and merge them. Why Docker? What benefits does it give us? And why Docker, when there are many other virtualization technologies , like LXC, for example? Well, there are a few very important benefits: Image repository (hub.docker.com) Versioning Application-centric Let's discuss them in details. Image Repository Docker enables image sharing through its public repository at hub.docker.com . This means that after I prepare a working environment for my application, I make an image out of it and push it to the hub. Let's say, I want my Maven build to be executed in a container with a pre-installed graphviz package (in order to enable dot command line tool). First, I would start a plain vanilla Ubuntu container, and install graphviz inside it: $ sudo docker run -i -t ubuntu /bin/bash root@215d2696e8ad:/# sudo apt-get install -y graphviz Reading package lists... Done Building dependency tree Reading state information... Done The following extra packages will be installed: ... root@215d2696e8ad:/# exit $ sudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 215d2696e8ad ubuntu:14.04 /bin/bash About a minute ago Exited ( 0 ) 3 seconds ago high_mccarthy I have a container that stopped a few seconds ago. Container's ID is 215d2696e8ad . Now, I want to make it reusable for all further tests in Rultor.com. I have to create an image from it: $ sudo docker commit 215d2696e8ad yegor256/beta c5ad7718fc0e20fe4bf2c8a9bfade4db8617a25366ca5b64be2e1e8aa0de6e52 I just made my new commit to a new image yegor256/beta . This image can be reused right now. I can create a new container from this image and it will have graphviz installed inside! Now it's time to share my image at Docker hub, in order to make it available for Rultor: $ sudo docker push yegor256/beta The push refers to a repository [ yegor256/beta ] ( len: 1 ) Sending image list Pushing repository yegor256/beta ( 1 tags ) 511136ea3c5a: Image already pushed, skipping d7ac5e4f1812: Image already pushed, skipping 2f4b4d6a4a06: Image already pushed, skipping 83ff768040a0: Image already pushed, skipping 6c37f792ddac: Image already pushed, skipping e54ca5efa2e9: Image already pushed, skipping c5ad7718fc0e: Image successfully pushed Pushing tag for rev [ c5ad7718fc0e ] on { https://registry-1.docker.io/v1/repositories/yegor256/beta/tags/latest } The last step is to configure Rultor to use this image in all builds. To do this, I will edit .rultor.yml in the root directory of my Github repository: docker : image : yegor256/beta That's it. From now on, Rultor will use my custom Docker image with pre-installed graphviz, in every build (merge, release, deploy, etc.) Moreover, if and when I want to add something else to the image, it's easy to do. Say, I want to install Ruby into my build image. I start a container from the image and install it (pay attention, I'm starting a container not from ubuntu image, as I did before, but from yegor256/beta ): $ sudo docker run -i -t yegor256/beta /bin/bash root@7e0fbd9806c9:/# sudo apt-get install -y ruby Reading package lists... Done Building dependency tree Reading state information... Done The following extra packages will be installed: ... root@7e0fbd9806c9:/# exit $ sudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7e0fbd9806c9 yegor256/beta:latest /bin/bash 28 seconds ago Exited ( 0 ) 2 seconds ago pensive_pare 215d2696e8ad ubuntu:14.04 /bin/bash 10 minutes ago Exited ( 0 ) 8 minutes ago high_mccarthy You can now see that I have two containers. The first one is the one I am using right now; it contains Ruby. The second one is the one I was using before and it contains graphviz. Now I have to commit again and push: $ sudo docker commit 7e0fbd9806c9 yegor256/beta 6cbfb7a6b18a2182f42171f6bb5aef67c4819b5c2795edffa6a63ba78aaada2d $ sudo docker push yegor256/beta ... Thus, this Docker hub is a very convenient feature for Rultor and similar systems. Versioning As you saw in the example above, every change to a Docker image has its own version (hash) and it's possible to track changes. It is also possible to roll back to any particular change. Rultor is not using this functionality itself, but Rultor users are able to control their build configurations with much better precision. Application-Centric Docker, unlike LXC or Vagrant, for example, is application-centric. This means that when we start a container — we start an application. With other virtualization technologies, when you get a virtual machine — you get a fully functional Unix environment, where you can login through SSH and do whatever you want. Docker makes things simpler. It doesn't give you SSH access to container, but runs an application inside and shows you its output. This is exactly what we need in Rultor. We need to run an automated build (for example Maven or Bundler), see its output and get its exit code. If the code is not zero, we fail the build and report to the user. This is how we run Maven build: $ sudo docker run --rm -i -t yegor256/rultor mvn clean test [ INFO ] ------------------------------------------------------------------------ [ INFO ] Building jcabi-github 0.13 [ INFO ] ------------------------------------------------------------------------ [ INFO ] [ INFO ] --- maven-clean-plugin:2.5:clean ( default-clean ) @ jcabi-github --- [ INFO ] ... As you can see, Maven starts immediately. We don't worry about the internals of the container. We just start an application inside it. Furthermore, thanks to the --rm option, the container gets destroyed immediately after Maven execution is finished. This is what application-centric is about. Our overall impression of Docker is highly positive. "},{"title":"Rultor + Travis","url":"/2014/07/31/travis-and-rultor.html","tags":["docker","rultor","devops"],"date":"2014-07-31 00:00:00 +0000","categories":["best"],"body":" Rultor is a coding team assistant. Travis is a hosted continuous integration system. In this article I'll show how our open source projects are using them in tandem to achieve seamless continuous delivery. I'll show a few practical scenarios. Scenario #1: Merge Pull Request jcabi-mysql-maven-plugin is a Maven plugin for MySQL integration testing . @ChristianRedl submitted pull request #35 with a new feature. I reviewed the request and asked Rultor to merge it into master : As you can see, an actual merge operation was made by Rultor. I gave him access to the project by adding his Github account to the list of project collaborators. Before giving a \"go ahead\" to Rultor I checked the status of the pre-build reported by Travis: Travis found a new commit in the pull request and immediately (without any interaction from my side) triggered a build in that branch. The build didn't fail, that's why Travis gave me a green sign. I looked at that sign and at the code. Since all problems in the code were corrected by the pull request author and Travis didn't complain — I gave a \"go\" to Rultor. Scenario #2: Continuous Integration Even though the previous step guarantees that master branch is always clean and stable, we're using Travis to continuously integrate it. Every commit made to master triggers a new build in Travis. The result of the build changes the status of the project in Travis: either \"failing\" or \"passing\". jcabi-aspects is a collection of AOP AspectJ aspects . We configured Travis to build it continuously. This is the badge it produces (the left one): Again, let me stress that even through read-only master is a strong protection against broken builds, it doesn't guarantee that at any moment master is stable. For example, sometimes unit tests fail sporadically due to changes in calendar, in environment, in dependencies, in network connection qualities, etc. Well, ideally, unit tests should either fail or pass because they are environment independent. However, in reality, unit tests are far from being ideal. That's why a combination of read-only master with Rultor and continuous integration with Travis gives us higher stability. Scenario #3: Release to RubyGems jekyll-github-deploy is a Ruby gem that automates deployment of Jekyll sites to Github Pages . @leucos submitted a pull request #4 with a new feature. The request was merged successfully into master branch. Then, Rultor was instructed by myself that master branch should be released to RubyGems and a new version to set is 1.5: Rultor executed a simple script, pre-configured in its .rultor.yml : release : script : | ./test.sh rm -rf *.gem sed -i \"s/2.0-SNAPSHOT/${tag}/g\" jgd.gemspec gem build jgd.gemspec chmod 0600 ../rubygems.yml gem push *.gem --config-file ../rubygems.yml The script is parameterized, as you see. There is one parameter that is passed by Rultor into the script: ${tag} . This parameter was provided by myself in the Github issue, when I submitted a command to Rultor. The script tests that the gem works (integration testing) and clean up afterwords: $ ./test.sh $ rm -rf *.gem Then, it changes the version of itself in jgd.gemspec to the one provided in the ${tag} (it is an environment variable), and builds a new .gem : $ sed -i \"s/2.0-SNAPSHOT/${tag}/g\" jgd.gemspec $ gem build jgd.gemspec Finally, it pushes a newly built .gem to RubyGems, using login credentials from ../rubygems.yml . This file is created by Rultor right before starting the script (this mechanism is discussed below): $ chmod 0600 ../rubygems.yml $ gem push *.gem --config-file ../rubygems.yml If everything works fine and RubyGems confirms successful deployment, Rultor reports to Github. This is exactly what happened in pull request #4 . Scenario #4: Deploy to CloudBees s3auth.com is a Basic HTTP authentication gateway for Amazon S3 Buckets . It is a Java web app. In its pull request #195 , a resource leakage problem was fixed by @carlosmiranda and the pull request was merged by Rultor. Then, @davvd instructed Rultor to deploy master branch to production environment. Rultor created a new Docker container and ran mvn clean deploy in it. Maven deployed the application to CloudBees : The overall procedure took 21 minutes, as you see the in the report generated by Rultor. There is one important trick worth mentioning. Deployment to production always means using secure credentials, like login, password, SSH keys, etc. In this particular example, Maven CloudBees Plugin needed API key, secret and web application name. These three parameters are kept secure and can't be revealed in an \"open source\" way. So, there is a mechanism that configures Rultor accordingly through its .rultor.yml file (pay attention to the first few lines): assets : settings.xml : \"yegor256/home#assets/s3auth/settings.xml\" pubring.gpg : \"yegor256/home#assets/pubring.gpg\" secring.gpg : \"yegor256/home#assets/secring.gpg\" These YAML entries inform Rultor that it has to get assets/s3auth/settings.xml file from yegor256/home private (!) Github repository and put it into the working directory of Docker container, right before starting the Maven build. This settings.xml file contains that secret data CloudBees plugin needs in order to deploy the application. How to Deploy to CloudBees, in One Click explains this process even better. You Can Do The Same Both Rultor and Travis are free hosted products, provided your projects are open source and hosted at Github. Other good examples of Rultor+Travis usage can be seen in these Github issues: jcabi/jcabi-http#47 , jcabi/jcabi-http#48 "},{"title":"Cache Java Method Results","url":"/2014/08/03/cacheable-java-annotation.html","tags":["java","jcabi","aop"],"date":"2014-08-03 00:00:00 +0000","categories":[],"body":" Say, you have a method that takes time to execute and you want its result to be cached. There are many solutions , including Apache Commons JCS , Ehcache , JSR 107 , Guava Caching and many others. jcabi-aspects offers a very simple one, based on AOP aspects and Java6 annotations: import com.jcabi.aspects.Cacheable ; public class Page { @Cacheable ( lifetime = 5 , unit = TimeUnit . MINUTES ) String load () { return new URL ( \"http://google.com\" ). getContent (). toString (); } } The result of load() method will be cached in memory for five minutes. How It Works? This post about AOP, AspectJ and method loging explains how \"aspect weaving\" works (I highly recommend that you read it first). Here I'll explain how caching works. The approach is very straight forward. There is a static hash map with keys as \"method coordinates\" and values as their results. Method coordinates consist of the object, an owner of the method and a method name with parameter types. In the example above, right after the method load() finishes, the map gets a new entry (simplified example, of course): key: [page, \"load()\"] value: \"<html>...</html>\" Every consecutive call to load() will be intercepted by the aspect from jcabi-aspects and resolved immediately with a value from the cache map. The method will not get any control until the end of its lifetime, which is five minutes in the example above. What About Cache Flushing? Sometimes it's necessary to have the ability to flush cache before the end of its lifetime. Here is a practical example: import com.jcabi.aspects.Cacheable ; public class Employees { @Cacheable ( lifetime = 1 , unit = TimeUnit . HOURS ) int size () { // calculate their amount in MySQL } @Cacheable.FlushBefore void add ( Employee employee ) { // add a new one to MySQL } } It's obvious that the number of employees in the database will be different after add() method execution and the result of size() should be invalidated in cache. This invalidation operation is called \"flushing\" and @Cacheable.FlushBefore triggers it. Actually, every call to add() invalidates all cached methods in this class, not only size() . There is also @Cacheable.FlushAfter . The difference is that FlushBefore guarantees that cache is already invalidated when the method add() starts. FlushAfter invalidates cache after method add() finishes. This small difference makes a big one, sometimes. This article explains how to add jcabi-aspects to your project . "},{"title":"Strict Control of Java Code Quality","url":"/2014/08/13/strict-code-quality-control.html","tags":["java","qulice","static-analysis"],"date":"2014-08-13 00:00:00 +0000","categories":["best"],"body":"There are many tools that control the quality of Java code, including Checkstyle , PMD , FindBugs , Cobertura , etc. All of them are usually used to analyze quality and build some fancy reports. Very often, those reports are published by continuous integration servers, like Jenkins. Qulice takes things one step further. It aggregates a few quality checkers, configures them to a maximum strict mode, and breaks your build if any of them fail. Seriously. There are over 130 checks in Checkstyle, over 400 rules in PMD, and over 400 bugs in FindBugs. All of them should say: \"Yes, we like your code\". Otherwise, your build shouldn't pass. What do you think? Would it be convenient for you — to have your code rejected every time it breaks just one of 900 checks? Would it be productive for the team — to force developers to focus so much on code quality? First Reaction If you join one of our teams as a Java developer, you will develop your code in branches and, then, Rultor will merge your changes into master . Before actually merging, though, Rultor will run an automated build script to make sure that your branch doesn't break it. As a static analysis tool, Qulice is just one of the steps in the automated build script. It is actually a Maven plugin and we automate Java builds with Maven 3x. Thus, if your changes break any of Qulice's rules, your entire branch gets rejected. Your first reaction - I've seen it hundreds of times - will be negative. You may actually become frustrated enough to leave the project immediately. You may say something like this (I'm quoting real life stories): \"These quality rules entirely ruin my creativity!\" \"Instead of wasting time on these misplaced commas and braces, we'd be better off developing new features!\" \"I've done many successful projects in my life, never heard about this ridiculous quality checking...\" This first reaction is only logical. I've seen many people say things like this, in both open source and commercial projects. Not only in Java, but also in PHP (with phpcs and phpmd ) and Ruby (with rubocop and simplecov ). How do I answer? Read on. On Second Thought My experience tells me that the sooner someone can get used to the strict quality control of Qulice, the faster he/she can learn and grow; the better programmer he/she is; and the further he/she can go with us and our projects. Having this experience in mind, I recommend that all new project members be patient and try to get used to this new approach to quality. In a few weeks, those who stick with it start to understand why this approach is good for the project and for them, as Java engineers. Ratatouille (2007) by Brad Bird and Jan Pinkava Why is it good? Read on. What Do Projects Get From Qulice? Let's take one simple rule as an example. Here is a piece of Java code that Qulice would complain about (due to the DesignForExtension rule from Checkstyle): public class Employee { public String name () { return \"Jeff\" ; } } What is wrong with this code? Method name() is not final and can be overridden by a class that extends Employee . Design-wise this is wrong, since a child class is allowed to break a super class, overriding its method. What is the right design? This one: public class Employee { public final String name () { return \"Jeff\" ; } } Now, the method is final and can't be overriden by child classes. It is a much safer design (according to Checkstyle, and I agree). So, let's say we make this rule mandatory for all classes in the project. What does the project gain from this? It can promise its members (programmers) a higher quality of work, compared to other projects that don't have this restriction, mostly because of: Predictability of Design — I don't have to scroll through the entire class to make sure it doesn't have methods that can be accidentally overriden. I know for sure that this can't happen in this project. In other words, I know what to expect. Less Hidden Tricks — Higher predictability of design leads to better visibility of mistakes and tricks. Standardization of source code makes it uniform. This means that it's easier to read and spot problems. Industry Standards — The decision to use this design is made by Checkstyle, not by a project architect. For me, as a project developer, this means that I'm following industry standards. That makes the project (and its leaders) more respectable. Learning — I'll bet that most of you who read this post didn't know about the design rule explained above. Just by reading this article, you learned something new. Imagine how much you could learn after making your code compliant to all 900 rules of Qulice (Checkstyle + PMD + FindBugs). The point about learning brings us to the last, and the most important, thought to discuss. What Do I Get from Qulice? As a programmer, I hope you already realize what you get from working in a project that raises its quality bar as high as Qulice asks. Yes, you'll learn a lot of new things about writing quality Java code. On top of that though, I would actually say that you are getting free lessons with every new line of code you write. And the teacher is a software, written by hundreds of Java developers, for the last ten years. Qulice just integrates those software tools together. Truthfully, it is the developers who are the real authors of quality checks and rules. So, what do I tell those who complain about quality rules being too strict? I say this: \"Do you want to learn and improve, or do you just want to get paid and get away with it?\" "},{"title":"How to Retry Java Method Call on Exception","url":"/2014/08/15/retry-java-method-on-exception.html","tags":["jcabi","java","aop"],"date":"2014-08-15 00:00:00 +0000","categories":[],"body":" If you have a method that fails occasionally and you want to retry it a few times before throwing an exception. @RetryOnFailure from jcabi-aspects can help. For example, if you're downloading the following web page: @RetryOnFailure ( attempts = 3 , delay = 10 , unit = TimeUnit . SECONDS ) public String load ( URL url ) { return url . openConnection (). getContent (); } This method call will throw an exception only after three failed executions with a ten seconds interval between them. This post explains how jcabi-aspects works with binary weaving. This mechanism integrates AspectJ with your code. When method load() from the example above is called, this is what is happening behind the scene (pseudo-code): while ( attempts ++ < 3 ) { try { return original_load ( url ); } catch ( Throwable ex ) { log ( \"we failed, will try again in 10 seconds\" ); sleep ( 10 ); } } This approach may be very useful in the following situations (based on my experience): Executing JDBC SELECT statements Loading data from HTTP, S3, FTP, etc resources Uploading data over the network Fetching data through RESTful stateless APIs The project is in Github . "},{"title":"Fluent JDBC Decorator","url":"/2014/08/18/fluent-jdbc-decorator.html","tags":["jcabi","java","jdbc"],"date":"2014-08-18 00:00:00 +0000","categories":[],"body":" This is how you fetch text from a SQL table with jcabi-jdbc : String name = new JdbcSession ( source ) . sql ( \"SELECT name FROM employee WHERE id = ?\" ) . set ( 1234 ) . select ( new SingleOutcome < String >( String . class )); Simple and straight forward, isn't it? The library simplifies interaction with relational databases via JDBC, avoiding the need to use ORMs. jcabi-jdbc is a lightweight wrapper of JDBC . It is very convenient to use when you don't need a full-scale ORM (like Hibernate), but want just to select, insert, or update a few rows in a relational database. Every instance of JdbcSession is a \"transaction\" in a database. You start it by instantiating the class with a single parameter — data source. You can obtain the data source from your connection pool. There are many implementations of connection pools. I would recommend that you use BoneCP . Below is an example of how you would connect to PostgreSQL: @Cacheable ( forever = true ) private static DataSource source () { BoneCPDataSource src = new BoneCPDataSource (); src . setDriverClass ( \"org.postgresql.Driver\" ); src . setJdbcUrl ( \"jdbc:postgresql://localhost/db_name\" ); src . setUser ( \"jeff\" ); src . setPassword ( \"secret\" ); return src ; } Be sure to pay attention to the @Cacheable annotation. This post explains how it can help you to cache Java method results for some time. Setting the forever attribute to true means that we don't want this method to be called more than once. Instead, we want the connection pool to be created just once, and every second call should return its existing instance (kind of like a Singleton pattern). jcabi-jdbc website explains how you can insert , update , or delete a row. You can also execute any SQL statement . By default, JdbcSession closes the JDBC connection right after the first select/update/insert operation. Simply put, it is designed to be used mainly for single atomic transactions. However, it is possible to leave the connection open and continue, for example: new JdbcSession ( source ) . autocommit ( false ) . sql ( \"START TRANSACTION\" ) . update () . sql ( \"DELETE FROM employee WHERE name = ?\" ) . set ( \"Jeff Lebowski\" ) . update () . sql ( \"INSERT INTO employee VALUES (?)\" ) . set ( \"Walter Sobchak\" ) . insert ( Outcome . VOID ) . commit (); In this example we're executing three SQL statements one by one, leaving connection (and transaction) open unti commit() is called. "},{"title":"How to Release to Maven Central, in One Click","url":"/2014/08/19/how-to-release-to-maven-central.html","tags":["java","rultor","devops","maven"],"date":"2014-08-19 00:00:00 +0000","categories":[],"body":"When I release a new version of jcabi-aspects , a Java open source library, to Maven Central, it takes 30 seconds of my time. Maybe even less. Recently, I released version 0.17.2. You can see how it all happened, in Github issue #80 : As you see, I gave a command to Rultor , and it released a new version to Maven central. I didn't do anything else. Now let's see how you can do the same. How you can configure your project so that the release of its new version to Maven Central takes just a few seconds of your time. By the way, I assume that you're hosting your project in Github. If not, this entire tutorial won't work. If you are still not in Github, I would strongly recommend moving there. Prepare Your POM Make sure your pom.xml contains all elements required by Sonatype, explained in Central Sync Requirements . We will deploy to Sonatype, and they will syncronize all JAR (and not only) artifacts to Maven Central. Register a Project With Sonatype Create an account in Sonatype JIRA and raise a ticket, asking to approve your groupId. This OSSRH Guide explains this step in more detail. Create and Distribute a GPG Key Create a GPG key and distribute it, as explained in this Working with PGP Signatures article. When this step is done, you should have two files: pubring.gpg and secring.gpg . Create settings.xml Create settings.xml , next to the two .gpg files created in the previous step: <settings> <profiles> <profile> <id> foo </id> <!-- give it the name of your project --> <properties> <gpg.homedir> /home/r </gpg.homedir> <gpg.keyname> 9A105525 </gpg.keyname> <gpg.passphrase> my-secret </gpg.passphrase> </properties> </profile> </profiles> <servers> <server> <id> sonatype </id> <username> <!-- Sonatype JIRA user name --> </username> <password> <!-- Sonatype JIRA pwd --> </password> </server> </servers> </settings> In this example, 9A105525 is the ID of your public key, and my-secret is the pass phrase you have used while generating the keys. Encrypt Security Assets Now, encrypt these three files with a Rultor public key ( 9AF0FA4C ): gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 9AF0FA4C gpg --trust-model always -a -e -r 9AF0FA4C pubring.gpg gpg --trust-model always -a -e -r 9AF0FA4C secring.gpg gpg --trust-model always -a -e -r 9AF0FA4C settings.xml You will get three new files: pubring.gpg.asc , secring.gpg.asc and settings.xml.asc . Add them to the root directory of your project, commit and push. The files contain your secret information, but only the Rultor server can decrypt them. Add Sonatype Repositories I would recommend using jcabi-parent , as a parent pom for your project. This will make many further steps unnecessary. If you're using jcabi-parent, skip this step. However, if you don't use jcabi-parent, you should add these two repositories to your pom.xml : <project> [...] <distributionManagement> <repository> <id> oss.sonatype.org </id> <url> https://oss.sonatype.org/service/local/staging/deploy/maven2/ </url> </repository> <snapshotRepository> <id> oss.sonatype.org </id> <url> https://oss.sonatype.org/content/repositories/snapshots </url> </snapshotRepository> </distributionManagement> </project> Configure GPG Plugin Again, I'd recommend using http://parent.jcabi.com , which configures this plugin automatically. If you're using it, skip this step. Otherwise, add this plugin to your pom.xml : <project> [..] <build> [..] <plugins> [..] <plugin> <artifactId> maven-gpg-plugin </artifactId> <version> 1.5 </version> <executions> <execution> <id> sign-artifacts </id> <phase> verify </phase> <goals> <goal> sign </goal> </goals> </execution> </executions> </plugin> </plugins> </build> </project> Configure Versions Plugin Once again, I recommend using http://parent.jcabi.com . It configures all required plugins out-of-the-box. If you're using it, skip this step. Otherwise, add this plugin to your pom.xml : <project> [..] <build> [..] <plugins> [..] <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> versions-maven-plugin </artifactId> <version> 2.1 </version> <configuration> <generateBackupPoms> false </generateBackupPoms> </configuration> </plugin> </plugins> </build> </project> Configure Sonatype Plugin Yes, you're right, http://parent.jcabi.com will help you here as well. If you're using it, skip this step too. Otherwise, add these four plugins to your pom.xml : <project> [..] <build> [..] <plugins> [..] <plugin> <artifactId> maven-deploy-plugin </artifactId> <configuration> <skip> true </skip> </configuration> </plugin> <plugin> <artifactId> maven-source-plugin </artifactId> <executions> <execution> <id> package-sources </id> <goals> <goal> jar </goal> </goals> </execution> </executions> </plugin> <plugin> <artifactId> maven-javadoc-plugin </artifactId> <executions> <execution> <id> package-javadoc </id> <phase> package </phase> <goals> <goal> jar </goal> </goals> </execution> </executions> </plugin> <plugin> <groupId> org.sonatype.plugins </groupId> <artifactId> nexus-staging-maven-plugin </artifactId> <version> 1.6 </version> <extensions> true </extensions> <configuration> <serverId> oss.sonatype.org </serverId> <nexusUrl> https://oss.sonatype.org/ </nexusUrl> <description> ${project.version} </description> </configuration> <executions> <execution> <id> deploy-to-sonatype </id> <phase> deploy </phase> <goals> <goal> deploy </goal> <goal> release </goal> </goals> </execution> </executions> </plugin> </plugins> </build> </project> Create Rultor Config Create a .rultor.yml file in the root directory of your project ( reference page explains this format in details): decrypt : settings.xml : \"repo/settings.xml.asc\" pubring.gpg : \"repo/pubring.gpg.asc\" secring.gpg : \"repo/secring.gpg.asc\" release : script : | mvn versions:set \"-DnewVersion=${tag}\" git commit -am \"${tag}\" mvn clean deploy --settings /home/r/settings.xml You can compare your file with live Rultor configuration of jcabi-aspects . Run It! Now it's time to see how it all works. Create a new ticket in the Github issue tracker, and post something like that into it (read more about Rultor commands ): @rultor release, tag is `0.1` You will get a response in a few seconds. The rest will be done by Rultor. Enjoy :) BTW, if something doesn't work as I've explained, don't hesitate to submit a ticket to Rultor issue tracker . I will try to help you. Yeah, forgot to mention, Rultor is also doing two important things. First, it creates a Github release with a proper description. Second, it posts a tweet about the release, which you can retweet, to make an announcement to your followers. Both features are very convenient for me. For example: DynamoDB Local Maven Plugin, 0.7.1 released https://t.co/C3KULouuKS — rultor.com (@rultors) August 19, 2014 "},{"title":"The Art of Software Testing by Glenford Myers","url":"/2014/08/22/art-of-software-testing.html","tags":["book-review","testing"],"date":"2014-08-22 00:00:00 +0000","categories":[],"body":" \"The Art of Software Testing\" by Glenford J. Myers, Tom Badgett and Corey Sandler is one of my favorite books concerning testing and software engineering in general. In this article, I will provide an overview of the book, as well as highlight the ideas and quotes that I found to be the most interesting. There were three editions of the book. The first one was published in 1979, when I was just too young to appreciate it. The second one was published in 2004 — I read it first in 2007. The third one was published just two years ago, in 2012. I bought this edition also, and read it like it was my first time. This book is still one of the top books in the software testing domain, despite its age and some content that is rather out-dated. Out-dated Content First, let's filter out what is not worth reading (in my opinion). There are eleven chapters, but you can easily skim through nine of them. This is because those chapter discuss concepts that are discussed elsewhere in the book with a more robust level of detail or on a much higher level of abstraction. For example, Chapter 3 contains an eleven-page checklist to be used by a code reviewer in order to find programming mistakes. This list is definitely not comprehensive and it can't compete with, say, \"Code Complete\" by Steve McConnell. I believe, this checklist had significant value twenty years ago, but now it is out of date. Chapter 5 discusses basic principles and strategies of unit testing. However, the discussion is not abstract enough for a short 25-page summary, and is not specific enough for a detailed discussion. Again, twenty years ago this information may have had some value. Nowadays, \"Growing Object-Oriented Softare, Guided by Tests\" by Steven Freeman and Nat Pryce is a much better source for this subject. There are also articles about usability testing, debugging, web application testing, and mobile testing. Here we have the same issue — they are not abstract enough and they are much too outdated to be relevant to the current issues in software testing. I would recommend readers to briefly skim those subjects for background information, but to not read too much into it. Psychology of Testing The most important and valuable part of the book is Chapter 2. It is full of priceless quotes that can also be very practical. For example, on page 6: Testing is a destructive, even sadistic, process, which explains why most people find it difficult In Chapter 2, Dr. Myers discusses the psychology of testing and a very common and crucial misunderstanding of testing objectives. He claims that it is commonly accepted that the goal of software testing is \"to show that a program performs its intended functions correctly\" (p.5). Testers are hired to check whether the software functions as expected. They then report back to management whether all tests have successfully passed and whether the program can be delivered to end users. Despite the plethora of software testing tomes available on the market today, many developers seem to have an attitude that is counter to extensive testing This is what Dr. Myers says on the second page, and I can humbly confirm that in all software groups I've been worked in thus far, almost everyone, including testers, project managers, and programmers, share this philosophy. They all believe that \"testing is the process of demonstrating that errors are not present\" (p.5) However, \"these definitions are upside down\" (p.6). The psychology of testing should be viewed as the opposite. There are two quotes that support this theory and I feel that they make the entire book. The first one, on page 6, defines the goal of software testing: Testing is the process of executing a program with the intent of finding errors The second one, on the following page, further refines the first goal: An unsuccessful test case is one that causes a program to produce the correct results without finding any errors Dr. Myers comes back to these two thoughts in every chapter. He reiterates over and over again that we should change the underlying psychology of how we view testing, in order to change our testing results. We should focus on breaking the software instead of confirming that it works. Because testing is a \"sadistic process\" (p.6) of breaking things. It is a \"destructive process\" (p.8). If you read Chapter2 very carefully and truly understand its underlying ideas, it may change your entire life :) This chapter should be a New Testament of every tester. Test Completion Criteria In Chapter 2, Dr. Myers also mentions that a program, no matter how simple, contains an unlimited number of errors. He says that \"you cannot test a program to guarantee that it is error free\" (p.10) and that \"it is impractical, often impossible, to find all the errros in a program\" (p.8). Furthermore, at the end of Chapter 6, he makes an important observation (p.135): One of the most difficult questions to answer when testing a program is determining when to stop, since there is no way of knowing if the error just detected is the last remaining error The problem is obvious. Since any program contains an unlimited number of errors, it doesn't matter how long we test, we won't find all of them. So when do we stop? What goals do we set for our testers? And even more importantly, when do we pay them and how much (this question is important to me since I only work with contractors and am required to define measurable and achievable goals)? The answer Dr. Myers gives is brilliant (p.136): Since the goal of testing is to find errors, why not make the completion criterion the detection of some predefined number of errors? He then goes on to discuss exactly how this \"predefined number\" can be estimated. I find this idea very interesting. I have even applied it to a few projects I've had in the last few years. It works. However it can also cause serious psychological problems for the team. Most people simply resent the goal of \"testing until you find a required number of bugs.\" The most common response is \"what if there are no bugs any more?\". However, after a few fights, the team eventually begins to appreciate the concept and get used to it. So, I can humbly confirm that Dr. Myers is right in his suggestion. You can successful plan testing based on a predefined number of errors. Summary I consider this book a fundamental writing in the area of software testing. This is mostly due to Chapter 2 of the book. In fact, there are just three pages of text that build the foundation of the entire book. They are the skeleton of the other two hundred pages. Unfortunately, since 1979, this skeleton hasn't become the backbone of the software testing industry. Most of us are still working against these principles. "},{"title":"How to Deploy to CloudBees, in One Click","url":"/2014/08/25/deploy-to-cloudbees.html","tags":["java","rultor","devops"],"date":"2014-08-25 00:00:00 +0000","categories":[],"body":"When I deploy a new version of stateful.co , a Java web application, to CloudBees, it takes 30 seconds of my time. Maybe even less. Recently, I deployed version 1.6.5. You can see how it all happened, in Github issue #6 : As you see, I gave a command to Rultor , and it packaged, tested and deployed a new version to CloudBees. I didn't do anything else. Now let's see how you can do the same. How you can configure your project so that the deployment of its new version to CloudBees takes just a few seconds of your time. Since CloudBees is [shutting down its PaaS service](http://www.cloudbees.com/press/cloudbees-becomes-enterprise-jenkins-company) by the end of December, 2014, this article will have no sense after that. Configure the CloudBees Maven Plugin Add this profile to your pom.xml : <project> [..] <profiles> <profile> <id> cloudbees </id> <activation> <property><name> bees.appId </name></property> </activation> <pluginRepositories> <pluginRepository> <id> cloudbees-public-release </id> <url> http://repository-cloudbees.forge.cloudbees.com/public-release </url> </pluginRepository> </pluginRepositories> <build> <pluginManagement> <plugins> <plugin> <artifactId> maven-deploy-plugin </artifactId> <configuration> <skip> true </skip> </configuration> </plugin> </plugins> </pluginManagement> <plugins> <plugin> <groupId> com.cloudbees </groupId> <artifactId> bees-maven-plugin </artifactId> <version> 1.3.2 </version> <configuration> <appid> ${bees.id} </appid> <apikey> ${bees.key} </apikey> <secret> ${bees.secret} </secret> </configuration> <executions> <execution> <id> deploy-to-production </id> <phase> deploy </phase> <goals> <goal> deploy </goal> </goals> </execution> </executions> </plugin> </plugins> </build> </profile> </profiles> </project> This plugin is not in Maven Central (unfortunately). That's why we have to specify that <pluginRepository> . Pay attention to the fact that we're also disabling maven-deploy-plugin , since it would try to deploy your WAR package to the repository from the <distributionManagement> section. We want to avoid this. The profile gets activated only when the bees.id property is defined. This won't happen during your normal development and testing, but it will occur during the deployment cycle initiated by Rultor, because we will define this property in settings.xml (discussed below). Secure Access to CloudBees Create an account in CloudBees and register your web application there. CloudBees is free, as long as you don't need too much computing power. I believe that web applications should be light-weight by definition, so CloudBees' free layer is an ideal choice. Create a settings.xml file (but don't commit it to your repo!): <settings> <profiles> <profile> <id> cloudbees </id> <properties> <bees.id> stateful/web </bees.id> <bees.key> <!-- your key --> </bees.key> <bees.secret> <!-- your secret --> </bees.secret> </properties> </profile> </profiles> </settings> Encrypt this file using GPG, with a Rultor key: gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 9AF0FA4C gpg --trust-model always -a -e -r 9AF0FA4C settings.xml You should get a settings.xml.asc file; add it to the root directory of your project, commit and push. This file contains your CloudBees credentials, but in an encrypted format. Nobody can read it, except the Rultor server. Configure Versions Plugin I recommend using http://parent.jcabi.com . It configures the required plugin out-of-the-box. If you're using it, skip this step. Otherwise, add this plugin to your pom.xml : <project> [..] <build> [..] <plugins> [..] <plugin> <groupId> org.codehaus.mojo </groupId> <artifactId> versions-maven-plugin </artifactId> <version> 2.1 </version> <configuration> <generateBackupPoms> false </generateBackupPoms> </configuration> </plugin> </plugins> </build> </project> Configure Rultor Create a .rultor.yml file in the root directory of your project (this reference page explains this format in detail): decrypt : settings.xml : \"repo/settings.xml.asc\" release : script : | mvn versions:set \"-DnewVersion=${tag}\" git commit -am \"${tag}\" mvn clean deploy --settings /home/r/settings.xml You can compare your file with live Rultor configuration of stateful.co . Run It! Now it's time to see how it all works. Create a new ticket in the Github issue tracker, and post something like that into it (read more about Rultor commands ): @rultor release, tag is `0.1` You will get a response in a few seconds. The rest will be done by Rultor. Enjoy :) BTW, if something doesn't work as I've explained, don't hesitate to submit a ticket to the Rultor issue tracker . I will try to help you. Also, a similar configuration can be performed for Heroku (using jcabi-heroku-maven-plugin ) and for AWS Elastic Beanstalk (using jcabi-beanstalk-maven-plugin ). I'll probably dedicate individual posts to them, as well. "},{"title":"How to Publish to Rubygems, in One Click","url":"/2014/08/26/publish-to-rubygems.html","tags":["rubygems","rultor","devops","ruby"],"date":"2014-08-26 00:00:00 +0000","categories":[],"body":"When I release a new version of jgd , a Ruby gem, to Rubygems.org, it takes 30 seconds of my time. Here is how I released a bug fix for version 1.5.1, in Github issue #6 : As you see, I gave a command to Rultor , and it released a new version to Rubygems. I didn't do anything else. Now let's see how you can do the same. How you can configure your project so that the release of its new version to Rubygems.org takes just a few seconds of your time. By the way, I assume that you're hosting your project in Github. If not, this entire tutorial won't work. If you are still not in Github, I would strongly recommend moving there. Create Rubygems Account Create an account in Rubygems.org . Create rubygems.yml Create a rubygems.yml file (you may already have it as ~/.gem/credentials ): :rubygems_api_key : d355d8940bb031bfe9acf03ed3da4c0d You should get this API key from Rubygems. To find your API key, click on your username when logged in to RubyGems.org and then click on \"Edit Profile\". Encrypt rubygems.yml Now, encrypt rubygems.yml with a Rultor public key 9AF0FA4C : gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 9AF0FA4C gpg --trust-model always -a -e -r 9AF0FA4C rubygems.yml You will get a new file rubygems.yml.asc . Add this file to the root directory of your project, commit and push. The file contains your secret information, but only the Rultor server can decrypt it. Prepare Gemspec In your gemspec file, make sure you use 1.0.snapshot as a version number: # coding: utf-8 Gem :: Specification . new do | s | # ... s . version = '1.0.snapshot' # ... end This version name will be replaced by Rultor during deployment. Configure Rultor Create a .rultor.yml file in the root directory of your project: decrypt : rubygems.yml : \"repo/rubygems.yml.asc\" release : script : | rm -rf *.gem sed -i \"s/1.0.snapshot/${tag}/g\" foo.gemspec gem build foo.gemspec chmod 0600 /home/r/rubygems.yml gem push *.gem --config-file /home/r/rubygems.yml In this example, replace foo with the name of your gem. Run It! Now it's time to see how it all works. Create a new ticket in the Github issue tracker, and post something like that into it (read more about Rultor commands ): @rultor release, tag is `0.1` You will get a response in a few seconds. The rest will be done by Rultor. Enjoy :) BTW, if something doesn't work as I've explained, don't hesitate to submit a ticket to Rultor issue tracker . I will try to help you. "},{"title":"How We Run as a Non-Root Inside Docker Container","url":"/2014/08/29/docker-non-root.html","tags":["docker","rultor"],"date":"2014-08-29 00:00:00 +0000","categories":[],"body":"Docker starts a process inside its container as a \"root\" user. In some cases, this is not convenient though. For example, initdb from PostgreSQL doesn't like to be started as root and will fail. In rultor.com , a DevOps team assistant, we're using Docker as a virtualization technology for every build we run. Here is how we change the user inside a running container, right after it is started. First, this is how we start a new Docker container: $ sudo docker run -i -t --rm -v \"$(pwd):/main\" yegor256/rultor /main/entry.sh There are two files in the current directory: entry.sh and script.sh . entry.sh is the file being executed by Docker on start, and it contains the following: #!/bin/bash adduser --disabled-password --gecos '' r adduser r sudo echo '%sudo ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers su -m r -c /home/r/script.sh script.sh will be executed as a user r inside the container. And this r user will have sudo permissions. This is exactly what all projects, managing their DevOps procedures with rultor.com , need. "},{"title":"Simple Java SSH Client","url":"/2014/09/02/java-ssh-client.html","tags":["java","jcabi","ssh"],"date":"2014-09-02 00:00:00 +0000","categories":[],"body":"An execution of a shell command via SSH can be done in Java, in just a few lines, using jcabi-ssh : String hello = new Shell . Plain ( new SSH ( \"ssh.example.com\" , 22 , \"yegor\" , \"-----BEGIN RSA PRIVATE KEY-----...\" ) ). exec ( \"echo 'Hello, world!'\" ); jcabi-ssh is a convenient wrapper of JSch , a well-known pure Java implementation of SSH2. Here is a more complex scenario, where I upload a file via SSH and then read back its grepped content: Shell shell = new SSH( \"ssh.example.com\", 22, \"yegor\", \"-----BEGIN RSA PRIVATE KEY-----...\" ); File file = new File(\"/tmp/data.txt\"); new Shell.Safe(shell).exec( \"cat > d.txt && grep 'some text' d.txt\", new FileInputStream(file), Logger.stream(Level.INFO, this), Logger.stream(Level.WARNING, this) ); Class SSH , which implements interface Shell , has only one method, exec . This method accepts four arguments: interface Shell { int exec( String cmd, InputStream stdin, OutputStream stdout, OutputStream stderr ); } I think it's obvious what these arguments are about. There are also a few convenient decorators that make it easier to operate with simple commands. Shell.Safe Shell.Safe decorates an instance of Shell and throws an exception if the exec exit code is not equal to zero. This may be very useful when you want to make sure that your command executed successfully, but don't want to duplicate if/throw in many places of your code. Shell ssh = new Shell.Safe( new SSH( \"ssh.example.com\", 22, \"yegor\", \"-----BEGIN RSA PRIVATE KEY-----...\" ) ); Shell.Verbose Shell.Verbose decorates an instance of Shell and copies stdout and stderr to the slf4j logging facility (using jcabi-log ). Of course, you can combine decorators, for example: Shell ssh = new Shell.Verbose( new Shell.Safe( new SSH( \"ssh.example.com\", 22, \"yegor\", \"-----BEGIN RSA PRIVATE KEY-----...\" ) ) ); Shell.Plain Shell.Plain is a wrapper of Shell that introduces a new exec method with only one argument, a command to execute. It also doesn't return an exit code, but stdout instead. This should be very convenient when you want to execute a simple command and just get its output (I'm combining it with Shell.Safe for safety): String login = new Shell.Plain(new Shell.Safe(ssh)).exec(\"whoami\"); Download You need a single dependency jcabi-ssh.jar in your Maven project (get its latest version in Maven Central ): <dependency> <groupId> com.jcabi </groupId> <artifactId> jcabi-ssh </artifactId> </dependency> The project is in Github . If you have any problems, just submit an issue. I'll try to help. "},{"title":"RESTful API and a Web Site in the Same URL","url":"/2014/09/09/restful-web-sites.html","tags":["restful","xslt","xml"],"date":"2014-09-09 00:00:00 +0000","categories":[],"body":"Look at Github RESTful API, for example. To get information about a repository you should make a GET request to api.github.com/repos/yegor256/rultor . In response, you will get a JSON document with all the details of the yegor256/rultor repository. Try it, the URL doesn't require any authentication. To open the same repository in a nice HTML+CSS page, you should use a different URL: github.com/yegor256/rultor . The URL is different, the server-side is definitely different, but the nature of the data is exactly the same. The only thing that changes is a representation layer. In the first case, we get JSON; in the second — HTML. How about combining them? How about using the same URL and the same server-side processing mechanism for both of them? How about shifting the whole rendering task to the client-side (the browser) and letting the server work solely with the data? The Good, the Bad, The Wierd (2008) by Kim Jee-woon XSLT is the technology that can help us do this. In \"XML+XSLT in a Browser\" I explained briefly how it works in a browser. In a nutshell, the server returns an XML with some data and a link to the XSL stylesheet. The stylesheet, being executed in a browser, converts XML to HTML. XSL language is as powerful as any other rendering engine, like JSP, JSF, Tiles, or what have you. Actually, it is much more powerful. Using this approach we literally remove the entire rendering layer (\"View\" in the MVC paradigm) from the server and move it to the browser. If we can make it possible, the web server will exponse just a RESTful API, and every response page will have an XSL stylesheet attached. What do we gain? We'll discuss later, at the end of the post. Now, let's see what problems we will face: JSON doesn't have a rendering layer. There is no such thing as XSLT for JSON. So, we will have to forget about JSON and stay with XML only. For me, this sounds perfectly all right. Others don't like XML and prefer to work with JSON only. Never understood them :) XSLT 2.0 is not supported by all browsers. Even XSLT 1.0 is only supported by some of them. For example, Internet Explorer 8 doesn't support XSLT at all. Browsers support only GET and POST HTTP methods, while traditional RESTful APIs exploit also, at least, PUT and DELETE . The first problem is not really a problem. It's just a matter of taste (and level of education). The last two problems are much more serious. Let's discuss them. XSL Transformation on the Server XSLT is not supported by some browsers. How do we solve this? I think that the best approach is to parse the User-Agent HTTP header in every request and make a guess, whether this particular version of the browser supports XSLT or not. It's not so difficult to do, since this compatibility information is public. If the browser doesn't support XSLT, we can do the transformation on the server side. We already have the XML with data, generated by the server, and we already have the XSL attached to it. All we need to do is to apply the latter to the former and obtain an HTML page. Then, we return the HTML to the browser. Besides that, we can also pay attention to the Accept header. If it is set to application/xml or text/xml , we return XML, no matter what User-Agent is saying. This means, basically, that some API client is talking to us, not a browser. And this client is not interested in HTML, but in pure data in XML format. POST Instead of PUT There is no workaround for this. Browsers don't know anything about PUT or DELETE . So, we should also forget them in our RESTful APIs. We should design our API using only two methods: GET and POST . Is this even possible? Yes. Why not? It won't look as fancy as with all six methods (some APIs also use OPTIONS and HEAD ), but it will work. What Do We Gain? OK, here is the question — why do we need this? What's wrong with the way most people work now? Why can't we make a web site separate from the API? What benefits do we get if we combine them? I've been combining them in all web applications I've worked with since 2011. And the biggest advantage I'm experiencing is avoiding code duplication. It is obvious that in the server we don't duplicate controllers (in the case of MVC). We have one layer of controllers, and they control both the API and the web site (since they are one thing now). Avoiding code duplication is a very important achievement. Moreover, I believe that it is the most important target for any software project. These small web apps work exactly as explained above: s3auth.com , stateful.co , bibrarian.com . They are all open source, and you can see their source code in Github. "},{"title":"Anti-Patterns in OOP","url":"/2014/09/10/anti-patterns-in-oop.html","tags":["oop","anti-pattern"],"date":"2014-09-10 00:00:00 +0000","categories":[],"body":"Here they come: NULL References Utility Classes Mutable Objects Getters and Setters Singletons Controllers, Managers, Validators Public Static Methods Avoid them at all cost. "},{"title":"Deployment Script vs. Rultor","url":"/2014/09/11/deployment-script-vs-rultor.html","tags":["rultor","devops"],"date":"2014-09-11 00:00:00 +0000","categories":[],"body":" When I explain how Rultor automates deployment/release processes, very often I hear something like: But I already have a script that deploys everything automatically. This response is very common, so I decided to summarize my three main arguments for automated Rultor deployment/release processes in one article: 1) isolated docker containers, 2) visibility of logs and 3) security of credentials. Read about them and see what Rultor gives you on top of your existing deployment script(s). Charlie and the Chocolate Factory (2005) by Tim Burton Before we start with the arguments, let me emphasize that Rultor is a useful interface to your custom scripts. When you decide to automate deployment with Rultor, you don't throw away any of your existing scripts. You just teach Rultor how to call them. Isolated Docker Containers The first advantage you get once you start calling your deployment scripts from Rultor is the usage of Docker . I'm sure you know what Docker is, but for those who don't — it is a manager of virtual Linux \"machines\". It's a command line script that you call when you need to run some script in a new virtual machine (aka \"container\"). Docker starts the container almost immediately and runs your script. The beauty of Docker is that every container is a perfectly isolated Linux environment, with its own file system, memory, processes, etc. When you tell Rultor to run your deployment script, it starts a new Docker container and runs your script there. But what benefit does this give me, you ask? The main benefit is that the container gets destroyed right after your script is done. This means that you can do all pre-configuration inside the container without any fear of conflict with your main working platform. Let me give an example. I'm developing on MacBook, where I install and remove packages which I need for development. At the same time, I have a project that, in order to be deployed, requires PHP 5.3, MySQL 5.6, phing, phpunit, phpcs and xdebug. Every MacOS version needs to be configured specifically to get these applications up and running, and it's a time-consuming job. I can change laptops, and I can change MacOS versions, but the project stays the same. It still requires the same set of packages in order to run its deployment script successfully. And the project is not in active development any more. I simply don't need these packages for my day-to-day work, since I'm working with Java more now. But, when I need to make a minor fix to that PHP project and deploy it, I have to install all the required PHP packages and configure them. Only after that can I deploy that minor fix. It is annoying, to say the least. Docker gives me the ability to automate all of this together. My existing deployment script will get a preamble, which will install and configure all necessary PHP-related packages in a clean Ubuntu container. This preamble will be executed on every run of my deployment script, inside a Docker container. For example, it may look like this: My deployment script looked like this before I started to use Rultor: 1 2 3 #!/bin/bash phing test git ftp push --user \"..\" --passwd \"..\" --syncroot php/src ftp://ftp.example.com/ Just two lines. The first one is a full run of unit tests. The second one is an FTP deployment to the production server. Very simple. But this script will only work if PHP 5.3, MySQL, phing, xdebug, phpcs and phpunit are installed. Again, it's a lot of work to install and configure them every time I upgrade my MacOS or change a laptop. Needless to say, that if/when someone joins the project and tries to run my scripts, he/she will have to do this pre-installation work again. So, here is a new script, which I'm using now. It is being executed inside a new Docker container, every time: 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash # First, we install all prerequisites sudo apt-get install -y php5 php5-mysql mysql sudo apt-get install php-pear sudo pear channel-discover pear.phpunit.de sudo pear install phpunit/PHPUnit sudo pear install PHP_CodeSniffer sudo pecl install xdebug sudo pear channel-discover pear.phing.info sudo pear install phing/phing # And now the same script I had before phing test git ftp push --user \"..\" --passwd \"..\" --syncroot php/src ftp://ftp.example.com/ Obviously, running this script on my MacBook (without virtualization) would cause a lot of trouble. Well, I don't even have apt-get here :) Thus, the first benefit that Rultor gives you is an isolation of your deployment script in its own virtual environment. We have this mostly thanks to Docker. Visibility of Logs Traditionally, we keep deployment scripts in some ~/deploy directory and run them with a magic set of parameters. In a small project, you do this yourself and this directory is on your own laptop. In a bigger project, there is a \"deployment\" server, that has that magic directory with a set of scripts that can be executed only by a few trusted senior developers. I've seen this setup many times. The biggest issue here is traceability. It's almost impossible to find out who deployed what and why some particular deployment failed. The senior deployment gurus simply SSH to the server and run those magic scripts with magic parameters. Logs are usually lost and problem tracking is very difficult or impossible. Rultor offers something different. With Rultor, there is no SSH access to deployment scripts any more. All scripts stay in the .rultor.yml configuration file, and you start them by posting messages in your issue tracking system (for example Github, JIRA or Trac). Rultor runs the script and publishes its full log right to your ticket. The log stays with your project forever. You can always get back to the ticket you were working with and check why deployment failed and what instructions were actually executed. For example, check out this Github issue, where I was deploying a new version of Rultor itself, and failed a few times: yegor256/rultor#563 . All my failed attempts are protocolled. I can always get back to them and investigate. For a big project this information is vital. Thus, the second benefit of Rultor versus a standalone deployment script is visibility of every single operation. Security of Credentials When you have a custom script sitting in your laptop or in that secret team deployment server, your production credentials stay close to it. There is just no other way. If your software works with a database, it has to know login credentials (user name, password, DB name, port number, etc.). Well, in the worst case, some people just hard code that information right into the source code. We aren't even going to discuss this case, that's how bad it is. But let's say you separate your DB credentials from the source code. You will have something like a db.properties or db.ini file, which will be attached to the application right before deployment. You can also keep that file directly in the production server, which is even better, but not always possible, especially with PaaS deployments, for example. A similar problem exists with deployments of artifacts to repositories. Say, you're regularly deploying to RubyGems.org. Your ~/.gem/credentials will contain your secret API key. So, very often, your deployment scripts are accompanied by some files with sensitive and secure information. And these files have this information in a plain, open format. No encryption, no protection. Just user names, passwords, codes and tokens in plain text. Why is this bad? Well, for a single developer with a single laptop this doesn't sound like a problem. Although, I don't like the idea of losing a laptop somewhere in an airport with all credentials open and ready to be used. You may argue that there are disc protection tools, like FileVault for MacOS or BestCrypt for Windows. Yes, maybe. But let's see what happens when we have a team of developers, working together and sharing those deployment scripts and files with credentials. Once you give access to your deployment scripts to a new member of the team, you have to share all that sensitive data. There is just no way around it. In order to use the scripts he/she has to be able to open files with credentials. This is a problem, if you care about the security of your data. Rultor solves this problem by offering an on-the-fly GPG decryption of your sensitive data, right before they are used by your deployment scripts. In the .rultor.yml configuration file you just say: decrypt : db.ini : \"repo/db.ini.asc\" deploy : script : ftp put db.ini production Then, you encrypt your db.ini using a Rultor GPG key, and fearlessly commit db.ini.asc to the repository. Nobody will be able to open and read that file, except the Rultor server itself, right before running the deployment script. Thus, the third benefit of Rultor versus a standalone deployment script is proper security of sensitive data. "},{"title":"Deploying to Heroku, in One Click","url":"/2014/09/13/deploying-to-heroku.html","tags":["rultor","devops","heroku","java"],"date":"2014-09-13 00:00:00 +0000","categories":[],"body":"There were a few articles already about our usage of Rultor for automating continuous delivery cycles of Java and Ruby projects, including Rubygems , CloudBees and MavenCentral . This one describes how Heroku deployment can be automated. When I need to deploy a new version of an Aintshy web application, all I do is create one message in a Github ticket. I just say @rultor release 0.1.4 and version 0.1.4 gets deployed to Heroku. See Github ticket #5 . You can do the same, with the help of Rultor.com , a free hosted DevOps assistant. Create Heroku Project Create a new project at Heroku.com . Then install their command line toolbelt . Authenticate at Heroku You should authenticate your public SSH key at Heroku, using their command line toolbelt. The process is explained here , but it is not much of a process. You just run heroku login and enter your login credentials. As a result, you will get your existing key (located at ~/.ssh/id_rsa.pub ) authenticated by Heroku. If you didn't have the key before, it will be created automatically. Encrypt SSH Key Now, encrypt id_rsa and id_rsa.pub (they are in the ~/.ssh directory) with a Rultor public key, 9AF0FA4C : gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 9AF0FA4C gpg --trust-model always -a -e -r 9AF0FA4C id_rsa gpg --trust-model always -a -e -r 9AF0FA4C id_rsa.pub You will get two new files id_rsa.asc and id_rsa.pub.asc . Add them to the root directory of your project, commit and push. These files contain your secret information, but only the Rultor server can decrypt them. Create Rultor Config Create a .rultor.yml file in the root directory of your project ( reference page explains this format in detail): decrypt : id_rsa : \"repo/id_rsa.asc\" id_rsa.pub : \"repo/id_rsa.pub.asc\" release : script : | mvn versions:set \"-DnewVersion=${tag}\" git commit -am \"${tag}\" mvn clean install -Pqulice --errors git remote add heroku git@heroku.com:aintshy.git mkdir ~/.ssh mv ../id_rsa ../id_rsa.pub ~/.ssh chmod -R 600 ~/.ssh/* echo -e \"Host *\\n StrictHostKeyChecking no\\n UserKnownHostsFile=/dev/null\" > ~/.ssh/config git push -f heroku $(git symbolic-ref --short HEAD):master You can compare your file with live Rultor configuration of aintshy/hub . Run It! Now it's time to see how it all works. Create a new ticket in the Github issue tracker, and post something like this into it (read more about Rultor commands ): @rultor release, tag is `0.1` You will get a response in a few seconds. The rest will be done by Rultor. Enjoy :) BTW, if something doesn't work as I've explained, don't hesitate to submit a ticket to the Rultor issue tracker . I will try to help you. "},{"title":"Getters/Setters. Evil. Period.","url":"/2014/09/16/getters-and-setters-are-evil.html","tags":["oop","anti-pattern"],"date":"2014-09-16 00:00:00 +0000","categories":["best"],"body":"There is an old debate, started in 2003 by Allen Holub in this Why getter and setter methods are evil famous article, about whether getters/setters is an anti-pattern and should be avoided or if it is something we inevitably need in object-oriented programming. I'll try to add my two cents to this discussion. The gist of the following text is this: getters and setters is a terrible practice and those who use it can't be excused. Again, to avoid any misunderstanding, I'm not saying that get/set should be avoided when possible. No. I'm saying that you should never have them near your code. Arrogant enough to catch your attention? You've been using that get/set pattern for 15 years and you're a respected Java architect? And you don't want to hear that nonsense from a stranger? Well, I understand your feelings. I felt almost the same when I stumbled upon Object Thinking by David West, the best book about object-oriented programming I've read so far. So please. Calm down and try to understand while I try to explain. Existing Arguments There are a few arguments against \"accessors\" (another name for getters and setters), in an object-oriented world. All of them, I think, are not strong enough. Let's briefly go through them. Tell, Don't Ask Allen Holub says, \"Don't ask for the information you need to do the work; ask the object that has the information to do the work for you\". Violated Encapsulation Principle An object can be teared apart by other objects, since they are able to inject any new data into it, through setters. The object simply can't encapsulate its own state safely enough, since anyone can alter it. Exposed Implementation Details If we can get an object out of another object, we are relying too much on the first object's implementation details. If tomorrow it will change, say, the type of that result, we have to change our code as well. All these justifications are reasonable, but they are missing the main point. Fundamental Misbelief Most programmers believe that an object is a data structure with methods. I'm quoting Getters and Setters Are Not Evil , an article by Bozhidar Bozhanov: But the majority of objects for which people generate getters and setters are simple data holders. This misconception is the consequence of a huge misunderstanding! Objects are not \"simple data holders\". Objects are not data structures with attached methods. This \"data holder\" concept came to object-oriented programming from procedural languages, especially C and COBOL. I'll say it again: an object is not a set of data elements and functions that manipulate them. An object is not a data entity. What is it then? A Ball and A Dog In true object-oriented programming, objects are living creatures, like you and me. They are living organisms, with their own behaviour, properties and a life cycle. Can a living organism have a setter? Can you \"set\" a ball to a dog? Not really. But that is exactly what the following piece of software is doing: Dog dog = new Dog (); dog . setBall ( new Ball ()); How does that sound? Can you get a ball from a dog? Well, you probably can, if she ate it and you're doing surgery. In that case, yes, we can \"get\" a ball from a dog. This is what I'm talking about: Dog dog = new Dog (); Ball ball = dog . getBall (); Or an even more ridiculous example: Dog dog = new Dog (); dog . setWeight ( \"23kg\" ); Can you imagine this transaction in the real world? :) Does it look similar to what you're writing every day? If yes, then you're a procedural programmer. Admit it. And this is what David West has to say about it, on page 30 of his book: Step one in the transformation of a successful procedural developer into a successful object developer is a lobotomy. Do you need a lobotomy? Well, I definitely needed one and received it, while reading West's Object Thinking . Object Thinking Start thinking like an object and you will immediately rename those methods. This is what you will probably get: Dog dog = new Dog (); dog . take ( new Ball ()); Ball ball = dog . give (); Now, we're treating the dog as a real animal, who can take a ball from us and can give it back, when we ask. Worth mentioning is that the dog can't give NULL back. Dogs simply don't know what NULL is :) Object thinking immediately eliminates NULL references from your code. A Fish Called Wanda (1988) by Charles Crichton Besides that, object thinking will lead to object immutability, like in the \"weight of the dog\" example. You would re-write that like this instead: Dog dog = new Dog ( \"23kg\" ); int weight = dog . weight (); The dog is an immutable living organism, which doesn't allow anyone from the outside to change her weight, or size, or name, etc. She can tell, on request, her weight or name. There is nothing wrong with public methods that demonstrate requests for certain \"insides\" of an object. But these methods are not \"getters\" and they should never have the \"get\" prefix. We're not \"getting\" anything from the dog. We're not getting her name. We're asking her to tell us her name. See the difference? We're not talking semantics here, either. We are differentiating the procedural programming mindset from an object-oriented one. In procedural programming, we're working with data, manipulating them, getting, setting, and deleting when necessary. We're in charge, and the data is just a passive component. The dog is nothing to us — it's just a \"data holder\". It doesn't have its own life. We are free to get whatever is necessary from it and set any data into it. This is how C, COBOL, Pascal and many other procedural languages work(ed). On the contrary, in a true object-oriented world, we treat objects like living organisms, with their own date of birth and a moment of death — with their own identity and habits, if you wish. We can ask a dog to give us some piece of data (for example, her weight), and she may return us that information. But we always remember that the dog is an active component. She decides what will happen after our request. That's why, it is conceptually incorrect to have any methods starting with set or get in an object . And it's not about breaking encapsulation, like many people argue. It is whether you're thinking like an object or you're still writing COBOL in Java syntax. PS. Yes, you may ask, — what about JavaBeans, JPA, JAXB, and many other Java APIs that rely on the get/set notation? What about Ruby's built-in feature that simplies the creation of accessors? Well, all of that is our misfortune. It is much easier to stay in a primitive world of procedural COBOL than to truly understand and appreciate the beautiful world of true objects. PPS. Forgot to say, yes, dependency injection via setters is also a terrible anti-pattern. About it, in one of the next posts :) "},{"title":"Remote Programming in Teamed.io","url":"/2014/09/22/remote-programming-interview.html","tags":["mgmt"],"date":"2014-09-22 00:00:00 +0000","categories":[],"body":"Here is an interview taken by Lisette Sutherland from www.CollaborationSuperpowers.com , a few hours ago, which I enjoyed to give :) I answered these questions (approximately): How Teamed.io differs from other software companies (0:50)? How do we control programmers remotely (1:59)? Do we compare ourselves with open source (3:52)? How do we build a network of programmers (5:10)? Why people like to work with us (5:40)? What happens when a programmer fails (7:50)? How can it be financially successful (9:40)? How do we organize \"team building\" (11:50)? What challenges do we have (14:50)? What about micro-management (17:55)? Can this work in a non-IT sector (19:40)? What do you do to manage the team (20:48)? Isn't it difficult to manage so many tasks (24:18)? Do we have cultural issues (25:35)? Is it true that people are not enough result-oriented (27:40)? Are there any other challenges (29:12)? What do I like personally about it (30:40)? How do we scale our teams when we need more programmers (32:01)? What an \"unlimited pool of talents\" means (34:40)? What advice do I have for those who work remotely (37:50)? Where do I work from, personally (39:10)? How do we find clients (42:29)? Enjoy :) "},{"title":"Built-in Fake Objects","url":"/2014/09/23/built-in-fake-objects.html","tags":["testing","java"],"date":"2014-09-23 00:00:00 +0000","categories":[],"body":"While mock objects are perfect instruments for unit testing, mocking through mock frameworks may turn your unit tests into an unmaintainable mess. The root cause of this complexity is that our objects are too big. They have many methods and these methods return other objects, which also have methods. When we pass a mock version of such an object as a parameter, we should make sure that all of its methods return valid objects. This leads to inevitable complexity, which turns unit tests to waste almost impossible to maintain. Object Hierarchy Take the Region interface from jcabi-dynamo as an example (this snippet and all others in this article are simplified, for the sake of brevity): public interface Region { Table table ( String name ); } Its table() method returns an instance of the Table interface, which has its own methods: public interface Table { Frame frame (); Item put ( Attributes attrs ); Region region (); } Interface Frame , returned by the frame() method, also has its own methods. And so on. In order to create a properly mocked instance of interface Region , one would normally create a dozen other mock objects. With Mockito it will look like this: public void testMe () { // many more lines here... Frame frame = Mockito . mock ( Frame . class ); Mockito . doReturn (...). when ( frame ). iterator (); Table table = Mockito . mock ( Table . class ); Mockito . doReturn ( frame ). when ( table ). frame (); Region region = Mockito . mock ( Region . class ); Mockito . doReturn ( table ). when ( region ). table ( Mockito . anyString ()); } And all of this is just a scaffolding before the actual testing. Sample Use Case Let's say, you're developing a project that uses jcabi-dynamo for managing data in DynamoDB. Your class may look similar to this: public class Employee { private final String name ; private final Region region ; public Employee ( String empl , Region dynamo ) { this . name = empl ; this . region = dynamo ; } public Integer salary () { return Integer . parseInt ( this . region . table ( \"employees\" ) . frame () . where ( \"name\" , this . name ) . iterator () . next () . get ( \"salary\" ) . getN () ); } } You can imagine how difficult it will be to unit test this class, using Mockito, for example. First, we have to mock the Region interface. Then, we have to mock a Table interface and make sure it is returned by the table() method. Then, we have to mock a Frame interface, etc. The unit test will be much longer than the class itself. Besides that, its real purpose, which is to test the retrieval of an employee's salary, will not be obvious to the reader. Moreover, when we need to test a similar method of a similar class, we will need to restart this mocking from scratch. Again, multiple lines of code, which will look very similar to what we have already written. Fake Classes The solution is to create fake classes and ship them together with real classes. This is what jcabi-dynamo is doing. Just look at its JavaDoc . There is a package called com.jcabi.dynamo.mock that contains only fake classes, suitable only for unit testing. Even though their sole purpose is to optimize unit testing, we ship them together with production code, in the same JAR package. This is what a test will look like, when a fake class MkRegion is used: public class EmployeeTest { public void canFetchSalaryFromDynamoDb () { Region region = new MkRegion ( new H2Data (). with ( \"employees\" , new String [] { \"name\" }, new String [] { \"salary\" } ) ); region . table ( \"employees\" ). put ( new Attributes () . with ( \"name\" , \"Jeff\" ) . with ( \"salary\" , new AttributeValue (). withN ( 50000 )) ); Employee emp = new Employee ( \"Jeff\" , region ); assertThat ( emp . salary (), equalTo ( 50000 )) } } This test looks obvious to me. First, we create a fake DynamoDB region, which works on top of H2Data storage (in-memory H2 database). The storage will be ready for a single employees table with a hash key name and a single salary attribute. Then, we put a record into the table, with a hash Jeff and a salary 50000 . Finally, we create an instance of class Employee and check how it fetches the salary from DynamoDB. I'm currently doing the same thing in almost every open source library I'm working with. I'm creating a collection of fake classes, that simplify testing inside the library and for its users. "},{"title":"Monetary Awards Can Work","url":"/2014/09/24/why-monetary-awards-dont-work.html","tags":["mgmt"],"date":"2014-09-24 00:00:00 +0000","categories":[],"body":"Monetary rewards for employees. Do they work? Should we use them? Can money motivate creative minds? Will a programmer work better if he gets paid only when he reaches his goals and objectives? Much research has already been done on this subject, and most of it proves that connecting results with money is a very demotivating approach. For example, Ian Larkin says that the most productive workers \"suffered a 6-8% decrease in productivity after the award was instituted\". I believe this is completely true. Money may become a terrible de-motivator for all modern employees (not just programmers). My question is — why is this so? Why doesn't money work, even when it was invented to be a universal instrument to measure our labor? Why can't an American dollar, which has been used for centuries as a trading tool between working people, be used anymore? Why, in a modern office, do we try to hide monetary motivation and replace it with everything else , like free lunches, team building events, paid vacations, etc. Why don't we just say — \"Jeff completed his task faster than everybody else. This is his $500 check. Whoever completes the next task gets $300,\" out loud in the office?... Sounds uncomfortable, doesn't it? Why does money as a motivator scare us? I have an answer. Money doesn't work when there are no ground rules. When we say that Jeff will get a $500 bonus if he finishes his task on time, but don't say what he should do when someone distracts him — Jeff gets frustrated. He also doesn't understand who his boss is anymore. Does he just work for the bonus, or should he also satisfy a CTO who comes to his desk asking him to do something else urgently? Is Jeff allowed to tell the CTO \"to get lost\" because he's working towards his own personal objective (the bonus)? In all cases I've seen myself and in all research cases I've read about, people keep repeating the same mistake. They create a rewards program (monetary or not) without setting ground rules for the team. By doing so, they encourage people to play wild-wild west, where the fastest gets the cash bag. Obviously, the Bad and the Ugly get to the prize faster, while the Good gets demotivated and depressed. In a clockwise direction from the top left corner: The Good, the Bad and the Ugly (1966) by Sergio Leone; Roger Federer; A Serious Man (2009) by Ethan Coen and Joel Coen; Two and a Half Men (TV Series). What do I mean by ground rules? It should be a simple document ( PMBOK calls it a Staffing Management Plan) that helps me, as a team member, answer at least these basic questions: How my personal results are measured? Who gives me tasks and who do I report to? How should I resolve conflicts between tasks? What are my personal deadlines for every task? Do I have measurable quality expectations for my deliverables? How do my mistakes affect my performance grade? The ground rules document should be superior to your boss. If the document says that your results get an A+ grade, the boss should have no say. If she doesn't like you personally, it doesn't matter. You get an A+ grade, and you are the best. That's it. Does your team have such a document? Can you answer all of these questions? If not, you're not ready for a rewards program. It will only make your management situation worse, just like all the scientific research says. Rewards will motivate the most cunning to take advantage of the most hard working and good-natured. Team spirit will suffer, big time. On the other hand, if you have that \"ground rules\" document and you strictly follow it, giving monetary rewards to your workers will significantly increase their performance and motivation. They will know exactly what needs to be done to get the rewards, and they won't have any distraction. Your team won't be a group of wild west gunslingers anymore, but more like players in a sports arena. The best players will go further, and the worst will know exactly what needs to be done to improve. Fair competition will lead to a better cumulative result. Moreover, if your ground rules are strict and explicit, you can use not only rewards, but also punishments. And your team will gladly accept them, because they will help emphasize what (and who) works best and help get rid of the waste. I'm speaking from experience here. In XDSD we're not only rewarding programmers with money, but we also never pay for anything except delivered results. We manage to do this mostly because our groud rules are very strict and non-ambiguous. And we never break them. "}]}